{"ast":null,"code":"import _asyncToGenerator from \"/Users/ryanliang/Downloads/main_movir_picker/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { tidy, util } from '@tensorflow/tfjs-core';\nimport { getNodeNameAndIndex, getParamValue, getTensor, getTensorsForCurrentContenxt, parseNodeName } from '../operations/executors/utils';\nimport { executeOp } from '../operations/operation_executor';\nimport { ExecutionContext } from './execution_context';\nimport { getExecutionSubgraph, getNodesInTopologicalOrder, isControlFlow } from './model_analysis';\nexport class GraphExecutor {\n  /**\n   *\n   * @param graph Graph the model or function graph to be executed.\n   * @param parent When building function exector you need to set the parent\n   * executor. Since the weights and function executor maps are set at parant\n   * level, that function executor can access the function maps and weight maps\n   * through the parent.\n   */\n  constructor(graph, parent) {\n    this.graph = graph;\n    this.parent = parent;\n    this.compiledMap = new Map();\n    this._weightMap = {};\n    this.SEPERATOR = ',';\n    this._functions = {};\n    this._functionExecutorMap = {};\n    this._outputs = graph.outputs;\n    this._inputs = graph.inputs;\n    this._initNodes = graph.initNodes;\n    this._signature = graph.signature;\n    this._functions = graph.functions; // create sub-graph executors\n\n    if (graph.functions != null) {\n      Object.keys(graph.functions).forEach(name => {\n        this._functionExecutorMap[name] = new GraphExecutor(graph.functions[name], this);\n      });\n    }\n  }\n\n  get weightIds() {\n    return this.parent ? this.parent.weightIds : this._weightIds;\n  }\n\n  get functionExecutorMap() {\n    return this.parent ? this.parent.functionExecutorMap : this._functionExecutorMap;\n  }\n\n  get weightMap() {\n    return this.parent ? this.parent.weightMap : this._weightMap;\n  }\n\n  set weightMap(weightMap) {\n    const weightIds = Object.keys(weightMap).map(key => weightMap[key].map(tensor => tensor.id));\n    this._weightIds = [].concat(...weightIds);\n    this._weightMap = weightMap;\n  }\n  /**\n   * Set `ResourceManager` shared by executors of a model.\n   * @param resourceManager: `ResourceManager` of the `GraphModel`.\n   */\n\n\n  set resourceManager(resourceManager) {\n    this._resourceManager = resourceManager;\n  }\n\n  get inputs() {\n    return this._inputs.map(node => {\n      return {\n        name: node.name,\n        shape: node.attrParams['shape'] ? node.attrParams['shape'].value : undefined,\n        dtype: node.attrParams['dtype'] ? node.attrParams['dtype'].value : undefined\n      };\n    });\n  }\n\n  get outputs() {\n    return this._outputs.map(node => {\n      return {\n        name: node.name,\n        shape: node.attrParams['shape'] ? node.attrParams['shape'].value : undefined,\n        dtype: node.attrParams['dtype'] ? node.attrParams['dtype'].value : undefined\n      };\n    });\n  }\n\n  get inputNodes() {\n    return this._inputs.map(node => node.signatureKey || node.name);\n  }\n\n  get outputNodes() {\n    return this._outputs.map(node => {\n      const name = node.signatureKey || node.name;\n      return node.defaultOutput ? `${name}:${node.defaultOutput}` : name;\n    });\n  }\n\n  get functions() {\n    return Object.keys(this._functions).reduce((map, key) => {\n      map[key] = this._functions[key].signature;\n      return map;\n    }, {});\n  }\n\n  getCompilationKey(inputs, outputs) {\n    const sortedInputs = inputs.map(node => node.name).sort();\n    const sortedOutputs = outputs.map(node => node.name).sort();\n    return sortedInputs.join(this.SEPERATOR) + '--' + sortedOutputs.join(this.SEPERATOR);\n  }\n  /**\n   * Compiles the inference graph and returns the minimal set of nodes that are\n   * required for execution, in the correct execution order.\n   */\n\n\n  compile(inputs, outputs) {\n    const executionInfo = getExecutionSubgraph(inputs, outputs, this.weightMap, this._initNodes);\n    const {\n      missingInputs,\n      dynamicNode,\n      syncInputs\n    } = executionInfo;\n\n    if (dynamicNode != null) {\n      throw new Error(`This execution contains the node '${dynamicNode.name}', which has ` + `the dynamic op '${dynamicNode.op}'. Please use ` + `model.executeAsync() instead. Alternatively, to avoid the ` + `dynamic ops, specify the inputs [${syncInputs}]`);\n    }\n\n    if (missingInputs.length > 0) {\n      const outNames = outputs.map(n => n.name);\n      const inNames = Object.keys(inputs);\n      throw new Error(`Cannot compute the outputs [${outNames}] from the provided inputs ` + `[${inNames}]. Missing the following inputs: [${missingInputs}]`);\n    }\n\n    return getNodesInTopologicalOrder(this.graph, this.weightMap, executionInfo);\n  }\n  /**\n   * Executes the inference for given input tensors.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs Optional. output node name from the Tensorflow model, if\n   * no outputs are specified, the default outputs of the model would be used.\n   * You can inspect intermediate nodes of the model by adding them to the\n   * outputs array.\n   */\n\n\n  execute(inputs, outputs) {\n    inputs = this.mapInputs(inputs);\n    const names = Object.keys(inputs).sort();\n    this.checkInputs(inputs);\n    this.checkInputShapeAndType(inputs);\n    outputs = this.mapOutputs(outputs);\n    this.checkOutputs(outputs);\n    const inputNodes = names.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n    const outputNodeNames = outputs.map(name => parseNodeName(name)[0]);\n    let outputNodes = outputNodeNames.map(name => this.graph.nodes[name]); // If no outputs are specified, then use the default outputs of the model.\n\n    if (outputNodes.length === 0) {\n      outputNodes = this._outputs;\n    }\n\n    const compilationKey = this.getCompilationKey(inputNodes, outputNodes); // Do nothing if the compiled graph cache contains the input.\n\n    let orderedNodes = this.compiledMap.get(compilationKey);\n\n    if (orderedNodes == null) {\n      orderedNodes = this.compile(inputs, outputNodes);\n      this.compiledMap.set(compilationKey, orderedNodes);\n    }\n\n    const tensorArrayMap = {};\n    const tensorListMap = {};\n    return tidy(() => {\n      const context = new ExecutionContext(this.weightMap, tensorArrayMap, tensorListMap, this.functionExecutorMap);\n      const tensorsMap = Object.assign({}, this.weightMap);\n      Object.keys(inputs).forEach(name => {\n        const [nodeName, index] = parseNodeName(name);\n        const tensors = [];\n        tensors[index] = inputs[name];\n        tensorsMap[nodeName] = tensors;\n      });\n      const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);\n      const intermediateTensorConsumerCount = {};\n\n      for (let i = 0; i < orderedNodes.length; i++) {\n        const node = orderedNodes[i];\n\n        if (!tensorsMap[node.name]) {\n          const tensors = executeOp(node, tensorsMap, context, this._resourceManager);\n\n          if (util.isPromise(tensors)) {\n            throw new Error(`The execution of the op '${node.op}' returned a promise. ` + `Please use model.executeAsync() instead.`);\n          }\n\n          tensorsMap[node.name] = tensors;\n          this.checkTensorForDisposal(node.name, node, tensorsMap, context, tensorsToKeep, outputNodeNames, intermediateTensorConsumerCount);\n        }\n      } // dispose the context for the root executor\n\n\n      if (this.parent == null) {\n        context.dispose(tensorsToKeep);\n      }\n\n      return outputs.map(name => getTensor(name, tensorsMap, context));\n    });\n  }\n\n  getFrozenTensorIds(tensorMap) {\n    const ids = [].concat.apply([], Object.keys(tensorMap).map(key => tensorMap[key]).map(tensors => tensors.map(tensor => tensor.id)));\n    return new Set(ids);\n  }\n\n  checkTensorForDisposal(nodeName, node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount) {\n    // Skip output nodes and any control flow nodes, since its dependency is\n    // tricky to track correctly.\n    if (node.category === 'control' || outputNames.indexOf(nodeName) !== -1) {\n      return;\n    }\n\n    tensorMap[nodeName].forEach(tensor => {\n      if (tensor != null) {\n        intermediateTensorConsumerCount[tensor.id] = (intermediateTensorConsumerCount[tensor.id] || 0) + node.children.length;\n      }\n    });\n    node.inputs.forEach(input => {\n      // Skip any control flow nodes, since its dependency is tricky to track\n      // correctly.\n      if (input.category !== 'control') {\n        const tensors = getTensorsForCurrentContenxt(input.name, tensorMap, context);\n\n        if (tensors != null) {\n          tensors.forEach(tensor => {\n            if (tensor && !tensorsToKeep.has(tensor.id)) {\n              const count = intermediateTensorConsumerCount[tensor.id];\n\n              if (count === 1) {\n                tensor.dispose();\n                delete intermediateTensorConsumerCount[tensor.id];\n              } else if (count != null) {\n                // only intermediate nodes has count set, inputs and weights are\n                // not.\n                intermediateTensorConsumerCount[tensor.id]--;\n              }\n            }\n          });\n        }\n      }\n    });\n  }\n  /**\n   * Executes the inference for given input tensors in Async fashion.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs output node name from the Tensorflow model, if no outputs\n   * are specified, the default outputs of the model would be used. You can\n   * inspect intermediate nodes of the model by adding them to the outputs\n   * array.\n   */\n\n\n  executeAsync(inputs, outputs) {\n    var _this = this;\n\n    return _asyncToGenerator(function* () {\n      return _this._executeAsync(inputs, outputs);\n    })();\n  }\n  /**\n   * Executes the inference for given input tensors in Async fashion.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs Optional. output node name from the Tensorflow model,\n   * if no outputs are specified, the default outputs of the model would be\n   * used. You can inspect intermediate nodes of the model by adding them to the\n   * outputs array.\n   * @param isFunctionExecution Optional. Flag for executing a function.\n   * @param tensorArrayMap Optional, global TensorArray map by id. Used for\n   * function execution.\n   * @param tensorArrayMap Optinal global TensorList map by id. Used for\n   * function execution.\n   */\n\n\n  _executeAsync(inputs, outputs, isFunctionExecution = false, tensorArrayMap = {}, tensorListMap = {}) {\n    var _this2 = this;\n\n    return _asyncToGenerator(function* () {\n      if (!isFunctionExecution) {\n        inputs = _this2.mapInputs(inputs);\n\n        _this2.checkInputs(inputs);\n\n        _this2.checkInputShapeAndType(inputs);\n\n        outputs = _this2.mapOutputs(outputs);\n\n        _this2.checkOutputs(outputs);\n      }\n\n      const context = new ExecutionContext(_this2.weightMap, tensorArrayMap, tensorListMap, _this2.functionExecutorMap); // Graph with control flow op requires runtime evaluation of the execution\n      // order, while without control flow the execution order is pre-determined\n      // in the compile method.\n\n      const tensorMap = yield _this2.executeWithControlFlow(inputs, context, outputs, isFunctionExecution);\n      const results = outputs.map(name => getTensor(name, tensorMap, context)); // dispose all the intermediate tensors\n\n      const outputIds = results.map(t => t.id);\n      const inputIds = Object.keys(inputs).map(name => inputs[name].id);\n      const keepIds = new Set([...outputIds, ...inputIds, ..._this2.weightIds]);\n      Object.keys(tensorMap).forEach(key => {\n        const tensorArray = tensorMap[key];\n        tensorArray.forEach(tensor => {\n          if (tensor && !tensor.isDisposed && !keepIds.has(tensor.id)) {\n            tensor.dispose();\n          }\n        });\n      }); // dispose the context for the root executor\n\n      if (_this2.parent == null) {\n        context.dispose(keepIds);\n      }\n\n      return results;\n    })();\n  }\n\n  executeFunctionAsync(inputs, tensorArrayMap, tensorListMap) {\n    var _this3 = this;\n\n    return _asyncToGenerator(function* () {\n      const mappedInputs = inputs.reduce((map, tensor, index) => {\n        map[_this3.inputs[index].name] = tensor;\n        return map;\n      }, {});\n      return _this3._executeAsync(mappedInputs, _this3.outputNodes, true, tensorArrayMap, tensorListMap);\n    })();\n  }\n  /**\n   * When there are control flow nodes in the graph, the graph execution use\n   * ExecutionContext to keep track of the frames and loop iterators.\n   * @param inputs placeholder tensors for the graph.\n   * @param context the execution context object for current execution.\n   * @param outputNames Optional. output node name from the Tensorflow model,\n   * if no outputs are specified, the default outputs of the model would be\n   * used. You can inspect intermediate nodes of the model by adding them to the\n   * outputs array.\n   * @param isFunctionExecution Flag for executing a function.\n   */\n\n\n  executeWithControlFlow(inputs, context, outputNames, isFunctionExecution) {\n    var _this4 = this;\n\n    return _asyncToGenerator(function* () {\n      const names = Object.keys(inputs);\n      const inputNodes = names.map(name => _this4.graph.nodes[parseNodeName(name)[0]]);\n      const outputNodeNames = outputNames.map(name => parseNodeName(name)[0]);\n      let outputNodes = outputNodeNames.map(name => _this4.graph.nodes[name]); // If no outputs are specified, then use the default outputs of the model.\n\n      if (outputNodes.length === 0) {\n        outputNodes = _this4._outputs;\n      }\n\n      const {\n        usedNodes,\n        missingInputs,\n        dynamicNode,\n        syncInputs\n      } = getExecutionSubgraph(inputs, outputNodes, _this4.weightMap, _this4._initNodes); // First nodes to execute include inputNodes, weights, and initNodes.\n\n      const stack = [...inputNodes, ..._this4.graph.weights, ...(_this4._initNodes || [])].map(node => {\n        return {\n          node,\n          contexts: context.currentContext\n        };\n      });\n      const tensorsMap = Object.assign({}, _this4.weightMap);\n      Object.keys(inputs).forEach(name => {\n        const [nodeName, index] = parseNodeName(name);\n        const tensors = [];\n        tensors[index] = inputs[name];\n        tensorsMap[nodeName] = tensors;\n      });\n      const intermediateTensorConsumerCount = {};\n\n      const tensorsToKeep = _this4.getFrozenTensorIds(tensorsMap);\n\n      const added = {};\n\n      while (stack.length > 0) {\n        const promises = _this4.processStack(inputNodes, stack, context, tensorsMap, added, tensorsToKeep, outputNodeNames, intermediateTensorConsumerCount, usedNodes);\n\n        yield Promise.all(promises);\n      }\n\n      if (dynamicNode == null && !isFunctionExecution) {\n        console.warn(`This model execution did not contain any nodes with control flow ` + `or dynamic output shapes. You can use model.execute() instead.`);\n      }\n\n      const missingOutputs = outputNodes.filter(node => !isControlFlow(node) && !getTensor(node.name, tensorsMap, context)).map(node => node.name);\n\n      if (missingOutputs.length > 0) {\n        let alternativeMsg = '';\n\n        if (dynamicNode != null) {\n          alternativeMsg = `Alternatively, to avoid the dynamic ops, use model.execute() ` + `and specify the inputs [${syncInputs}]`;\n        }\n\n        throw new Error(`Cannot compute the outputs [${missingOutputs}] from the provided ` + `inputs [${names}]. Consider providing the following inputs: ` + `[${missingInputs}]. ${alternativeMsg}`);\n      }\n\n      return tensorsMap;\n    })();\n  }\n\n  processStack(inputNodes, stack, context, tensorMap, added, tensorsToKeep, outputNames, intermediateTensorConsumerCount, usedNodes) {\n    const promises = [];\n\n    while (stack.length > 0) {\n      const item = stack.pop();\n      context.currentContext = item.contexts;\n      let nodeName = ''; // The tensor of the Enter op with isConstant set should be set\n      // in the parent scope, so it will be available as constant for the\n      // whole loop.\n\n      if (item.node.op === 'Enter' && getParamValue('isConstant', item.node, tensorMap, context)) {\n        [nodeName] = getNodeNameAndIndex(item.node.name, context);\n      } // only process nodes that are not in the tensorMap yet, this include\n      // inputNodes and internal initNodes.\n\n\n      if (tensorMap[item.node.name] == null) {\n        const tensors = executeOp(item.node, tensorMap, context, this._resourceManager);\n\n        if (!nodeName) {\n          [nodeName] = getNodeNameAndIndex(item.node.name, context);\n        }\n\n        const currentContext = context.currentContext;\n\n        if (util.isPromise(tensors)) {\n          promises.push(tensors.then(t => {\n            tensorMap[nodeName] = t;\n            context.currentContext = currentContext;\n            this.checkTensorForDisposal(nodeName, item.node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount);\n            this.processChildNodes(item.node, stack, context, tensorMap, added, usedNodes);\n            return t;\n          }));\n        } else {\n          tensorMap[nodeName] = tensors;\n          this.checkTensorForDisposal(nodeName, item.node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount);\n          this.processChildNodes(item.node, stack, context, tensorMap, added, usedNodes);\n        }\n      } else {\n        this.processChildNodes(item.node, stack, context, tensorMap, added, usedNodes);\n      }\n    }\n\n    return promises;\n  }\n\n  processChildNodes(node, stack, context, tensorMap, added, usedNodes) {\n    node.children.forEach(childNode => {\n      const [nodeName] = getNodeNameAndIndex(childNode.name, context);\n\n      if (added[nodeName] || !usedNodes.has(childNode.name)) {\n        return;\n      } // Merge op can be pushed if any of its inputs has value.\n\n\n      if (childNode.op === 'Merge') {\n        if (childNode.inputNames.some(name => {\n          return !!getTensor(name, tensorMap, context);\n        })) {\n          added[nodeName] = true;\n          stack.push({\n            contexts: context.currentContext,\n            node: childNode\n          });\n        }\n      } else // Otherwise all inputs must to have value.\n        if (childNode.inputNames.every(name => {\n          return !!getTensor(name, tensorMap, context);\n        })) {\n          added[nodeName] = true;\n          stack.push({\n            contexts: context.currentContext,\n            node: childNode\n          });\n        }\n    });\n  }\n  /**\n   * Releases the memory used by the weight tensors.\n   */\n\n\n  dispose() {\n    Object.keys(this.weightMap).forEach(key => this.weightMap[key].forEach(tensor => tensor.dispose()));\n  }\n\n  checkInputShapeAndType(inputs) {\n    Object.keys(inputs).forEach(name => {\n      const input = inputs[name];\n      const [nodeName] = parseNodeName(name);\n      const node = this.graph.nodes[nodeName];\n\n      if (node.attrParams['shape'] && node.attrParams['shape'].value) {\n        const shape = node.attrParams['shape'].value;\n        const match = shape.length === input.shape.length && input.shape.every((dim, index) => shape[index] === -1 || shape[index] === dim);\n        util.assert(match, () => `The shape of dict['${node.name}'] provided in ` + `model.execute(dict) must be [${shape}], but was ` + `[${input.shape}]`);\n      }\n\n      if (node.attrParams['dtype'] && node.attrParams['dtype'].value) {\n        util.assert(input.dtype === node.attrParams['dtype'].value, () => `The dtype of dict['${node.name}'] provided in ` + `model.execute(dict) must be ` + `${node.attrParams['dtype'].value}, but was ${input.dtype}`);\n      }\n    });\n  }\n\n  mapInputs(inputs) {\n    const result = {};\n\n    for (const inputName in inputs) {\n      if (this._signature != null && this._signature.inputs != null && this._signature.inputs[inputName] != null) {\n        const tensor = this._signature.inputs[inputName];\n        result[tensor.name] = inputs[inputName];\n      } else {\n        result[inputName] = inputs[inputName];\n      }\n    }\n\n    return result;\n  }\n\n  checkInputs(inputs) {\n    const notInGraph = Object.keys(inputs).filter(name => {\n      const [nodeName] = parseNodeName(name);\n      return this.graph.nodes[nodeName] == null;\n    });\n\n    if (notInGraph.length > 0) {\n      throw new Error(`The dict provided in model.execute(dict) has ` + `keys: [${notInGraph}] that are not part of graph`);\n    }\n  }\n\n  mapOutputs(outputs) {\n    return outputs.map(name => {\n      if (this._signature != null && this._signature.outputs != null && this._signature.outputs[name] != null) {\n        const tensor = this._signature.outputs[name];\n        return tensor.name;\n      }\n\n      return name;\n    }, {});\n  }\n\n  checkOutputs(outputs) {\n    outputs.forEach(name => {\n      const [normalizedName] = parseNodeName(name);\n\n      if (!this.graph.nodes[normalizedName]) {\n        throw new Error(`The output '${name}' is not found in the graph`);\n      }\n    });\n  }\n\n}","map":{"version":3,"sources":["/Users/ryanliang/Downloads/main_movir_picker/node_modules/@tensorflow/tfjs-converter/dist/executor/graph_executor.js"],"names":["tidy","util","getNodeNameAndIndex","getParamValue","getTensor","getTensorsForCurrentContenxt","parseNodeName","executeOp","ExecutionContext","getExecutionSubgraph","getNodesInTopologicalOrder","isControlFlow","GraphExecutor","constructor","graph","parent","compiledMap","Map","_weightMap","SEPERATOR","_functions","_functionExecutorMap","_outputs","outputs","_inputs","inputs","_initNodes","initNodes","_signature","signature","functions","Object","keys","forEach","name","weightIds","_weightIds","functionExecutorMap","weightMap","map","key","tensor","id","concat","resourceManager","_resourceManager","node","shape","attrParams","value","undefined","dtype","inputNodes","signatureKey","outputNodes","defaultOutput","reduce","getCompilationKey","sortedInputs","sort","sortedOutputs","join","compile","executionInfo","missingInputs","dynamicNode","syncInputs","Error","op","length","outNames","n","inNames","execute","mapInputs","names","checkInputs","checkInputShapeAndType","mapOutputs","checkOutputs","nodes","outputNodeNames","compilationKey","orderedNodes","get","set","tensorArrayMap","tensorListMap","context","tensorsMap","assign","nodeName","index","tensors","tensorsToKeep","getFrozenTensorIds","intermediateTensorConsumerCount","i","isPromise","checkTensorForDisposal","dispose","tensorMap","ids","apply","Set","outputNames","category","indexOf","children","input","has","count","executeAsync","_executeAsync","isFunctionExecution","executeWithControlFlow","results","outputIds","t","inputIds","keepIds","tensorArray","isDisposed","executeFunctionAsync","mappedInputs","usedNodes","stack","weights","contexts","currentContext","added","promises","processStack","Promise","all","console","warn","missingOutputs","filter","alternativeMsg","item","pop","push","then","processChildNodes","childNode","inputNames","some","every","match","dim","assert","result","inputName","notInGraph","normalizedName"],"mappings":";;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASA,IAAT,EAAeC,IAAf,QAA2B,uBAA3B;AACA,SAASC,mBAAT,EAA8BC,aAA9B,EAA6CC,SAA7C,EAAwDC,4BAAxD,EAAsFC,aAAtF,QAA2G,+BAA3G;AACA,SAASC,SAAT,QAA0B,kCAA1B;AACA,SAASC,gBAAT,QAAiC,qBAAjC;AACA,SAASC,oBAAT,EAA+BC,0BAA/B,EAA2DC,aAA3D,QAAgF,kBAAhF;AACA,OAAO,MAAMC,aAAN,CAAoB;AACvB;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACIC,EAAAA,WAAW,CAACC,KAAD,EAAQC,MAAR,EAAgB;AACvB,SAAKD,KAAL,GAAaA,KAAb;AACA,SAAKC,MAAL,GAAcA,MAAd;AACA,SAAKC,WAAL,GAAmB,IAAIC,GAAJ,EAAnB;AACA,SAAKC,UAAL,GAAkB,EAAlB;AACA,SAAKC,SAAL,GAAiB,GAAjB;AACA,SAAKC,UAAL,GAAkB,EAAlB;AACA,SAAKC,oBAAL,GAA4B,EAA5B;AACA,SAAKC,QAAL,GAAgBR,KAAK,CAACS,OAAtB;AACA,SAAKC,OAAL,GAAeV,KAAK,CAACW,MAArB;AACA,SAAKC,UAAL,GAAkBZ,KAAK,CAACa,SAAxB;AACA,SAAKC,UAAL,GAAkBd,KAAK,CAACe,SAAxB;AACA,SAAKT,UAAL,GAAkBN,KAAK,CAACgB,SAAxB,CAZuB,CAavB;;AACA,QAAIhB,KAAK,CAACgB,SAAN,IAAmB,IAAvB,EAA6B;AACzBC,MAAAA,MAAM,CAACC,IAAP,CAAYlB,KAAK,CAACgB,SAAlB,EAA6BG,OAA7B,CAAqCC,IAAI,IAAI;AACzC,aAAKb,oBAAL,CAA0Ba,IAA1B,IACI,IAAItB,aAAJ,CAAkBE,KAAK,CAACgB,SAAN,CAAgBI,IAAhB,CAAlB,EAAyC,IAAzC,CADJ;AAEH,OAHD;AAIH;AACJ;;AACY,MAATC,SAAS,GAAG;AACZ,WAAO,KAAKpB,MAAL,GAAc,KAAKA,MAAL,CAAYoB,SAA1B,GAAsC,KAAKC,UAAlD;AACH;;AACsB,MAAnBC,mBAAmB,GAAG;AACtB,WAAO,KAAKtB,MAAL,GAAc,KAAKA,MAAL,CAAYsB,mBAA1B,GACH,KAAKhB,oBADT;AAEH;;AACY,MAATiB,SAAS,GAAG;AACZ,WAAO,KAAKvB,MAAL,GAAc,KAAKA,MAAL,CAAYuB,SAA1B,GAAsC,KAAKpB,UAAlD;AACH;;AACY,MAAToB,SAAS,CAACA,SAAD,EAAY;AACrB,UAAMH,SAAS,GAAGJ,MAAM,CAACC,IAAP,CAAYM,SAAZ,EAAuBC,GAAvB,CAA2BC,GAAG,IAAIF,SAAS,CAACE,GAAD,CAAT,CAAeD,GAAf,CAAmBE,MAAM,IAAIA,MAAM,CAACC,EAApC,CAAlC,CAAlB;AACA,SAAKN,UAAL,GAAkB,GAAGO,MAAH,CAAU,GAAGR,SAAb,CAAlB;AACA,SAAKjB,UAAL,GAAkBoB,SAAlB;AACH;AACD;AACJ;AACA;AACA;;;AACuB,MAAfM,eAAe,CAACA,eAAD,EAAkB;AACjC,SAAKC,gBAAL,GAAwBD,eAAxB;AACH;;AACS,MAANnB,MAAM,GAAG;AACT,WAAO,KAAKD,OAAL,CAAae,GAAb,CAAiBO,IAAI,IAAI;AAC5B,aAAO;AACHZ,QAAAA,IAAI,EAAEY,IAAI,CAACZ,IADR;AAEHa,QAAAA,KAAK,EAAED,IAAI,CAACE,UAAL,CAAgB,OAAhB,IACHF,IAAI,CAACE,UAAL,CAAgB,OAAhB,EAAyBC,KADtB,GAEHC,SAJD;AAKHC,QAAAA,KAAK,EAAEL,IAAI,CAACE,UAAL,CAAgB,OAAhB,IACHF,IAAI,CAACE,UAAL,CAAgB,OAAhB,EAAyBC,KADtB,GAEHC;AAPD,OAAP;AASH,KAVM,CAAP;AAWH;;AACU,MAAP3B,OAAO,GAAG;AACV,WAAO,KAAKD,QAAL,CAAciB,GAAd,CAAkBO,IAAI,IAAI;AAC7B,aAAO;AACHZ,QAAAA,IAAI,EAAEY,IAAI,CAACZ,IADR;AAEHa,QAAAA,KAAK,EAAED,IAAI,CAACE,UAAL,CAAgB,OAAhB,IACHF,IAAI,CAACE,UAAL,CAAgB,OAAhB,EAAyBC,KADtB,GAEHC,SAJD;AAKHC,QAAAA,KAAK,EAAEL,IAAI,CAACE,UAAL,CAAgB,OAAhB,IACHF,IAAI,CAACE,UAAL,CAAgB,OAAhB,EAAyBC,KADtB,GAEHC;AAPD,OAAP;AASH,KAVM,CAAP;AAWH;;AACa,MAAVE,UAAU,GAAG;AACb,WAAO,KAAK5B,OAAL,CAAae,GAAb,CAAiBO,IAAI,IAAIA,IAAI,CAACO,YAAL,IAAqBP,IAAI,CAACZ,IAAnD,CAAP;AACH;;AACc,MAAXoB,WAAW,GAAG;AACd,WAAO,KAAKhC,QAAL,CAAciB,GAAd,CAAmBO,IAAD,IAAU;AAC/B,YAAMZ,IAAI,GAAGY,IAAI,CAACO,YAAL,IAAqBP,IAAI,CAACZ,IAAvC;AACA,aAAOY,IAAI,CAACS,aAAL,GAAuB,GAAErB,IAAK,IAAGY,IAAI,CAACS,aAAc,EAApD,GAAyDrB,IAAhE;AACH,KAHM,CAAP;AAIH;;AACY,MAATJ,SAAS,GAAG;AACZ,WAAOC,MAAM,CAACC,IAAP,CAAY,KAAKZ,UAAjB,EAA6BoC,MAA7B,CAAoC,CAACjB,GAAD,EAAMC,GAAN,KAAc;AACrDD,MAAAA,GAAG,CAACC,GAAD,CAAH,GAAW,KAAKpB,UAAL,CAAgBoB,GAAhB,EAAqBX,SAAhC;AACA,aAAOU,GAAP;AACH,KAHM,EAGJ,EAHI,CAAP;AAIH;;AACDkB,EAAAA,iBAAiB,CAAChC,MAAD,EAASF,OAAT,EAAkB;AAC/B,UAAMmC,YAAY,GAAGjC,MAAM,CAACc,GAAP,CAAWO,IAAI,IAAIA,IAAI,CAACZ,IAAxB,EAA8ByB,IAA9B,EAArB;AACA,UAAMC,aAAa,GAAGrC,OAAO,CAACgB,GAAR,CAAYO,IAAI,IAAIA,IAAI,CAACZ,IAAzB,EAA+ByB,IAA/B,EAAtB;AACA,WAAOD,YAAY,CAACG,IAAb,CAAkB,KAAK1C,SAAvB,IAAoC,IAApC,GACHyC,aAAa,CAACC,IAAd,CAAmB,KAAK1C,SAAxB,CADJ;AAEH;AACD;AACJ;AACA;AACA;;;AACI2C,EAAAA,OAAO,CAACrC,MAAD,EAASF,OAAT,EAAkB;AACrB,UAAMwC,aAAa,GAAGtD,oBAAoB,CAACgB,MAAD,EAASF,OAAT,EAAkB,KAAKe,SAAvB,EAAkC,KAAKZ,UAAvC,CAA1C;AACA,UAAM;AAAEsC,MAAAA,aAAF;AAAiBC,MAAAA,WAAjB;AAA8BC,MAAAA;AAA9B,QAA6CH,aAAnD;;AACA,QAAIE,WAAW,IAAI,IAAnB,EAAyB;AACrB,YAAM,IAAIE,KAAJ,CAAW,qCAAoCF,WAAW,CAAC/B,IAAK,eAAtD,GACX,mBAAkB+B,WAAW,CAACG,EAAG,gBADtB,GAEX,4DAFW,GAGX,oCAAmCF,UAAW,GAH7C,CAAN;AAIH;;AACD,QAAIF,aAAa,CAACK,MAAd,GAAuB,CAA3B,EAA8B;AAC1B,YAAMC,QAAQ,GAAG/C,OAAO,CAACgB,GAAR,CAAYgC,CAAC,IAAIA,CAAC,CAACrC,IAAnB,CAAjB;AACA,YAAMsC,OAAO,GAAGzC,MAAM,CAACC,IAAP,CAAYP,MAAZ,CAAhB;AACA,YAAM,IAAI0C,KAAJ,CAAW,+BAA8BG,QAAS,6BAAxC,GACX,IAAGE,OAAQ,qCAAoCR,aAAc,GAD5D,CAAN;AAEH;;AACD,WAAOtD,0BAA0B,CAAC,KAAKI,KAAN,EAAa,KAAKwB,SAAlB,EAA6ByB,aAA7B,CAAjC;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACIU,EAAAA,OAAO,CAAChD,MAAD,EAASF,OAAT,EAAkB;AACrBE,IAAAA,MAAM,GAAG,KAAKiD,SAAL,CAAejD,MAAf,CAAT;AACA,UAAMkD,KAAK,GAAG5C,MAAM,CAACC,IAAP,CAAYP,MAAZ,EAAoBkC,IAApB,EAAd;AACA,SAAKiB,WAAL,CAAiBnD,MAAjB;AACA,SAAKoD,sBAAL,CAA4BpD,MAA5B;AACAF,IAAAA,OAAO,GAAG,KAAKuD,UAAL,CAAgBvD,OAAhB,CAAV;AACA,SAAKwD,YAAL,CAAkBxD,OAAlB;AACA,UAAM6B,UAAU,GAAGuB,KAAK,CAACpC,GAAN,CAAUL,IAAI,IAAI,KAAKpB,KAAL,CAAWkE,KAAX,CAAiB1E,aAAa,CAAC4B,IAAD,CAAb,CAAoB,CAApB,CAAjB,CAAlB,CAAnB;AACA,UAAM+C,eAAe,GAAG1D,OAAO,CAACgB,GAAR,CAAYL,IAAI,IAAI5B,aAAa,CAAC4B,IAAD,CAAb,CAAoB,CAApB,CAApB,CAAxB;AACA,QAAIoB,WAAW,GAAG2B,eAAe,CAAC1C,GAAhB,CAAoBL,IAAI,IAAI,KAAKpB,KAAL,CAAWkE,KAAX,CAAiB9C,IAAjB,CAA5B,CAAlB,CATqB,CAUrB;;AACA,QAAIoB,WAAW,CAACe,MAAZ,KAAuB,CAA3B,EAA8B;AAC1Bf,MAAAA,WAAW,GAAG,KAAKhC,QAAnB;AACH;;AACD,UAAM4D,cAAc,GAAG,KAAKzB,iBAAL,CAAuBL,UAAvB,EAAmCE,WAAnC,CAAvB,CAdqB,CAerB;;AACA,QAAI6B,YAAY,GAAG,KAAKnE,WAAL,CAAiBoE,GAAjB,CAAqBF,cAArB,CAAnB;;AACA,QAAIC,YAAY,IAAI,IAApB,EAA0B;AACtBA,MAAAA,YAAY,GAAG,KAAKrB,OAAL,CAAarC,MAAb,EAAqB6B,WAArB,CAAf;AACA,WAAKtC,WAAL,CAAiBqE,GAAjB,CAAqBH,cAArB,EAAqCC,YAArC;AACH;;AACD,UAAMG,cAAc,GAAG,EAAvB;AACA,UAAMC,aAAa,GAAG,EAAtB;AACA,WAAOvF,IAAI,CAAC,MAAM;AACd,YAAMwF,OAAO,GAAG,IAAIhF,gBAAJ,CAAqB,KAAK8B,SAA1B,EAAqCgD,cAArC,EAAqDC,aAArD,EAAoE,KAAKlD,mBAAzE,CAAhB;AACA,YAAMoD,UAAU,GAAG1D,MAAM,CAAC2D,MAAP,CAAc,EAAd,EAAkB,KAAKpD,SAAvB,CAAnB;AACAP,MAAAA,MAAM,CAACC,IAAP,CAAYP,MAAZ,EAAoBQ,OAApB,CAA4BC,IAAI,IAAI;AAChC,cAAM,CAACyD,QAAD,EAAWC,KAAX,IAAoBtF,aAAa,CAAC4B,IAAD,CAAvC;AACA,cAAM2D,OAAO,GAAG,EAAhB;AACAA,QAAAA,OAAO,CAACD,KAAD,CAAP,GAAiBnE,MAAM,CAACS,IAAD,CAAvB;AACAuD,QAAAA,UAAU,CAACE,QAAD,CAAV,GAAuBE,OAAvB;AACH,OALD;AAMA,YAAMC,aAAa,GAAG,KAAKC,kBAAL,CAAwBN,UAAxB,CAAtB;AACA,YAAMO,+BAA+B,GAAG,EAAxC;;AACA,WAAK,IAAIC,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGd,YAAY,CAACd,MAAjC,EAAyC4B,CAAC,EAA1C,EAA8C;AAC1C,cAAMnD,IAAI,GAAGqC,YAAY,CAACc,CAAD,CAAzB;;AACA,YAAI,CAACR,UAAU,CAAC3C,IAAI,CAACZ,IAAN,CAAf,EAA4B;AACxB,gBAAM2D,OAAO,GAAGtF,SAAS,CAACuC,IAAD,EAAO2C,UAAP,EAAmBD,OAAnB,EAA4B,KAAK3C,gBAAjC,CAAzB;;AACA,cAAI5C,IAAI,CAACiG,SAAL,CAAeL,OAAf,CAAJ,EAA6B;AACzB,kBAAM,IAAI1B,KAAJ,CAAW,4BAA2BrB,IAAI,CAACsB,EAAG,wBAApC,GACX,0CADC,CAAN;AAEH;;AACDqB,UAAAA,UAAU,CAAC3C,IAAI,CAACZ,IAAN,CAAV,GAAwB2D,OAAxB;AACA,eAAKM,sBAAL,CAA4BrD,IAAI,CAACZ,IAAjC,EAAuCY,IAAvC,EAA6C2C,UAA7C,EAAyDD,OAAzD,EAAkEM,aAAlE,EAAiFb,eAAjF,EAAkGe,+BAAlG;AACH;AACJ,OAtBa,CAuBd;;;AACA,UAAI,KAAKjF,MAAL,IAAe,IAAnB,EAAyB;AACrByE,QAAAA,OAAO,CAACY,OAAR,CAAgBN,aAAhB;AACH;;AACD,aAAOvE,OAAO,CAACgB,GAAR,CAAYL,IAAI,IAAI9B,SAAS,CAAC8B,IAAD,EAAOuD,UAAP,EAAmBD,OAAnB,CAA7B,CAAP;AACH,KA5BU,CAAX;AA6BH;;AACDO,EAAAA,kBAAkB,CAACM,SAAD,EAAY;AAC1B,UAAMC,GAAG,GAAG,GAAG3D,MAAH,CAAU4D,KAAV,CAAgB,EAAhB,EAAoBxE,MAAM,CAACC,IAAP,CAAYqE,SAAZ,EAC3B9D,GAD2B,CACvBC,GAAG,IAAI6D,SAAS,CAAC7D,GAAD,CADO,EAE3BD,GAF2B,CAEvBsD,OAAO,IAAIA,OAAO,CAACtD,GAAR,CAAYE,MAAM,IAAIA,MAAM,CAACC,EAA7B,CAFY,CAApB,CAAZ;AAGA,WAAO,IAAI8D,GAAJ,CAAQF,GAAR,CAAP;AACH;;AACDH,EAAAA,sBAAsB,CAACR,QAAD,EAAW7C,IAAX,EAAiBuD,SAAjB,EAA4Bb,OAA5B,EAAqCM,aAArC,EAAoDW,WAApD,EAAiET,+BAAjE,EAAkG;AACpH;AACA;AACA,QAAIlD,IAAI,CAAC4D,QAAL,KAAkB,SAAlB,IAA+BD,WAAW,CAACE,OAAZ,CAAoBhB,QAApB,MAAkC,CAAC,CAAtE,EAAyE;AACrE;AACH;;AACDU,IAAAA,SAAS,CAACV,QAAD,CAAT,CAAoB1D,OAApB,CAA4BQ,MAAM,IAAI;AAClC,UAAIA,MAAM,IAAI,IAAd,EAAoB;AAChBuD,QAAAA,+BAA+B,CAACvD,MAAM,CAACC,EAAR,CAA/B,GACI,CAACsD,+BAA+B,CAACvD,MAAM,CAACC,EAAR,CAA/B,IAA8C,CAA/C,IACII,IAAI,CAAC8D,QAAL,CAAcvC,MAFtB;AAGH;AACJ,KAND;AAOAvB,IAAAA,IAAI,CAACrB,MAAL,CAAYQ,OAAZ,CAAoB4E,KAAK,IAAI;AACzB;AACA;AACA,UAAIA,KAAK,CAACH,QAAN,KAAmB,SAAvB,EAAkC;AAC9B,cAAMb,OAAO,GAAGxF,4BAA4B,CAACwG,KAAK,CAAC3E,IAAP,EAAamE,SAAb,EAAwBb,OAAxB,CAA5C;;AACA,YAAIK,OAAO,IAAI,IAAf,EAAqB;AACjBA,UAAAA,OAAO,CAAC5D,OAAR,CAAgBQ,MAAM,IAAI;AACtB,gBAAIA,MAAM,IAAI,CAACqD,aAAa,CAACgB,GAAd,CAAkBrE,MAAM,CAACC,EAAzB,CAAf,EAA6C;AACzC,oBAAMqE,KAAK,GAAGf,+BAA+B,CAACvD,MAAM,CAACC,EAAR,CAA7C;;AACA,kBAAIqE,KAAK,KAAK,CAAd,EAAiB;AACbtE,gBAAAA,MAAM,CAAC2D,OAAP;AACA,uBAAOJ,+BAA+B,CAACvD,MAAM,CAACC,EAAR,CAAtC;AACH,eAHD,MAIK,IAAIqE,KAAK,IAAI,IAAb,EAAmB;AACpB;AACA;AACAf,gBAAAA,+BAA+B,CAACvD,MAAM,CAACC,EAAR,CAA/B;AACH;AACJ;AACJ,WAbD;AAcH;AACJ;AACJ,KAtBD;AAuBH;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACUsE,EAAAA,YAAY,CAACvF,MAAD,EAASF,OAAT,EAAkB;AAAA;;AAAA;AAChC,aAAO,KAAI,CAAC0F,aAAL,CAAmBxF,MAAnB,EAA2BF,OAA3B,CAAP;AADgC;AAEnC;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACU0F,EAAAA,aAAa,CAACxF,MAAD,EAASF,OAAT,EAAkB2F,mBAAmB,GAAG,KAAxC,EAA+C5B,cAAc,GAAG,EAAhE,EAAoEC,aAAa,GAAG,EAApF,EAAwF;AAAA;;AAAA;AACvG,UAAI,CAAC2B,mBAAL,EAA0B;AACtBzF,QAAAA,MAAM,GAAG,MAAI,CAACiD,SAAL,CAAejD,MAAf,CAAT;;AACA,QAAA,MAAI,CAACmD,WAAL,CAAiBnD,MAAjB;;AACA,QAAA,MAAI,CAACoD,sBAAL,CAA4BpD,MAA5B;;AACAF,QAAAA,OAAO,GAAG,MAAI,CAACuD,UAAL,CAAgBvD,OAAhB,CAAV;;AACA,QAAA,MAAI,CAACwD,YAAL,CAAkBxD,OAAlB;AACH;;AACD,YAAMiE,OAAO,GAAG,IAAIhF,gBAAJ,CAAqB,MAAI,CAAC8B,SAA1B,EAAqCgD,cAArC,EAAqDC,aAArD,EAAoE,MAAI,CAAClD,mBAAzE,CAAhB,CARuG,CASvG;AACA;AACA;;AACA,YAAMgE,SAAS,SAAS,MAAI,CAACc,sBAAL,CAA4B1F,MAA5B,EAAoC+D,OAApC,EAA6CjE,OAA7C,EAAsD2F,mBAAtD,CAAxB;AACA,YAAME,OAAO,GAAG7F,OAAO,CAACgB,GAAR,CAAYL,IAAI,IAAI9B,SAAS,CAAC8B,IAAD,EAAOmE,SAAP,EAAkBb,OAAlB,CAA7B,CAAhB,CAbuG,CAcvG;;AACA,YAAM6B,SAAS,GAAGD,OAAO,CAAC7E,GAAR,CAAY+E,CAAC,IAAIA,CAAC,CAAC5E,EAAnB,CAAlB;AACA,YAAM6E,QAAQ,GAAGxF,MAAM,CAACC,IAAP,CAAYP,MAAZ,EAAoBc,GAApB,CAAwBL,IAAI,IAAIT,MAAM,CAACS,IAAD,CAAN,CAAaQ,EAA7C,CAAjB;AACA,YAAM8E,OAAO,GAAG,IAAIhB,GAAJ,CAAQ,CAAC,GAAGa,SAAJ,EAAe,GAAGE,QAAlB,EAA4B,GAAG,MAAI,CAACpF,SAApC,CAAR,CAAhB;AACAJ,MAAAA,MAAM,CAACC,IAAP,CAAYqE,SAAZ,EAAuBpE,OAAvB,CAA+BO,GAAG,IAAI;AAClC,cAAMiF,WAAW,GAAGpB,SAAS,CAAC7D,GAAD,CAA7B;AACAiF,QAAAA,WAAW,CAACxF,OAAZ,CAAoBQ,MAAM,IAAI;AAC1B,cAAIA,MAAM,IAAI,CAACA,MAAM,CAACiF,UAAlB,IAAgC,CAACF,OAAO,CAACV,GAAR,CAAYrE,MAAM,CAACC,EAAnB,CAArC,EAA6D;AACzDD,YAAAA,MAAM,CAAC2D,OAAP;AACH;AACJ,SAJD;AAKH,OAPD,EAlBuG,CA0BvG;;AACA,UAAI,MAAI,CAACrF,MAAL,IAAe,IAAnB,EAAyB;AACrByE,QAAAA,OAAO,CAACY,OAAR,CAAgBoB,OAAhB;AACH;;AACD,aAAOJ,OAAP;AA9BuG;AA+B1G;;AACKO,EAAAA,oBAAoB,CAAClG,MAAD,EAAS6D,cAAT,EAAyBC,aAAzB,EAAwC;AAAA;;AAAA;AAC9D,YAAMqC,YAAY,GAAGnG,MAAM,CAAC+B,MAAP,CAAc,CAACjB,GAAD,EAAME,MAAN,EAAcmD,KAAd,KAAwB;AACvDrD,QAAAA,GAAG,CAAC,MAAI,CAACd,MAAL,CAAYmE,KAAZ,EAAmB1D,IAApB,CAAH,GAA+BO,MAA/B;AACA,eAAOF,GAAP;AACH,OAHoB,EAGlB,EAHkB,CAArB;AAIA,aAAO,MAAI,CAAC0E,aAAL,CAAmBW,YAAnB,EAAiC,MAAI,CAACtE,WAAtC,EAAmD,IAAnD,EAAyDgC,cAAzD,EAAyEC,aAAzE,CAAP;AAL8D;AAMjE;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACU4B,EAAAA,sBAAsB,CAAC1F,MAAD,EAAS+D,OAAT,EAAkBiB,WAAlB,EAA+BS,mBAA/B,EAAoD;AAAA;;AAAA;AAC5E,YAAMvC,KAAK,GAAG5C,MAAM,CAACC,IAAP,CAAYP,MAAZ,CAAd;AACA,YAAM2B,UAAU,GAAGuB,KAAK,CAACpC,GAAN,CAAUL,IAAI,IAAI,MAAI,CAACpB,KAAL,CAAWkE,KAAX,CAAiB1E,aAAa,CAAC4B,IAAD,CAAb,CAAoB,CAApB,CAAjB,CAAlB,CAAnB;AACA,YAAM+C,eAAe,GAAGwB,WAAW,CAAClE,GAAZ,CAAgBL,IAAI,IAAI5B,aAAa,CAAC4B,IAAD,CAAb,CAAoB,CAApB,CAAxB,CAAxB;AACA,UAAIoB,WAAW,GAAG2B,eAAe,CAAC1C,GAAhB,CAAoBL,IAAI,IAAI,MAAI,CAACpB,KAAL,CAAWkE,KAAX,CAAiB9C,IAAjB,CAA5B,CAAlB,CAJ4E,CAK5E;;AACA,UAAIoB,WAAW,CAACe,MAAZ,KAAuB,CAA3B,EAA8B;AAC1Bf,QAAAA,WAAW,GAAG,MAAI,CAAChC,QAAnB;AACH;;AACD,YAAM;AAAEuG,QAAAA,SAAF;AAAa7D,QAAAA,aAAb;AAA4BC,QAAAA,WAA5B;AAAyCC,QAAAA;AAAzC,UAAwDzD,oBAAoB,CAACgB,MAAD,EAAS6B,WAAT,EAAsB,MAAI,CAAChB,SAA3B,EAAsC,MAAI,CAACZ,UAA3C,CAAlF,CAT4E,CAU5E;;AACA,YAAMoG,KAAK,GAAG,CACV,GAAG1E,UADO,EACK,GAAG,MAAI,CAACtC,KAAL,CAAWiH,OADnB,EAC4B,IAAI,MAAI,CAACrG,UAAL,IAAmB,EAAvB,CAD5B,EAEZa,GAFY,CAERO,IAAI,IAAI;AACV,eAAO;AAAEA,UAAAA,IAAF;AAAQkF,UAAAA,QAAQ,EAAExC,OAAO,CAACyC;AAA1B,SAAP;AACH,OAJa,CAAd;AAKA,YAAMxC,UAAU,GAAG1D,MAAM,CAAC2D,MAAP,CAAc,EAAd,EAAkB,MAAI,CAACpD,SAAvB,CAAnB;AACAP,MAAAA,MAAM,CAACC,IAAP,CAAYP,MAAZ,EAAoBQ,OAApB,CAA4BC,IAAI,IAAI;AAChC,cAAM,CAACyD,QAAD,EAAWC,KAAX,IAAoBtF,aAAa,CAAC4B,IAAD,CAAvC;AACA,cAAM2D,OAAO,GAAG,EAAhB;AACAA,QAAAA,OAAO,CAACD,KAAD,CAAP,GAAiBnE,MAAM,CAACS,IAAD,CAAvB;AACAuD,QAAAA,UAAU,CAACE,QAAD,CAAV,GAAuBE,OAAvB;AACH,OALD;AAMA,YAAMG,+BAA+B,GAAG,EAAxC;;AACA,YAAMF,aAAa,GAAG,MAAI,CAACC,kBAAL,CAAwBN,UAAxB,CAAtB;;AACA,YAAMyC,KAAK,GAAG,EAAd;;AACA,aAAOJ,KAAK,CAACzD,MAAN,GAAe,CAAtB,EAAyB;AACrB,cAAM8D,QAAQ,GAAG,MAAI,CAACC,YAAL,CAAkBhF,UAAlB,EAA8B0E,KAA9B,EAAqCtC,OAArC,EAA8CC,UAA9C,EAA0DyC,KAA1D,EAAiEpC,aAAjE,EAAgFb,eAAhF,EAAiGe,+BAAjG,EAAkI6B,SAAlI,CAAjB;;AACA,cAAMQ,OAAO,CAACC,GAAR,CAAYH,QAAZ,CAAN;AACH;;AACD,UAAIlE,WAAW,IAAI,IAAf,IAAuB,CAACiD,mBAA5B,EAAiD;AAC7CqB,QAAAA,OAAO,CAACC,IAAR,CAAc,mEAAD,GACR,gEADL;AAEH;;AACD,YAAMC,cAAc,GAAGnF,WAAW,CAC7BoF,MADkB,CACX5F,IAAI,IAAI,CAACnC,aAAa,CAACmC,IAAD,CAAd,IAChB,CAAC1C,SAAS,CAAC0C,IAAI,CAACZ,IAAN,EAAYuD,UAAZ,EAAwBD,OAAxB,CAFS,EAGlBjD,GAHkB,CAGdO,IAAI,IAAIA,IAAI,CAACZ,IAHC,CAAvB;;AAIA,UAAIuG,cAAc,CAACpE,MAAf,GAAwB,CAA5B,EAA+B;AAC3B,YAAIsE,cAAc,GAAG,EAArB;;AACA,YAAI1E,WAAW,IAAI,IAAnB,EAAyB;AACrB0E,UAAAA,cAAc,GACT,+DAAD,GACK,2BAA0BzE,UAAW,GAF9C;AAGH;;AACD,cAAM,IAAIC,KAAJ,CAAW,+BAA8BsE,cAAe,sBAA9C,GACX,WAAU9D,KAAM,8CADL,GAEX,IAAGX,aAAc,MAAK2E,cAAe,EAFpC,CAAN;AAGH;;AACD,aAAOlD,UAAP;AAjD4E;AAkD/E;;AACD2C,EAAAA,YAAY,CAAChF,UAAD,EAAa0E,KAAb,EAAoBtC,OAApB,EAA6Ba,SAA7B,EAAwC6B,KAAxC,EAA+CpC,aAA/C,EAA8DW,WAA9D,EAA2ET,+BAA3E,EAA4G6B,SAA5G,EAAuH;AAC/H,UAAMM,QAAQ,GAAG,EAAjB;;AACA,WAAOL,KAAK,CAACzD,MAAN,GAAe,CAAtB,EAAyB;AACrB,YAAMuE,IAAI,GAAGd,KAAK,CAACe,GAAN,EAAb;AACArD,MAAAA,OAAO,CAACyC,cAAR,GAAyBW,IAAI,CAACZ,QAA9B;AACA,UAAIrC,QAAQ,GAAG,EAAf,CAHqB,CAIrB;AACA;AACA;;AACA,UAAIiD,IAAI,CAAC9F,IAAL,CAAUsB,EAAV,KAAiB,OAAjB,IACAjE,aAAa,CAAC,YAAD,EAAeyI,IAAI,CAAC9F,IAApB,EAA0BuD,SAA1B,EAAqCb,OAArC,CADjB,EACgE;AAC5D,SAACG,QAAD,IAAazF,mBAAmB,CAAC0I,IAAI,CAAC9F,IAAL,CAAUZ,IAAX,EAAiBsD,OAAjB,CAAhC;AACH,OAVoB,CAWrB;AACA;;;AACA,UAAIa,SAAS,CAACuC,IAAI,CAAC9F,IAAL,CAAUZ,IAAX,CAAT,IAA6B,IAAjC,EAAuC;AACnC,cAAM2D,OAAO,GAAGtF,SAAS,CAACqI,IAAI,CAAC9F,IAAN,EAAYuD,SAAZ,EAAuBb,OAAvB,EAAgC,KAAK3C,gBAArC,CAAzB;;AACA,YAAI,CAAC8C,QAAL,EAAe;AACX,WAACA,QAAD,IAAazF,mBAAmB,CAAC0I,IAAI,CAAC9F,IAAL,CAAUZ,IAAX,EAAiBsD,OAAjB,CAAhC;AACH;;AACD,cAAMyC,cAAc,GAAGzC,OAAO,CAACyC,cAA/B;;AACA,YAAIhI,IAAI,CAACiG,SAAL,CAAeL,OAAf,CAAJ,EAA6B;AACzBsC,UAAAA,QAAQ,CAACW,IAAT,CAAcjD,OAAO,CAACkD,IAAR,CAAazB,CAAC,IAAI;AAC5BjB,YAAAA,SAAS,CAACV,QAAD,CAAT,GAAsB2B,CAAtB;AACA9B,YAAAA,OAAO,CAACyC,cAAR,GAAyBA,cAAzB;AACA,iBAAK9B,sBAAL,CAA4BR,QAA5B,EAAsCiD,IAAI,CAAC9F,IAA3C,EAAiDuD,SAAjD,EAA4Db,OAA5D,EAAqEM,aAArE,EAAoFW,WAApF,EAAiGT,+BAAjG;AACA,iBAAKgD,iBAAL,CAAuBJ,IAAI,CAAC9F,IAA5B,EAAkCgF,KAAlC,EAAyCtC,OAAzC,EAAkDa,SAAlD,EAA6D6B,KAA7D,EAAoEL,SAApE;AACA,mBAAOP,CAAP;AACH,WANa,CAAd;AAOH,SARD,MASK;AACDjB,UAAAA,SAAS,CAACV,QAAD,CAAT,GAAsBE,OAAtB;AACA,eAAKM,sBAAL,CAA4BR,QAA5B,EAAsCiD,IAAI,CAAC9F,IAA3C,EAAiDuD,SAAjD,EAA4Db,OAA5D,EAAqEM,aAArE,EAAoFW,WAApF,EAAiGT,+BAAjG;AACA,eAAKgD,iBAAL,CAAuBJ,IAAI,CAAC9F,IAA5B,EAAkCgF,KAAlC,EAAyCtC,OAAzC,EAAkDa,SAAlD,EAA6D6B,KAA7D,EAAoEL,SAApE;AACH;AACJ,OApBD,MAqBK;AACD,aAAKmB,iBAAL,CAAuBJ,IAAI,CAAC9F,IAA5B,EAAkCgF,KAAlC,EAAyCtC,OAAzC,EAAkDa,SAAlD,EAA6D6B,KAA7D,EAAoEL,SAApE;AACH;AACJ;;AACD,WAAOM,QAAP;AACH;;AACDa,EAAAA,iBAAiB,CAAClG,IAAD,EAAOgF,KAAP,EAActC,OAAd,EAAuBa,SAAvB,EAAkC6B,KAAlC,EAAyCL,SAAzC,EAAoD;AACjE/E,IAAAA,IAAI,CAAC8D,QAAL,CAAc3E,OAAd,CAAuBgH,SAAD,IAAe;AACjC,YAAM,CAACtD,QAAD,IAAczF,mBAAmB,CAAC+I,SAAS,CAAC/G,IAAX,EAAiBsD,OAAjB,CAAvC;;AACA,UAAI0C,KAAK,CAACvC,QAAD,CAAL,IAAmB,CAACkC,SAAS,CAACf,GAAV,CAAcmC,SAAS,CAAC/G,IAAxB,CAAxB,EAAuD;AACnD;AACH,OAJgC,CAKjC;;;AACA,UAAI+G,SAAS,CAAC7E,EAAV,KAAiB,OAArB,EAA8B;AAC1B,YAAI6E,SAAS,CAACC,UAAV,CAAqBC,IAArB,CAA0BjH,IAAI,IAAI;AAClC,iBAAO,CAAC,CAAC9B,SAAS,CAAC8B,IAAD,EAAOmE,SAAP,EAAkBb,OAAlB,CAAlB;AACH,SAFG,CAAJ,EAEI;AACA0C,UAAAA,KAAK,CAACvC,QAAD,CAAL,GAAkB,IAAlB;AACAmC,UAAAA,KAAK,CAACgB,IAAN,CAAW;AAAEd,YAAAA,QAAQ,EAAExC,OAAO,CAACyC,cAApB;AAAoCnF,YAAAA,IAAI,EAAEmG;AAA1C,WAAX;AACH;AACJ,OAPD,MAQK;AACJ,YAAIA,SAAS,CAACC,UAAV,CAAqBE,KAArB,CAA2BlH,IAAI,IAAI;AACpC,iBAAO,CAAC,CAAC9B,SAAS,CAAC8B,IAAD,EAAOmE,SAAP,EAAkBb,OAAlB,CAAlB;AACH,SAFI,CAAJ,EAEG;AACA0C,UAAAA,KAAK,CAACvC,QAAD,CAAL,GAAkB,IAAlB;AACAmC,UAAAA,KAAK,CAACgB,IAAN,CAAW;AAAEd,YAAAA,QAAQ,EAAExC,OAAO,CAACyC,cAApB;AAAoCnF,YAAAA,IAAI,EAAEmG;AAA1C,WAAX;AACH;AACJ,KArBD;AAsBH;AACD;AACJ;AACA;;;AACI7C,EAAAA,OAAO,GAAG;AACNrE,IAAAA,MAAM,CAACC,IAAP,CAAY,KAAKM,SAAjB,EACKL,OADL,CACaO,GAAG,IAAI,KAAKF,SAAL,CAAeE,GAAf,EAAoBP,OAApB,CAA4BQ,MAAM,IAAIA,MAAM,CAAC2D,OAAP,EAAtC,CADpB;AAEH;;AACDvB,EAAAA,sBAAsB,CAACpD,MAAD,EAAS;AAC3BM,IAAAA,MAAM,CAACC,IAAP,CAAYP,MAAZ,EAAoBQ,OAApB,CAA4BC,IAAI,IAAI;AAChC,YAAM2E,KAAK,GAAGpF,MAAM,CAACS,IAAD,CAApB;AACA,YAAM,CAACyD,QAAD,IAAcrF,aAAa,CAAC4B,IAAD,CAAjC;AACA,YAAMY,IAAI,GAAG,KAAKhC,KAAL,CAAWkE,KAAX,CAAiBW,QAAjB,CAAb;;AACA,UAAI7C,IAAI,CAACE,UAAL,CAAgB,OAAhB,KAA4BF,IAAI,CAACE,UAAL,CAAgB,OAAhB,EAAyBC,KAAzD,EAAgE;AAC5D,cAAMF,KAAK,GAAGD,IAAI,CAACE,UAAL,CAAgB,OAAhB,EAAyBC,KAAvC;AACA,cAAMoG,KAAK,GAAGtG,KAAK,CAACsB,MAAN,KAAiBwC,KAAK,CAAC9D,KAAN,CAAYsB,MAA7B,IACVwC,KAAK,CAAC9D,KAAN,CAAYqG,KAAZ,CAAkB,CAACE,GAAD,EAAM1D,KAAN,KAAgB7C,KAAK,CAAC6C,KAAD,CAAL,KAAiB,CAAC,CAAlB,IAAuB7C,KAAK,CAAC6C,KAAD,CAAL,KAAiB0D,GAA1E,CADJ;AAEArJ,QAAAA,IAAI,CAACsJ,MAAL,CAAYF,KAAZ,EAAmB,MAAO,sBAAqBvG,IAAI,CAACZ,IAAK,iBAAhC,GACpB,gCAA+Ba,KAAM,aADjB,GAEpB,IAAG8D,KAAK,CAAC9D,KAAM,GAFpB;AAGH;;AACD,UAAID,IAAI,CAACE,UAAL,CAAgB,OAAhB,KAA4BF,IAAI,CAACE,UAAL,CAAgB,OAAhB,EAAyBC,KAAzD,EAAgE;AAC5DhD,QAAAA,IAAI,CAACsJ,MAAL,CAAY1C,KAAK,CAAC1D,KAAN,KAAgBL,IAAI,CAACE,UAAL,CAAgB,OAAhB,EAAyBC,KAArD,EAA4D,MAAO,sBAAqBH,IAAI,CAACZ,IAAK,iBAAhC,GAC7D,8BAD6D,GAE7D,GAAEY,IAAI,CAACE,UAAL,CAAgB,OAAhB,EAAyBC,KAAM,aAAY4D,KAAK,CAAC1D,KAAM,EAF9D;AAGH;AACJ,KAjBD;AAkBH;;AACDuB,EAAAA,SAAS,CAACjD,MAAD,EAAS;AACd,UAAM+H,MAAM,GAAG,EAAf;;AACA,SAAK,MAAMC,SAAX,IAAwBhI,MAAxB,EAAgC;AAC5B,UAAI,KAAKG,UAAL,IAAmB,IAAnB,IAA2B,KAAKA,UAAL,CAAgBH,MAAhB,IAA0B,IAArD,IACA,KAAKG,UAAL,CAAgBH,MAAhB,CAAuBgI,SAAvB,KAAqC,IADzC,EAC+C;AAC3C,cAAMhH,MAAM,GAAG,KAAKb,UAAL,CAAgBH,MAAhB,CAAuBgI,SAAvB,CAAf;AACAD,QAAAA,MAAM,CAAC/G,MAAM,CAACP,IAAR,CAAN,GAAsBT,MAAM,CAACgI,SAAD,CAA5B;AACH,OAJD,MAKK;AACDD,QAAAA,MAAM,CAACC,SAAD,CAAN,GAAoBhI,MAAM,CAACgI,SAAD,CAA1B;AACH;AACJ;;AACD,WAAOD,MAAP;AACH;;AACD5E,EAAAA,WAAW,CAACnD,MAAD,EAAS;AAChB,UAAMiI,UAAU,GAAG3H,MAAM,CAACC,IAAP,CAAYP,MAAZ,EAAoBiH,MAApB,CAA2BxG,IAAI,IAAI;AAClD,YAAM,CAACyD,QAAD,IAAarF,aAAa,CAAC4B,IAAD,CAAhC;AACA,aAAO,KAAKpB,KAAL,CAAWkE,KAAX,CAAiBW,QAAjB,KAA8B,IAArC;AACH,KAHkB,CAAnB;;AAIA,QAAI+D,UAAU,CAACrF,MAAX,GAAoB,CAAxB,EAA2B;AACvB,YAAM,IAAIF,KAAJ,CAAW,+CAAD,GACX,UAASuF,UAAW,8BADnB,CAAN;AAEH;AACJ;;AACD5E,EAAAA,UAAU,CAACvD,OAAD,EAAU;AAChB,WAAOA,OAAO,CAACgB,GAAR,CAAYL,IAAI,IAAI;AACvB,UAAI,KAAKN,UAAL,IAAmB,IAAnB,IAA2B,KAAKA,UAAL,CAAgBL,OAAhB,IAA2B,IAAtD,IACA,KAAKK,UAAL,CAAgBL,OAAhB,CAAwBW,IAAxB,KAAiC,IADrC,EAC2C;AACvC,cAAMO,MAAM,GAAG,KAAKb,UAAL,CAAgBL,OAAhB,CAAwBW,IAAxB,CAAf;AACA,eAAOO,MAAM,CAACP,IAAd;AACH;;AACD,aAAOA,IAAP;AACH,KAPM,EAOJ,EAPI,CAAP;AAQH;;AACD6C,EAAAA,YAAY,CAACxD,OAAD,EAAU;AAClBA,IAAAA,OAAO,CAACU,OAAR,CAAgBC,IAAI,IAAI;AACpB,YAAM,CAACyH,cAAD,IAAmBrJ,aAAa,CAAC4B,IAAD,CAAtC;;AACA,UAAI,CAAC,KAAKpB,KAAL,CAAWkE,KAAX,CAAiB2E,cAAjB,CAAL,EAAuC;AACnC,cAAM,IAAIxF,KAAJ,CAAW,eAAcjC,IAAK,6BAA9B,CAAN;AACH;AACJ,KALD;AAMH;;AAtesB","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { tidy, util } from '@tensorflow/tfjs-core';\nimport { getNodeNameAndIndex, getParamValue, getTensor, getTensorsForCurrentContenxt, parseNodeName } from '../operations/executors/utils';\nimport { executeOp } from '../operations/operation_executor';\nimport { ExecutionContext } from './execution_context';\nimport { getExecutionSubgraph, getNodesInTopologicalOrder, isControlFlow } from './model_analysis';\nexport class GraphExecutor {\n    /**\n     *\n     * @param graph Graph the model or function graph to be executed.\n     * @param parent When building function exector you need to set the parent\n     * executor. Since the weights and function executor maps are set at parant\n     * level, that function executor can access the function maps and weight maps\n     * through the parent.\n     */\n    constructor(graph, parent) {\n        this.graph = graph;\n        this.parent = parent;\n        this.compiledMap = new Map();\n        this._weightMap = {};\n        this.SEPERATOR = ',';\n        this._functions = {};\n        this._functionExecutorMap = {};\n        this._outputs = graph.outputs;\n        this._inputs = graph.inputs;\n        this._initNodes = graph.initNodes;\n        this._signature = graph.signature;\n        this._functions = graph.functions;\n        // create sub-graph executors\n        if (graph.functions != null) {\n            Object.keys(graph.functions).forEach(name => {\n                this._functionExecutorMap[name] =\n                    new GraphExecutor(graph.functions[name], this);\n            });\n        }\n    }\n    get weightIds() {\n        return this.parent ? this.parent.weightIds : this._weightIds;\n    }\n    get functionExecutorMap() {\n        return this.parent ? this.parent.functionExecutorMap :\n            this._functionExecutorMap;\n    }\n    get weightMap() {\n        return this.parent ? this.parent.weightMap : this._weightMap;\n    }\n    set weightMap(weightMap) {\n        const weightIds = Object.keys(weightMap).map(key => weightMap[key].map(tensor => tensor.id));\n        this._weightIds = [].concat(...weightIds);\n        this._weightMap = weightMap;\n    }\n    /**\n     * Set `ResourceManager` shared by executors of a model.\n     * @param resourceManager: `ResourceManager` of the `GraphModel`.\n     */\n    set resourceManager(resourceManager) {\n        this._resourceManager = resourceManager;\n    }\n    get inputs() {\n        return this._inputs.map(node => {\n            return {\n                name: node.name,\n                shape: node.attrParams['shape'] ?\n                    node.attrParams['shape'].value :\n                    undefined,\n                dtype: node.attrParams['dtype'] ?\n                    node.attrParams['dtype'].value :\n                    undefined\n            };\n        });\n    }\n    get outputs() {\n        return this._outputs.map(node => {\n            return {\n                name: node.name,\n                shape: node.attrParams['shape'] ?\n                    node.attrParams['shape'].value :\n                    undefined,\n                dtype: node.attrParams['dtype'] ?\n                    node.attrParams['dtype'].value :\n                    undefined\n            };\n        });\n    }\n    get inputNodes() {\n        return this._inputs.map(node => node.signatureKey || node.name);\n    }\n    get outputNodes() {\n        return this._outputs.map((node) => {\n            const name = node.signatureKey || node.name;\n            return node.defaultOutput ? (`${name}:${node.defaultOutput}`) : name;\n        });\n    }\n    get functions() {\n        return Object.keys(this._functions).reduce((map, key) => {\n            map[key] = this._functions[key].signature;\n            return map;\n        }, {});\n    }\n    getCompilationKey(inputs, outputs) {\n        const sortedInputs = inputs.map(node => node.name).sort();\n        const sortedOutputs = outputs.map(node => node.name).sort();\n        return sortedInputs.join(this.SEPERATOR) + '--' +\n            sortedOutputs.join(this.SEPERATOR);\n    }\n    /**\n     * Compiles the inference graph and returns the minimal set of nodes that are\n     * required for execution, in the correct execution order.\n     */\n    compile(inputs, outputs) {\n        const executionInfo = getExecutionSubgraph(inputs, outputs, this.weightMap, this._initNodes);\n        const { missingInputs, dynamicNode, syncInputs } = executionInfo;\n        if (dynamicNode != null) {\n            throw new Error(`This execution contains the node '${dynamicNode.name}', which has ` +\n                `the dynamic op '${dynamicNode.op}'. Please use ` +\n                `model.executeAsync() instead. Alternatively, to avoid the ` +\n                `dynamic ops, specify the inputs [${syncInputs}]`);\n        }\n        if (missingInputs.length > 0) {\n            const outNames = outputs.map(n => n.name);\n            const inNames = Object.keys(inputs);\n            throw new Error(`Cannot compute the outputs [${outNames}] from the provided inputs ` +\n                `[${inNames}]. Missing the following inputs: [${missingInputs}]`);\n        }\n        return getNodesInTopologicalOrder(this.graph, this.weightMap, executionInfo);\n    }\n    /**\n     * Executes the inference for given input tensors.\n     * @param inputs Tensor map for the model inputs, keyed by the input node\n     * names.\n     * @param outputs Optional. output node name from the Tensorflow model, if\n     * no outputs are specified, the default outputs of the model would be used.\n     * You can inspect intermediate nodes of the model by adding them to the\n     * outputs array.\n     */\n    execute(inputs, outputs) {\n        inputs = this.mapInputs(inputs);\n        const names = Object.keys(inputs).sort();\n        this.checkInputs(inputs);\n        this.checkInputShapeAndType(inputs);\n        outputs = this.mapOutputs(outputs);\n        this.checkOutputs(outputs);\n        const inputNodes = names.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n        const outputNodeNames = outputs.map(name => parseNodeName(name)[0]);\n        let outputNodes = outputNodeNames.map(name => this.graph.nodes[name]);\n        // If no outputs are specified, then use the default outputs of the model.\n        if (outputNodes.length === 0) {\n            outputNodes = this._outputs;\n        }\n        const compilationKey = this.getCompilationKey(inputNodes, outputNodes);\n        // Do nothing if the compiled graph cache contains the input.\n        let orderedNodes = this.compiledMap.get(compilationKey);\n        if (orderedNodes == null) {\n            orderedNodes = this.compile(inputs, outputNodes);\n            this.compiledMap.set(compilationKey, orderedNodes);\n        }\n        const tensorArrayMap = {};\n        const tensorListMap = {};\n        return tidy(() => {\n            const context = new ExecutionContext(this.weightMap, tensorArrayMap, tensorListMap, this.functionExecutorMap);\n            const tensorsMap = Object.assign({}, this.weightMap);\n            Object.keys(inputs).forEach(name => {\n                const [nodeName, index] = parseNodeName(name);\n                const tensors = [];\n                tensors[index] = inputs[name];\n                tensorsMap[nodeName] = tensors;\n            });\n            const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);\n            const intermediateTensorConsumerCount = {};\n            for (let i = 0; i < orderedNodes.length; i++) {\n                const node = orderedNodes[i];\n                if (!tensorsMap[node.name]) {\n                    const tensors = executeOp(node, tensorsMap, context, this._resourceManager);\n                    if (util.isPromise(tensors)) {\n                        throw new Error(`The execution of the op '${node.op}' returned a promise. ` +\n                            `Please use model.executeAsync() instead.`);\n                    }\n                    tensorsMap[node.name] = tensors;\n                    this.checkTensorForDisposal(node.name, node, tensorsMap, context, tensorsToKeep, outputNodeNames, intermediateTensorConsumerCount);\n                }\n            }\n            // dispose the context for the root executor\n            if (this.parent == null) {\n                context.dispose(tensorsToKeep);\n            }\n            return outputs.map(name => getTensor(name, tensorsMap, context));\n        });\n    }\n    getFrozenTensorIds(tensorMap) {\n        const ids = [].concat.apply([], Object.keys(tensorMap)\n            .map(key => tensorMap[key])\n            .map(tensors => tensors.map(tensor => tensor.id)));\n        return new Set(ids);\n    }\n    checkTensorForDisposal(nodeName, node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount) {\n        // Skip output nodes and any control flow nodes, since its dependency is\n        // tricky to track correctly.\n        if (node.category === 'control' || outputNames.indexOf(nodeName) !== -1) {\n            return;\n        }\n        tensorMap[nodeName].forEach(tensor => {\n            if (tensor != null) {\n                intermediateTensorConsumerCount[tensor.id] =\n                    (intermediateTensorConsumerCount[tensor.id] || 0) +\n                        node.children.length;\n            }\n        });\n        node.inputs.forEach(input => {\n            // Skip any control flow nodes, since its dependency is tricky to track\n            // correctly.\n            if (input.category !== 'control') {\n                const tensors = getTensorsForCurrentContenxt(input.name, tensorMap, context);\n                if (tensors != null) {\n                    tensors.forEach(tensor => {\n                        if (tensor && !tensorsToKeep.has(tensor.id)) {\n                            const count = intermediateTensorConsumerCount[tensor.id];\n                            if (count === 1) {\n                                tensor.dispose();\n                                delete intermediateTensorConsumerCount[tensor.id];\n                            }\n                            else if (count != null) {\n                                // only intermediate nodes has count set, inputs and weights are\n                                // not.\n                                intermediateTensorConsumerCount[tensor.id]--;\n                            }\n                        }\n                    });\n                }\n            }\n        });\n    }\n    /**\n     * Executes the inference for given input tensors in Async fashion.\n     * @param inputs Tensor map for the model inputs, keyed by the input node\n     * names.\n     * @param outputs output node name from the Tensorflow model, if no outputs\n     * are specified, the default outputs of the model would be used. You can\n     * inspect intermediate nodes of the model by adding them to the outputs\n     * array.\n     */\n    async executeAsync(inputs, outputs) {\n        return this._executeAsync(inputs, outputs);\n    }\n    /**\n     * Executes the inference for given input tensors in Async fashion.\n     * @param inputs Tensor map for the model inputs, keyed by the input node\n     * names.\n     * @param outputs Optional. output node name from the Tensorflow model,\n     * if no outputs are specified, the default outputs of the model would be\n     * used. You can inspect intermediate nodes of the model by adding them to the\n     * outputs array.\n     * @param isFunctionExecution Optional. Flag for executing a function.\n     * @param tensorArrayMap Optional, global TensorArray map by id. Used for\n     * function execution.\n     * @param tensorArrayMap Optinal global TensorList map by id. Used for\n     * function execution.\n     */\n    async _executeAsync(inputs, outputs, isFunctionExecution = false, tensorArrayMap = {}, tensorListMap = {}) {\n        if (!isFunctionExecution) {\n            inputs = this.mapInputs(inputs);\n            this.checkInputs(inputs);\n            this.checkInputShapeAndType(inputs);\n            outputs = this.mapOutputs(outputs);\n            this.checkOutputs(outputs);\n        }\n        const context = new ExecutionContext(this.weightMap, tensorArrayMap, tensorListMap, this.functionExecutorMap);\n        // Graph with control flow op requires runtime evaluation of the execution\n        // order, while without control flow the execution order is pre-determined\n        // in the compile method.\n        const tensorMap = await this.executeWithControlFlow(inputs, context, outputs, isFunctionExecution);\n        const results = outputs.map(name => getTensor(name, tensorMap, context));\n        // dispose all the intermediate tensors\n        const outputIds = results.map(t => t.id);\n        const inputIds = Object.keys(inputs).map(name => inputs[name].id);\n        const keepIds = new Set([...outputIds, ...inputIds, ...this.weightIds]);\n        Object.keys(tensorMap).forEach(key => {\n            const tensorArray = tensorMap[key];\n            tensorArray.forEach(tensor => {\n                if (tensor && !tensor.isDisposed && !keepIds.has(tensor.id)) {\n                    tensor.dispose();\n                }\n            });\n        });\n        // dispose the context for the root executor\n        if (this.parent == null) {\n            context.dispose(keepIds);\n        }\n        return results;\n    }\n    async executeFunctionAsync(inputs, tensorArrayMap, tensorListMap) {\n        const mappedInputs = inputs.reduce((map, tensor, index) => {\n            map[this.inputs[index].name] = tensor;\n            return map;\n        }, {});\n        return this._executeAsync(mappedInputs, this.outputNodes, true, tensorArrayMap, tensorListMap);\n    }\n    /**\n     * When there are control flow nodes in the graph, the graph execution use\n     * ExecutionContext to keep track of the frames and loop iterators.\n     * @param inputs placeholder tensors for the graph.\n     * @param context the execution context object for current execution.\n     * @param outputNames Optional. output node name from the Tensorflow model,\n     * if no outputs are specified, the default outputs of the model would be\n     * used. You can inspect intermediate nodes of the model by adding them to the\n     * outputs array.\n     * @param isFunctionExecution Flag for executing a function.\n     */\n    async executeWithControlFlow(inputs, context, outputNames, isFunctionExecution) {\n        const names = Object.keys(inputs);\n        const inputNodes = names.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n        const outputNodeNames = outputNames.map(name => parseNodeName(name)[0]);\n        let outputNodes = outputNodeNames.map(name => this.graph.nodes[name]);\n        // If no outputs are specified, then use the default outputs of the model.\n        if (outputNodes.length === 0) {\n            outputNodes = this._outputs;\n        }\n        const { usedNodes, missingInputs, dynamicNode, syncInputs } = getExecutionSubgraph(inputs, outputNodes, this.weightMap, this._initNodes);\n        // First nodes to execute include inputNodes, weights, and initNodes.\n        const stack = [\n            ...inputNodes, ...this.graph.weights, ...(this._initNodes || [])\n        ].map(node => {\n            return { node, contexts: context.currentContext };\n        });\n        const tensorsMap = Object.assign({}, this.weightMap);\n        Object.keys(inputs).forEach(name => {\n            const [nodeName, index] = parseNodeName(name);\n            const tensors = [];\n            tensors[index] = inputs[name];\n            tensorsMap[nodeName] = tensors;\n        });\n        const intermediateTensorConsumerCount = {};\n        const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);\n        const added = {};\n        while (stack.length > 0) {\n            const promises = this.processStack(inputNodes, stack, context, tensorsMap, added, tensorsToKeep, outputNodeNames, intermediateTensorConsumerCount, usedNodes);\n            await Promise.all(promises);\n        }\n        if (dynamicNode == null && !isFunctionExecution) {\n            console.warn(`This model execution did not contain any nodes with control flow ` +\n                `or dynamic output shapes. You can use model.execute() instead.`);\n        }\n        const missingOutputs = outputNodes\n            .filter(node => !isControlFlow(node) &&\n            !getTensor(node.name, tensorsMap, context))\n            .map(node => node.name);\n        if (missingOutputs.length > 0) {\n            let alternativeMsg = '';\n            if (dynamicNode != null) {\n                alternativeMsg =\n                    `Alternatively, to avoid the dynamic ops, use model.execute() ` +\n                        `and specify the inputs [${syncInputs}]`;\n            }\n            throw new Error(`Cannot compute the outputs [${missingOutputs}] from the provided ` +\n                `inputs [${names}]. Consider providing the following inputs: ` +\n                `[${missingInputs}]. ${alternativeMsg}`);\n        }\n        return tensorsMap;\n    }\n    processStack(inputNodes, stack, context, tensorMap, added, tensorsToKeep, outputNames, intermediateTensorConsumerCount, usedNodes) {\n        const promises = [];\n        while (stack.length > 0) {\n            const item = stack.pop();\n            context.currentContext = item.contexts;\n            let nodeName = '';\n            // The tensor of the Enter op with isConstant set should be set\n            // in the parent scope, so it will be available as constant for the\n            // whole loop.\n            if (item.node.op === 'Enter' &&\n                getParamValue('isConstant', item.node, tensorMap, context)) {\n                [nodeName] = getNodeNameAndIndex(item.node.name, context);\n            }\n            // only process nodes that are not in the tensorMap yet, this include\n            // inputNodes and internal initNodes.\n            if (tensorMap[item.node.name] == null) {\n                const tensors = executeOp(item.node, tensorMap, context, this._resourceManager);\n                if (!nodeName) {\n                    [nodeName] = getNodeNameAndIndex(item.node.name, context);\n                }\n                const currentContext = context.currentContext;\n                if (util.isPromise(tensors)) {\n                    promises.push(tensors.then(t => {\n                        tensorMap[nodeName] = t;\n                        context.currentContext = currentContext;\n                        this.checkTensorForDisposal(nodeName, item.node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount);\n                        this.processChildNodes(item.node, stack, context, tensorMap, added, usedNodes);\n                        return t;\n                    }));\n                }\n                else {\n                    tensorMap[nodeName] = tensors;\n                    this.checkTensorForDisposal(nodeName, item.node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount);\n                    this.processChildNodes(item.node, stack, context, tensorMap, added, usedNodes);\n                }\n            }\n            else {\n                this.processChildNodes(item.node, stack, context, tensorMap, added, usedNodes);\n            }\n        }\n        return promises;\n    }\n    processChildNodes(node, stack, context, tensorMap, added, usedNodes) {\n        node.children.forEach((childNode) => {\n            const [nodeName,] = getNodeNameAndIndex(childNode.name, context);\n            if (added[nodeName] || !usedNodes.has(childNode.name)) {\n                return;\n            }\n            // Merge op can be pushed if any of its inputs has value.\n            if (childNode.op === 'Merge') {\n                if (childNode.inputNames.some(name => {\n                    return !!getTensor(name, tensorMap, context);\n                })) {\n                    added[nodeName] = true;\n                    stack.push({ contexts: context.currentContext, node: childNode });\n                }\n            }\n            else // Otherwise all inputs must to have value.\n             if (childNode.inputNames.every(name => {\n                return !!getTensor(name, tensorMap, context);\n            })) {\n                added[nodeName] = true;\n                stack.push({ contexts: context.currentContext, node: childNode });\n            }\n        });\n    }\n    /**\n     * Releases the memory used by the weight tensors.\n     */\n    dispose() {\n        Object.keys(this.weightMap)\n            .forEach(key => this.weightMap[key].forEach(tensor => tensor.dispose()));\n    }\n    checkInputShapeAndType(inputs) {\n        Object.keys(inputs).forEach(name => {\n            const input = inputs[name];\n            const [nodeName,] = parseNodeName(name);\n            const node = this.graph.nodes[nodeName];\n            if (node.attrParams['shape'] && node.attrParams['shape'].value) {\n                const shape = node.attrParams['shape'].value;\n                const match = shape.length === input.shape.length &&\n                    input.shape.every((dim, index) => shape[index] === -1 || shape[index] === dim);\n                util.assert(match, () => `The shape of dict['${node.name}'] provided in ` +\n                    `model.execute(dict) must be [${shape}], but was ` +\n                    `[${input.shape}]`);\n            }\n            if (node.attrParams['dtype'] && node.attrParams['dtype'].value) {\n                util.assert(input.dtype === node.attrParams['dtype'].value, () => `The dtype of dict['${node.name}'] provided in ` +\n                    `model.execute(dict) must be ` +\n                    `${node.attrParams['dtype'].value}, but was ${input.dtype}`);\n            }\n        });\n    }\n    mapInputs(inputs) {\n        const result = {};\n        for (const inputName in inputs) {\n            if (this._signature != null && this._signature.inputs != null &&\n                this._signature.inputs[inputName] != null) {\n                const tensor = this._signature.inputs[inputName];\n                result[tensor.name] = inputs[inputName];\n            }\n            else {\n                result[inputName] = inputs[inputName];\n            }\n        }\n        return result;\n    }\n    checkInputs(inputs) {\n        const notInGraph = Object.keys(inputs).filter(name => {\n            const [nodeName] = parseNodeName(name);\n            return this.graph.nodes[nodeName] == null;\n        });\n        if (notInGraph.length > 0) {\n            throw new Error(`The dict provided in model.execute(dict) has ` +\n                `keys: [${notInGraph}] that are not part of graph`);\n        }\n    }\n    mapOutputs(outputs) {\n        return outputs.map(name => {\n            if (this._signature != null && this._signature.outputs != null &&\n                this._signature.outputs[name] != null) {\n                const tensor = this._signature.outputs[name];\n                return tensor.name;\n            }\n            return name;\n        }, {});\n    }\n    checkOutputs(outputs) {\n        outputs.forEach(name => {\n            const [normalizedName] = parseNodeName(name);\n            if (!this.graph.nodes[normalizedName]) {\n                throw new Error(`The output '${name}' is not found in the graph`);\n            }\n        });\n    }\n}\n"]},"metadata":{},"sourceType":"module"}