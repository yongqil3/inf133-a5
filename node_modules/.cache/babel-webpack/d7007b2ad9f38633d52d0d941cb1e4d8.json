{"ast":null,"code":"import _asyncToGenerator from \"/Users/ryanliang/Downloads/main_movir_picker/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { dispose, tidy } from '../globals';\nimport { add } from '../ops/add';\nimport { div } from '../ops/div';\nimport { mul } from '../ops/mul';\nimport { sqrt } from '../ops/sqrt';\nimport { square } from '../ops/square';\nimport { sub } from '../ops/sub';\nimport { zerosLike } from '../ops/zeros_like';\nimport { registerClass } from '../serialization';\nimport { Optimizer } from './optimizer';\n/** @doclink Optimizer */\n\nexport class RMSPropOptimizer extends Optimizer {\n  constructor(learningRate, decay = 0.9, momentum = 0.0, epsilon = null, centered = false) {\n    super();\n    this.learningRate = learningRate;\n    this.decay = decay;\n    this.momentum = momentum;\n    this.epsilon = epsilon;\n    this.accumulatedMeanSquares = [];\n    this.accumulatedMoments = [];\n    this.accumulatedMeanGrads = [];\n    this.centered = centered;\n\n    if (epsilon == null) {\n      this.epsilon = ENGINE.backend.epsilon();\n    }\n\n    if (learningRate == null) {\n      throw new Error(`learningRate for RMSPropOptimizer must be defined.`);\n    }\n  }\n\n  applyGradients(variableGradients) {\n    const variableNames = Array.isArray(variableGradients) ? variableGradients.map(item => item.name) : Object.keys(variableGradients);\n    variableNames.forEach((name, i) => {\n      const value = ENGINE.registeredVariables[name];\n      const trainable = false;\n\n      if (this.accumulatedMeanSquares[i] == null) {\n        this.accumulatedMeanSquares[i] = {\n          originalName: `${name}/rms`,\n          variable: tidy(() => zerosLike(value).variable(trainable))\n        };\n      }\n\n      if (this.accumulatedMoments[i] == null) {\n        this.accumulatedMoments[i] = {\n          originalName: `${name}/momentum`,\n          variable: tidy(() => zerosLike(value).variable(trainable))\n        };\n      }\n\n      if (this.accumulatedMeanGrads[i] == null && this.centered) {\n        this.accumulatedMeanGrads[i] = {\n          originalName: `${name}/mg`,\n          variable: tidy(() => zerosLike(value).variable(trainable))\n        };\n      }\n\n      const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];\n\n      if (gradient == null) {\n        return;\n      }\n\n      const accumulatedMeanSquare = this.accumulatedMeanSquares[i].variable;\n      const accumulatedMoments = this.accumulatedMoments[i].variable;\n      tidy(() => {\n        const newAccumulatedMeanSquare = add(mul(accumulatedMeanSquare, this.decay), mul(square(gradient), 1 - this.decay));\n\n        if (this.centered) {\n          const accumulatedMeanGrad = this.accumulatedMeanGrads[i].variable; // Centered gradient\n\n          const newAccumulatedMeanGrad = add(mul(accumulatedMeanGrad, this.decay), mul(gradient, 1 - this.decay));\n          const gradContribution = div(mul(gradient, this.learningRate), sqrt(sub(newAccumulatedMeanSquare, add(square(newAccumulatedMeanGrad), this.epsilon))));\n          const newAccumulatedMoments = add(mul(accumulatedMoments, this.momentum), gradContribution);\n          accumulatedMeanSquare.assign(newAccumulatedMeanSquare);\n          accumulatedMeanGrad.assign(newAccumulatedMeanGrad);\n          accumulatedMoments.assign(newAccumulatedMoments);\n          const newValue = sub(value, newAccumulatedMoments);\n          value.assign(newValue);\n        } else {\n          // Plain gradient\n          const newAccumulatedMeanSquare = add(mul(accumulatedMeanSquare, this.decay), mul(square(gradient), 1 - this.decay));\n          const newAccumulatedMoments = add(mul(accumulatedMoments, this.momentum), div(mul(gradient, this.learningRate), sqrt(add(newAccumulatedMeanSquare, this.epsilon))));\n          accumulatedMeanSquare.assign(newAccumulatedMeanSquare);\n          accumulatedMoments.assign(newAccumulatedMoments);\n          const newValue = sub(value, newAccumulatedMoments);\n          value.assign(newValue);\n        }\n      });\n    });\n    this.incrementIterations();\n  }\n\n  dispose() {\n    if (this.accumulatedMeanSquares != null) {\n      dispose(this.accumulatedMeanSquares.map(v => v.variable));\n    }\n\n    if (this.accumulatedMeanGrads != null && this.centered) {\n      dispose(this.accumulatedMeanGrads.map(v => v.variable));\n    }\n\n    if (this.accumulatedMoments != null) {\n      dispose(this.accumulatedMoments.map(v => v.variable));\n    }\n  }\n\n  getWeights() {\n    var _this = this;\n\n    return _asyncToGenerator(function* () {\n      // Order matters for Python compatibility.\n      const variables = [..._this.accumulatedMeanSquares, ..._this.accumulatedMoments];\n\n      if (_this.centered) {\n        variables.push(..._this.accumulatedMeanGrads);\n      }\n\n      return [yield _this.saveIterations()].concat(variables.map(v => ({\n        name: v.originalName,\n        tensor: v.variable\n      })));\n    })();\n  }\n\n  setWeights(weightValues) {\n    var _this2 = this;\n\n    return _asyncToGenerator(function* () {\n      weightValues = yield _this2.extractIterations(weightValues);\n      const variableCount = _this2.centered ? weightValues.length / 3 : weightValues.length / 2;\n      const trainable = false;\n      _this2.accumulatedMeanSquares = weightValues.slice(0, variableCount).map(v => ({\n        originalName: v.name,\n        variable: v.tensor.variable(trainable)\n      }));\n      _this2.accumulatedMoments = weightValues.slice(variableCount, variableCount * 2).map(v => ({\n        originalName: v.name,\n        variable: v.tensor.variable(trainable)\n      }));\n\n      if (_this2.centered) {\n        _this2.accumulatedMeanGrads = weightValues.slice(variableCount * 2, variableCount * 3).map(v => ({\n          originalName: v.name,\n          variable: v.tensor.variable(trainable)\n        }));\n      }\n    })();\n  }\n\n  getConfig() {\n    return {\n      'learningRate': this.learningRate,\n      'decay': this.decay,\n      'momentum': this.momentum,\n      'epsilon': this.epsilon,\n      'centered': this.centered\n    };\n  }\n  /** @nocollapse */\n\n\n  static fromConfig(cls, config) {\n    return new cls(config['learningRate'], config['decay'], config['momentum'], config['epsilon'], config['centered']);\n  }\n\n}\n/** @nocollapse */\n\nRMSPropOptimizer.className = 'RMSProp'; // Note: Name matters for Python compatibility.\n\nregisterClass(RMSPropOptimizer);","map":{"version":3,"sources":["/Users/ryanliang/Downloads/main_movir_picker/node_modules/@tensorflow/tfjs-core/dist/optimizers/rmsprop_optimizer.js"],"names":["ENGINE","dispose","tidy","add","div","mul","sqrt","square","sub","zerosLike","registerClass","Optimizer","RMSPropOptimizer","constructor","learningRate","decay","momentum","epsilon","centered","accumulatedMeanSquares","accumulatedMoments","accumulatedMeanGrads","backend","Error","applyGradients","variableGradients","variableNames","Array","isArray","map","item","name","Object","keys","forEach","i","value","registeredVariables","trainable","originalName","variable","gradient","tensor","accumulatedMeanSquare","newAccumulatedMeanSquare","accumulatedMeanGrad","newAccumulatedMeanGrad","gradContribution","newAccumulatedMoments","assign","newValue","incrementIterations","v","getWeights","variables","push","saveIterations","concat","setWeights","weightValues","extractIterations","variableCount","length","slice","getConfig","fromConfig","cls","config","className"],"mappings":";;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASA,MAAT,QAAuB,WAAvB;AACA,SAASC,OAAT,EAAkBC,IAAlB,QAA8B,YAA9B;AACA,SAASC,GAAT,QAAoB,YAApB;AACA,SAASC,GAAT,QAAoB,YAApB;AACA,SAASC,GAAT,QAAoB,YAApB;AACA,SAASC,IAAT,QAAqB,aAArB;AACA,SAASC,MAAT,QAAuB,eAAvB;AACA,SAASC,GAAT,QAAoB,YAApB;AACA,SAASC,SAAT,QAA0B,mBAA1B;AACA,SAASC,aAAT,QAA8B,kBAA9B;AACA,SAASC,SAAT,QAA0B,aAA1B;AACA;;AACA,OAAO,MAAMC,gBAAN,SAA+BD,SAA/B,CAAyC;AAC5CE,EAAAA,WAAW,CAACC,YAAD,EAAeC,KAAK,GAAG,GAAvB,EAA4BC,QAAQ,GAAG,GAAvC,EAA4CC,OAAO,GAAG,IAAtD,EAA4DC,QAAQ,GAAG,KAAvE,EAA8E;AACrF;AACA,SAAKJ,YAAL,GAAoBA,YAApB;AACA,SAAKC,KAAL,GAAaA,KAAb;AACA,SAAKC,QAAL,GAAgBA,QAAhB;AACA,SAAKC,OAAL,GAAeA,OAAf;AACA,SAAKE,sBAAL,GAA8B,EAA9B;AACA,SAAKC,kBAAL,GAA0B,EAA1B;AACA,SAAKC,oBAAL,GAA4B,EAA5B;AACA,SAAKH,QAAL,GAAgBA,QAAhB;;AACA,QAAID,OAAO,IAAI,IAAf,EAAqB;AACjB,WAAKA,OAAL,GAAejB,MAAM,CAACsB,OAAP,CAAeL,OAAf,EAAf;AACH;;AACD,QAAIH,YAAY,IAAI,IAApB,EAA0B;AACtB,YAAM,IAAIS,KAAJ,CAAW,oDAAX,CAAN;AACH;AACJ;;AACDC,EAAAA,cAAc,CAACC,iBAAD,EAAoB;AAC9B,UAAMC,aAAa,GAAGC,KAAK,CAACC,OAAN,CAAcH,iBAAd,IAClBA,iBAAiB,CAACI,GAAlB,CAAsBC,IAAI,IAAIA,IAAI,CAACC,IAAnC,CADkB,GAElBC,MAAM,CAACC,IAAP,CAAYR,iBAAZ,CAFJ;AAGAC,IAAAA,aAAa,CAACQ,OAAd,CAAsB,CAACH,IAAD,EAAOI,CAAP,KAAa;AAC/B,YAAMC,KAAK,GAAGpC,MAAM,CAACqC,mBAAP,CAA2BN,IAA3B,CAAd;AACA,YAAMO,SAAS,GAAG,KAAlB;;AACA,UAAI,KAAKnB,sBAAL,CAA4BgB,CAA5B,KAAkC,IAAtC,EAA4C;AACxC,aAAKhB,sBAAL,CAA4BgB,CAA5B,IAAiC;AAC7BI,UAAAA,YAAY,EAAG,GAAER,IAAK,MADO;AAE7BS,UAAAA,QAAQ,EAAEtC,IAAI,CAAC,MAAMO,SAAS,CAAC2B,KAAD,CAAT,CAAiBI,QAAjB,CAA0BF,SAA1B,CAAP;AAFe,SAAjC;AAIH;;AACD,UAAI,KAAKlB,kBAAL,CAAwBe,CAAxB,KAA8B,IAAlC,EAAwC;AACpC,aAAKf,kBAAL,CAAwBe,CAAxB,IAA6B;AACzBI,UAAAA,YAAY,EAAG,GAAER,IAAK,WADG;AAEzBS,UAAAA,QAAQ,EAAEtC,IAAI,CAAC,MAAMO,SAAS,CAAC2B,KAAD,CAAT,CAAiBI,QAAjB,CAA0BF,SAA1B,CAAP;AAFW,SAA7B;AAIH;;AACD,UAAI,KAAKjB,oBAAL,CAA0Bc,CAA1B,KAAgC,IAAhC,IAAwC,KAAKjB,QAAjD,EAA2D;AACvD,aAAKG,oBAAL,CAA0Bc,CAA1B,IAA+B;AAC3BI,UAAAA,YAAY,EAAG,GAAER,IAAK,KADK;AAE3BS,UAAAA,QAAQ,EAAEtC,IAAI,CAAC,MAAMO,SAAS,CAAC2B,KAAD,CAAT,CAAiBI,QAAjB,CAA0BF,SAA1B,CAAP;AAFa,SAA/B;AAIH;;AACD,YAAMG,QAAQ,GAAGd,KAAK,CAACC,OAAN,CAAcH,iBAAd,IACbA,iBAAiB,CAACU,CAAD,CAAjB,CAAqBO,MADR,GAEbjB,iBAAiB,CAACM,IAAD,CAFrB;;AAGA,UAAIU,QAAQ,IAAI,IAAhB,EAAsB;AAClB;AACH;;AACD,YAAME,qBAAqB,GAAG,KAAKxB,sBAAL,CAA4BgB,CAA5B,EAA+BK,QAA7D;AACA,YAAMpB,kBAAkB,GAAG,KAAKA,kBAAL,CAAwBe,CAAxB,EAA2BK,QAAtD;AACAtC,MAAAA,IAAI,CAAC,MAAM;AACP,cAAM0C,wBAAwB,GAAGzC,GAAG,CAACE,GAAG,CAACsC,qBAAD,EAAwB,KAAK5B,KAA7B,CAAJ,EAAyCV,GAAG,CAACE,MAAM,CAACkC,QAAD,CAAP,EAAmB,IAAI,KAAK1B,KAA5B,CAA5C,CAApC;;AACA,YAAI,KAAKG,QAAT,EAAmB;AACf,gBAAM2B,mBAAmB,GAAG,KAAKxB,oBAAL,CAA0Bc,CAA1B,EAA6BK,QAAzD,CADe,CAEf;;AACA,gBAAMM,sBAAsB,GAAG3C,GAAG,CAACE,GAAG,CAACwC,mBAAD,EAAsB,KAAK9B,KAA3B,CAAJ,EAAuCV,GAAG,CAACoC,QAAD,EAAW,IAAI,KAAK1B,KAApB,CAA1C,CAAlC;AACA,gBAAMgC,gBAAgB,GAAG3C,GAAG,CAACC,GAAG,CAACoC,QAAD,EAAW,KAAK3B,YAAhB,CAAJ,EAAmCR,IAAI,CAACE,GAAG,CAACoC,wBAAD,EAA2BzC,GAAG,CAACI,MAAM,CAACuC,sBAAD,CAAP,EAAiC,KAAK7B,OAAtC,CAA9B,CAAJ,CAAvC,CAA5B;AACA,gBAAM+B,qBAAqB,GAAG7C,GAAG,CAACE,GAAG,CAACe,kBAAD,EAAqB,KAAKJ,QAA1B,CAAJ,EAAyC+B,gBAAzC,CAAjC;AACAJ,UAAAA,qBAAqB,CAACM,MAAtB,CAA6BL,wBAA7B;AACAC,UAAAA,mBAAmB,CAACI,MAApB,CAA2BH,sBAA3B;AACA1B,UAAAA,kBAAkB,CAAC6B,MAAnB,CAA0BD,qBAA1B;AACA,gBAAME,QAAQ,GAAG1C,GAAG,CAAC4B,KAAD,EAAQY,qBAAR,CAApB;AACAZ,UAAAA,KAAK,CAACa,MAAN,CAAaC,QAAb;AACH,SAXD,MAYK;AACD;AACA,gBAAMN,wBAAwB,GAAGzC,GAAG,CAACE,GAAG,CAACsC,qBAAD,EAAwB,KAAK5B,KAA7B,CAAJ,EAAyCV,GAAG,CAACE,MAAM,CAACkC,QAAD,CAAP,EAAmB,IAAI,KAAK1B,KAA5B,CAA5C,CAApC;AACA,gBAAMiC,qBAAqB,GAAG7C,GAAG,CAACE,GAAG,CAACe,kBAAD,EAAqB,KAAKJ,QAA1B,CAAJ,EAAyCZ,GAAG,CAACC,GAAG,CAACoC,QAAD,EAAW,KAAK3B,YAAhB,CAAJ,EAAmCR,IAAI,CAACH,GAAG,CAACyC,wBAAD,EAA2B,KAAK3B,OAAhC,CAAJ,CAAvC,CAA5C,CAAjC;AACA0B,UAAAA,qBAAqB,CAACM,MAAtB,CAA6BL,wBAA7B;AACAxB,UAAAA,kBAAkB,CAAC6B,MAAnB,CAA0BD,qBAA1B;AACA,gBAAME,QAAQ,GAAG1C,GAAG,CAAC4B,KAAD,EAAQY,qBAAR,CAApB;AACAZ,UAAAA,KAAK,CAACa,MAAN,CAAaC,QAAb;AACH;AACJ,OAvBG,CAAJ;AAwBH,KArDD;AAsDA,SAAKC,mBAAL;AACH;;AACDlD,EAAAA,OAAO,GAAG;AACN,QAAI,KAAKkB,sBAAL,IAA+B,IAAnC,EAAyC;AACrClB,MAAAA,OAAO,CAAC,KAAKkB,sBAAL,CAA4BU,GAA5B,CAAgCuB,CAAC,IAAIA,CAAC,CAACZ,QAAvC,CAAD,CAAP;AACH;;AACD,QAAI,KAAKnB,oBAAL,IAA6B,IAA7B,IAAqC,KAAKH,QAA9C,EAAwD;AACpDjB,MAAAA,OAAO,CAAC,KAAKoB,oBAAL,CAA0BQ,GAA1B,CAA8BuB,CAAC,IAAIA,CAAC,CAACZ,QAArC,CAAD,CAAP;AACH;;AACD,QAAI,KAAKpB,kBAAL,IAA2B,IAA/B,EAAqC;AACjCnB,MAAAA,OAAO,CAAC,KAAKmB,kBAAL,CAAwBS,GAAxB,CAA4BuB,CAAC,IAAIA,CAAC,CAACZ,QAAnC,CAAD,CAAP;AACH;AACJ;;AACKa,EAAAA,UAAU,GAAG;AAAA;;AAAA;AACf;AACA,YAAMC,SAAS,GAAG,CAAC,GAAG,KAAI,CAACnC,sBAAT,EAAiC,GAAG,KAAI,CAACC,kBAAzC,CAAlB;;AACA,UAAI,KAAI,CAACF,QAAT,EAAmB;AACfoC,QAAAA,SAAS,CAACC,IAAV,CAAe,GAAG,KAAI,CAAClC,oBAAvB;AACH;;AACD,aAAO,OAAO,KAAI,CAACmC,cAAL,EAAP,EAA8BC,MAA9B,CAAqCH,SAAS,CAACzB,GAAV,CAAcuB,CAAC,KAAK;AAAErB,QAAAA,IAAI,EAAEqB,CAAC,CAACb,YAAV;AAAwBG,QAAAA,MAAM,EAAEU,CAAC,CAACZ;AAAlC,OAAL,CAAf,CAArC,CAAP;AANe;AAOlB;;AACKkB,EAAAA,UAAU,CAACC,YAAD,EAAe;AAAA;;AAAA;AAC3BA,MAAAA,YAAY,SAAS,MAAI,CAACC,iBAAL,CAAuBD,YAAvB,CAArB;AACA,YAAME,aAAa,GAAG,MAAI,CAAC3C,QAAL,GAAgByC,YAAY,CAACG,MAAb,GAAsB,CAAtC,GAA0CH,YAAY,CAACG,MAAb,GAAsB,CAAtF;AACA,YAAMxB,SAAS,GAAG,KAAlB;AACA,MAAA,MAAI,CAACnB,sBAAL,GACIwC,YAAY,CAACI,KAAb,CAAmB,CAAnB,EAAsBF,aAAtB,EAAqChC,GAArC,CAAyCuB,CAAC,KAAK;AAC3Cb,QAAAA,YAAY,EAAEa,CAAC,CAACrB,IAD2B;AAE3CS,QAAAA,QAAQ,EAAEY,CAAC,CAACV,MAAF,CAASF,QAAT,CAAkBF,SAAlB;AAFiC,OAAL,CAA1C,CADJ;AAKA,MAAA,MAAI,CAAClB,kBAAL,GACIuC,YAAY,CAACI,KAAb,CAAmBF,aAAnB,EAAkCA,aAAa,GAAG,CAAlD,EACKhC,GADL,CACSuB,CAAC,KAAK;AACXb,QAAAA,YAAY,EAAEa,CAAC,CAACrB,IADL;AAEXS,QAAAA,QAAQ,EAAEY,CAAC,CAACV,MAAF,CAASF,QAAT,CAAkBF,SAAlB;AAFC,OAAL,CADV,CADJ;;AAMA,UAAI,MAAI,CAACpB,QAAT,EAAmB;AACf,QAAA,MAAI,CAACG,oBAAL,GACIsC,YAAY,CAACI,KAAb,CAAmBF,aAAa,GAAG,CAAnC,EAAsCA,aAAa,GAAG,CAAtD,EACKhC,GADL,CACSuB,CAAC,KAAK;AACXb,UAAAA,YAAY,EAAEa,CAAC,CAACrB,IADL;AAEXS,UAAAA,QAAQ,EAAEY,CAAC,CAACV,MAAF,CAASF,QAAT,CAAkBF,SAAlB;AAFC,SAAL,CADV,CADJ;AAMH;AAtB0B;AAuB9B;;AACD0B,EAAAA,SAAS,GAAG;AACR,WAAO;AACH,sBAAgB,KAAKlD,YADlB;AAEH,eAAS,KAAKC,KAFX;AAGH,kBAAY,KAAKC,QAHd;AAIH,iBAAW,KAAKC,OAJb;AAKH,kBAAY,KAAKC;AALd,KAAP;AAOH;AACD;;;AACiB,SAAV+C,UAAU,CAACC,GAAD,EAAMC,MAAN,EAAc;AAC3B,WAAO,IAAID,GAAJ,CAAQC,MAAM,CAAC,cAAD,CAAd,EAAgCA,MAAM,CAAC,OAAD,CAAtC,EAAiDA,MAAM,CAAC,UAAD,CAAvD,EAAqEA,MAAM,CAAC,SAAD,CAA3E,EAAwFA,MAAM,CAAC,UAAD,CAA9F,CAAP;AACH;;AArI2C;AAuIhD;;AACAvD,gBAAgB,CAACwD,SAAjB,GAA6B,SAA7B,C,CAAwC;;AACxC1D,aAAa,CAACE,gBAAD,CAAb","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { dispose, tidy } from '../globals';\nimport { add } from '../ops/add';\nimport { div } from '../ops/div';\nimport { mul } from '../ops/mul';\nimport { sqrt } from '../ops/sqrt';\nimport { square } from '../ops/square';\nimport { sub } from '../ops/sub';\nimport { zerosLike } from '../ops/zeros_like';\nimport { registerClass } from '../serialization';\nimport { Optimizer } from './optimizer';\n/** @doclink Optimizer */\nexport class RMSPropOptimizer extends Optimizer {\n    constructor(learningRate, decay = 0.9, momentum = 0.0, epsilon = null, centered = false) {\n        super();\n        this.learningRate = learningRate;\n        this.decay = decay;\n        this.momentum = momentum;\n        this.epsilon = epsilon;\n        this.accumulatedMeanSquares = [];\n        this.accumulatedMoments = [];\n        this.accumulatedMeanGrads = [];\n        this.centered = centered;\n        if (epsilon == null) {\n            this.epsilon = ENGINE.backend.epsilon();\n        }\n        if (learningRate == null) {\n            throw new Error(`learningRate for RMSPropOptimizer must be defined.`);\n        }\n    }\n    applyGradients(variableGradients) {\n        const variableNames = Array.isArray(variableGradients) ?\n            variableGradients.map(item => item.name) :\n            Object.keys(variableGradients);\n        variableNames.forEach((name, i) => {\n            const value = ENGINE.registeredVariables[name];\n            const trainable = false;\n            if (this.accumulatedMeanSquares[i] == null) {\n                this.accumulatedMeanSquares[i] = {\n                    originalName: `${name}/rms`,\n                    variable: tidy(() => zerosLike(value).variable(trainable))\n                };\n            }\n            if (this.accumulatedMoments[i] == null) {\n                this.accumulatedMoments[i] = {\n                    originalName: `${name}/momentum`,\n                    variable: tidy(() => zerosLike(value).variable(trainable))\n                };\n            }\n            if (this.accumulatedMeanGrads[i] == null && this.centered) {\n                this.accumulatedMeanGrads[i] = {\n                    originalName: `${name}/mg`,\n                    variable: tidy(() => zerosLike(value).variable(trainable))\n                };\n            }\n            const gradient = Array.isArray(variableGradients) ?\n                variableGradients[i].tensor :\n                variableGradients[name];\n            if (gradient == null) {\n                return;\n            }\n            const accumulatedMeanSquare = this.accumulatedMeanSquares[i].variable;\n            const accumulatedMoments = this.accumulatedMoments[i].variable;\n            tidy(() => {\n                const newAccumulatedMeanSquare = add(mul(accumulatedMeanSquare, this.decay), mul(square(gradient), 1 - this.decay));\n                if (this.centered) {\n                    const accumulatedMeanGrad = this.accumulatedMeanGrads[i].variable;\n                    // Centered gradient\n                    const newAccumulatedMeanGrad = add(mul(accumulatedMeanGrad, this.decay), mul(gradient, 1 - this.decay));\n                    const gradContribution = div(mul(gradient, this.learningRate), sqrt(sub(newAccumulatedMeanSquare, add(square(newAccumulatedMeanGrad), this.epsilon))));\n                    const newAccumulatedMoments = add(mul(accumulatedMoments, this.momentum), gradContribution);\n                    accumulatedMeanSquare.assign(newAccumulatedMeanSquare);\n                    accumulatedMeanGrad.assign(newAccumulatedMeanGrad);\n                    accumulatedMoments.assign(newAccumulatedMoments);\n                    const newValue = sub(value, newAccumulatedMoments);\n                    value.assign(newValue);\n                }\n                else {\n                    // Plain gradient\n                    const newAccumulatedMeanSquare = add(mul(accumulatedMeanSquare, this.decay), mul(square(gradient), 1 - this.decay));\n                    const newAccumulatedMoments = add(mul(accumulatedMoments, this.momentum), div(mul(gradient, this.learningRate), sqrt(add(newAccumulatedMeanSquare, this.epsilon))));\n                    accumulatedMeanSquare.assign(newAccumulatedMeanSquare);\n                    accumulatedMoments.assign(newAccumulatedMoments);\n                    const newValue = sub(value, newAccumulatedMoments);\n                    value.assign(newValue);\n                }\n            });\n        });\n        this.incrementIterations();\n    }\n    dispose() {\n        if (this.accumulatedMeanSquares != null) {\n            dispose(this.accumulatedMeanSquares.map(v => v.variable));\n        }\n        if (this.accumulatedMeanGrads != null && this.centered) {\n            dispose(this.accumulatedMeanGrads.map(v => v.variable));\n        }\n        if (this.accumulatedMoments != null) {\n            dispose(this.accumulatedMoments.map(v => v.variable));\n        }\n    }\n    async getWeights() {\n        // Order matters for Python compatibility.\n        const variables = [...this.accumulatedMeanSquares, ...this.accumulatedMoments];\n        if (this.centered) {\n            variables.push(...this.accumulatedMeanGrads);\n        }\n        return [await this.saveIterations()].concat(variables.map(v => ({ name: v.originalName, tensor: v.variable })));\n    }\n    async setWeights(weightValues) {\n        weightValues = await this.extractIterations(weightValues);\n        const variableCount = this.centered ? weightValues.length / 3 : weightValues.length / 2;\n        const trainable = false;\n        this.accumulatedMeanSquares =\n            weightValues.slice(0, variableCount).map(v => ({\n                originalName: v.name,\n                variable: v.tensor.variable(trainable)\n            }));\n        this.accumulatedMoments =\n            weightValues.slice(variableCount, variableCount * 2)\n                .map(v => ({\n                originalName: v.name,\n                variable: v.tensor.variable(trainable)\n            }));\n        if (this.centered) {\n            this.accumulatedMeanGrads =\n                weightValues.slice(variableCount * 2, variableCount * 3)\n                    .map(v => ({\n                    originalName: v.name,\n                    variable: v.tensor.variable(trainable)\n                }));\n        }\n    }\n    getConfig() {\n        return {\n            'learningRate': this.learningRate,\n            'decay': this.decay,\n            'momentum': this.momentum,\n            'epsilon': this.epsilon,\n            'centered': this.centered\n        };\n    }\n    /** @nocollapse */\n    static fromConfig(cls, config) {\n        return new cls(config['learningRate'], config['decay'], config['momentum'], config['epsilon'], config['centered']);\n    }\n}\n/** @nocollapse */\nRMSPropOptimizer.className = 'RMSProp'; // Note: Name matters for Python compatibility.\nregisterClass(RMSPropOptimizer);\n"]},"metadata":{},"sourceType":"module"}