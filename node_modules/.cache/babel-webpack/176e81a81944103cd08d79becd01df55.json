{"ast":null,"code":"import _asyncToGenerator from \"/Users/ryanliang/Downloads/main_movir_picker/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\n\n/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * Interfaces and methods for training models using tf.Tensor objects.\n */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { Tensor, tensor1d, util } from '@tensorflow/tfjs-core';\nimport { expandDims, gather, sliceAlongFirstAxis } from '../backend/tfjs_backend';\nimport { configureCallbacks, standardizeCallbacks } from '../base_callbacks';\nimport { NotImplementedError, ValueError } from '../errors';\nimport { disposeTensorsInLogs } from '../logs';\nimport { range } from '../utils/math_utils';\nexport function checkBatchSize(batchSize) {\n  tfc.util.assert(batchSize > 0 && Number.isInteger(batchSize), () => `batchSize is required to be a positive integer, but got ${batchSize}`);\n}\n/**\n * Slice a Tensor or an Array of Tensors, by start and stop indices.\n *\n * Porting Note: The `_slice_arrays` function in PyKeras is covered by this\n *   function and `sliceArraysByIndices()` together.\n *\n * @param arrays: the input.\n * @param start: the starting index (inclusive).\n * @param stop: the stopping index (exclusive).\n * @returns The result of the slicing. If `arrays` is an `Array` of\n *   `tf.Tensor`s, the slicing will be applied to all elements of the `Array`\n *   in the same way.\n */\n\nexport function sliceArrays(arrays, start, stop) {\n  if (arrays == null) {\n    return [null];\n  } else if (Array.isArray(arrays)) {\n    return arrays.map(array => sliceAlongFirstAxis(array, start, stop - start));\n  } else {\n    // Tensor.\n    return sliceAlongFirstAxis(arrays, start, stop - start);\n  }\n}\n/**\n * Slice a Tensor or an Array of Tensors, by random-order indices.\n *\n * Porting Note: The `_slice_arrays` function in PyKeras is covered by this\n *   function and `sliceArrays()` together.\n *\n * @param arrays The input `tf.Tensor` or `Array` of `tf.Tensor`s to slice.\n *   If an `Array` of `tf.Tensor`s, all `tf.Tensor`s will be sliced in the\n *   same fashion.\n * @param indices The indices to use for slicing along the first (batch)\n *   dimension.\n * @returns Result(s) of the slicing.\n */\n\nexport function sliceArraysByIndices(arrays, indices) {\n  return tfc.tidy(() => {\n    if (arrays == null) {\n      return null;\n    } else if (Array.isArray(arrays)) {\n      return arrays.map(array => sliceArraysByIndices(array, indices));\n    } else {\n      // TODO(cais): indices should be a pre-constructed Tensor1D to avoid\n      //   tensor1d() calls.\n      return gather(arrays, indices.dtype === 'int32' ? indices : indices.toInt());\n    }\n  });\n}\n/**\n * Returns a list of batch indices (tuples of indices).\n * @param size: Integer, total size of the data to slice into batches.\n * @param batchSize: Integer, batch size.\n * @returns An Array of [batchStart, batchEnd] tuples. batchStart is\n *   inclusive; batchEnd is exclusive. I.e., each batch consists of indices x\n *   that satisfy batchStart <= x < batchEnd.\n */\n\nexport function makeBatches(size, batchSize) {\n  const output = [];\n  let batchStart = 0;\n  let batchEnd = null;\n\n  while (batchStart < size) {\n    batchEnd = batchStart + batchSize;\n\n    if (batchEnd >= size) {\n      batchEnd = size;\n    }\n\n    output.push([batchStart, batchEnd]);\n    batchStart = batchEnd;\n  }\n\n  return output;\n}\n/**\n * Abstract fit function for `f(ins)`.\n * @param f A Function returning a list of tensors. For training, this\n *   function is expected to perform the updates to the variables.\n * @param ins List of tensors to be fed to `f`.\n * @param outLabels List of strings, display names of the outputs of `f`.\n * @param batchSize Integer batch size or `== null` if unknown. Default : 32.\n * @param epochs Number of times to iterate over the data. Default : 1.\n * @param verbose Verbosity mode: 0, 1, or 2. Default: 1.\n * @param callbacks List of callbacks to be called during training.\n * @param valF Function to call for validation.\n * @param valIns List of tensors to be fed to `valF`.\n * @param shuffle Whether to shuffle the data at the beginning of every\n * epoch. Default : true.\n * @param callbackMetrics List of strings, the display names of the metrics\n *   passed to the callbacks. They should be the concatenation of the\n *   display names of the outputs of `f` and the list of display names\n *   of the outputs of `valF`.\n * @param initialEpoch Epoch at which to start training (useful for\n *   resuming a previous training run). Default : 0.\n * @param stepsPerEpoch Total number of steps (batches on samples) before\n *   declaring one epoch finished and starting the next epoch. Ignored with\n *   the default value of `undefined` or `null`.\n * @param validationSteps Number of steps to run validation for (only if\n *   doing validation from data tensors). Not applicable for tfjs-layers.\n * @returns A `History` object.\n */\n\nfunction fitLoop(_x, _x2, _x3, _x4, _x5, _x6, _x7, _x8, _x9, _x10, _x11, _x12, _x13, _x14, _x15) {\n  return _fitLoop.apply(this, arguments);\n}\n\nfunction _fitLoop() {\n  _fitLoop = _asyncToGenerator(function* ( // Type `model` as `any` here to avoid circular dependency w/ training.ts.\n  // tslint:disable-next-line:no-any\n  model, f, ins, outLabels, batchSize, epochs, verbose, callbacks, valF, valIns, shuffle, callbackMetrics, initialEpoch, stepsPerEpoch, validationSteps) {\n    if (batchSize == null) {\n      batchSize = 32;\n    }\n\n    if (epochs == null) {\n      epochs = 1;\n    }\n\n    if (shuffle == null) {\n      shuffle = true;\n    }\n\n    if (initialEpoch == null) {\n      initialEpoch = 0;\n    } // TODO(cais): Change const to let below when implementing validation.\n\n\n    let doValidation = false;\n\n    if (valF != null && valIns != null) {\n      doValidation = true; // TODO(cais): verbose message.\n    }\n\n    if (validationSteps != null) {\n      doValidation = true;\n\n      if (stepsPerEpoch == null) {\n        throw new ValueError('Can only use `validationSteps` when doing step-wise training, ' + 'i.e., `stepsPerEpoch` must be set.');\n      }\n    }\n\n    const numTrainSamples = model.checkNumSamples(ins, batchSize, stepsPerEpoch, 'steps_per_epoch');\n    let indexArray;\n\n    if (numTrainSamples != null) {\n      indexArray = range(0, numTrainSamples);\n    }\n\n    if (verbose == null) {\n      verbose = 1;\n    }\n\n    const {\n      callbackList,\n      history\n    } = configureCallbacks(callbacks, verbose, epochs, initialEpoch, numTrainSamples, stepsPerEpoch, batchSize, doValidation, callbackMetrics);\n    callbackList.setModel(model);\n    model.history = history;\n    yield callbackList.onTrainBegin();\n    model.stopTraining_ = false; // TODO(cais): Take care of callbacks.validation_data as in PyKeras.\n    // TODO(cais): Pre-convert feeds for performance as in PyKeras.\n\n    for (let epoch = initialEpoch; epoch < epochs; ++epoch) {\n      yield callbackList.onEpochBegin(epoch);\n      const epochLogs = {};\n\n      if (stepsPerEpoch != null) {\n        throw new NotImplementedError('stepsPerEpoch mode is not implemented yet.');\n      } else {\n        if (shuffle === 'batch') {\n          throw new NotImplementedError('batch shuffling is not implemneted yet');\n        } else if (shuffle) {\n          util.shuffle(indexArray);\n        } // Convert the potentially shuffled indices to Tensor1D, to avoid the\n        // cost of repeated creation of Array1Ds later on.\n\n\n        const epochIndexArray1D = tensor1d(indexArray);\n        const batches = makeBatches(numTrainSamples, batchSize);\n\n        for (let batchIndex = 0; batchIndex < batches.length; ++batchIndex) {\n          const batchLogs = {};\n          yield callbackList.onBatchBegin(batchIndex, batchLogs);\n          tfc.tidy(() => {\n            const batchStart = batches[batchIndex][0];\n            const batchEnd = batches[batchIndex][1];\n            const batchIds = sliceAlongFirstAxis(epochIndexArray1D, batchStart, batchEnd - batchStart);\n            batchLogs['batch'] = batchIndex;\n            batchLogs['size'] = batchEnd - batchStart; // TODO(cais): In ins, train flag can be a number, instead of an\n            //   Tensor? Do we need to handle this in tfjs-layers?\n\n            const insBatch = sliceArraysByIndices(ins, batchIds);\n            const outs = f(insBatch);\n\n            for (let i = 0; i < outLabels.length; ++i) {\n              const label = outLabels[i];\n              const out = outs[i];\n              batchLogs[label] = out;\n              tfc.keep(out); // TODO(cais): Use scope() to avoid ownership.\n            }\n\n            if (batchIndex === batches.length - 1) {\n              // Last batch.\n              if (doValidation) {\n                const valOuts = model.testLoop(valF, valIns, batchSize); // Porting Notes: In tfjs-layers, valOuts is always an Array.\n\n                for (let i = 0; i < outLabels.length; ++i) {\n                  const label = outLabels[i];\n                  const out = valOuts[i];\n                  tfc.keep(out); // TODO(cais): Use scope() to avoid ownership.\n\n                  epochLogs['val_' + label] = out;\n                }\n              }\n            }\n          });\n          yield callbackList.onBatchEnd(batchIndex, batchLogs);\n          disposeTensorsInLogs(batchLogs);\n\n          if (model.stopTraining_) {\n            break;\n          } // TODO(cais): return outs as list of Tensor.\n\n        }\n\n        epochIndexArray1D.dispose();\n      } // TODO(cais): Run validation at the end of the epoch.\n\n\n      yield callbackList.onEpochEnd(epoch, epochLogs);\n\n      if (model.stopTraining_) {\n        break;\n      }\n    }\n\n    yield callbackList.onTrainEnd();\n    yield model.history.syncData();\n    return model.history;\n  });\n  return _fitLoop.apply(this, arguments);\n}\n\nexport function fitTensors(_x16, _x17, _x18) {\n  return _fitTensors.apply(this, arguments);\n}\n/**\n * Ensure tensors all have a rank of at least 2.\n *\n * If a tensor has a rank of 1, it is dimension-expanded to rank 2.\n * If any tensor has a rank of 0 (i.e., is a scalar), an error will be thrown.\n */\n\nfunction _fitTensors() {\n  _fitTensors = _asyncToGenerator(function* ( // Type `model` as `any` here to avoid circular dependency w/ training.ts.\n  // tslint:disable-next-line:no-any\n  model, x, y, args = {}) {\n    if (model.isTraining) {\n      throw new Error('Cannot start training because another fit() call is ongoing.');\n    }\n\n    model.isTraining = true;\n    let inputs;\n    let targets;\n    let inputValX;\n    let inputValY;\n    let valX;\n    let valY;\n    let sampleWeights;\n\n    try {\n      const batchSize = args.batchSize == null ? 32 : args.batchSize;\n      checkBatchSize(batchSize); // Validate user data.\n      // TODO(cais): Support sampleWeight.\n\n      const checkBatchAxis = false;\n      const standardizedOuts = yield model.standardizeUserData(x, y, args.sampleWeight, args.classWeight, checkBatchAxis, batchSize);\n      inputs = standardizedOuts[0];\n      targets = standardizedOuts[1];\n      sampleWeights = standardizedOuts[2]; // Prepare validation data.\n\n      let doValidation = false;\n      let valIns;\n\n      if (args.validationData != null && args.validationData.length > 0) {\n        doValidation = true;\n\n        if (args.validationData.length === 2) {\n          // config.validationData consists of valX and valY.\n          inputValX = args.validationData[0];\n          inputValY = args.validationData[1];\n        } else if (args.validationData.length === 3) {\n          throw new NotImplementedError('validationData including sample weights is not supported yet.');\n        } else {\n          throw new ValueError(`When passing validation data, it must contain 2 (valX, valY) ` + `or 3 (valX, valY, valSampleWeight) items; ` + `${args.validationData} is invalid.`);\n        }\n\n        const checkBatchAxis = true;\n        const valStandardized = yield model.standardizeUserData(inputValX, inputValY, null,\n        /** Unused sample weights. */\n        null,\n        /** Unused class weights. */\n        checkBatchAxis, batchSize);\n        valX = valStandardized[0];\n        valY = valStandardized[1];\n        valIns = valX.concat(valY); // TODO(cais): Add useLearningPhase data properly.\n      } else if (args.validationSplit != null && args.validationSplit > 0 && args.validationSplit < 1) {\n        doValidation = true; // Porting Note: In tfjs-layers, inputs[0] is always a Tensor.\n\n        const splitAt = Math.floor(inputs[0].shape[0] * (1 - args.validationSplit));\n        const originalBatchSize = inputs[0].shape[0];\n        valX = sliceArrays(inputs, splitAt, originalBatchSize);\n        inputs = sliceArrays(inputs, 0, splitAt);\n        valY = sliceArrays(targets, splitAt, originalBatchSize);\n        targets = sliceArrays(targets, 0, splitAt); // TODO(cais): Once sampleWeights becomes available, slice it to get\n        //   valSampleWeights.\n\n        valIns = valX.concat(valY); // TODO(cais): Add useLearningPhase data properly.\n      } else if (args.validationSteps != null) {\n        doValidation = true; // TODO(cais): Add useLearningPhase.\n      }\n\n      const ins = inputs.concat(targets).concat(sampleWeights);\n      model.checkTrainableWeightsConsistency(); // TODO(cais): Handle use_learning_phase and learning_phase?\n      // Porting Note: Here we see a key deviation of tfjs-layers from\n      // Keras.\n      //  Due to the imperative nature of tfjs-layers' backend (tfjs-core),\n      //  we do not construct symbolic computation graphs to embody the\n      //  training process. Instead, we define a function that performs the\n      //  training action. In PyKeras, the data (inputs and targets) are fed\n      //  through graph placeholders. In tfjs-layers, the data are fed as\n      //  function arguments. Since the function are defined below in the\n      //  scope, we don't have equivalents of PyKeras's\n      //  `_make_train_funciton`.\n\n      const trainFunction = model.makeTrainFunction();\n      const outLabels = model.getDedupedMetricsNames();\n      let valFunction;\n      let callbackMetrics;\n\n      if (doValidation) {\n        model.makeTestFunction();\n        valFunction = model.testFunction;\n        callbackMetrics = outLabels.slice().concat(outLabels.map(n => 'val_' + n));\n      } else {\n        valFunction = null;\n        valIns = [];\n        callbackMetrics = outLabels.slice();\n      }\n\n      const callbacks = standardizeCallbacks(args.callbacks, args.yieldEvery);\n      const out = yield fitLoop(model, trainFunction, ins, outLabels, batchSize, args.epochs, args.verbose, callbacks, valFunction, valIns, args.shuffle, callbackMetrics, args.initialEpoch, null, null);\n      return out;\n    } finally {\n      model.isTraining = false; // Memory clean up.\n\n      disposeNewTensors(inputs, x);\n      disposeNewTensors(targets, y);\n      disposeNewTensors(valX, inputValX);\n      disposeNewTensors(valY, inputValY);\n\n      if (sampleWeights != null) {\n        tfc.dispose(sampleWeights);\n      }\n    } // TODO(cais): Add value to outLabels.\n\n  });\n  return _fitTensors.apply(this, arguments);\n}\n\nexport function ensureTensorsRank2OrHigher(tensors) {\n  const outs = [];\n\n  if (tensors instanceof Tensor) {\n    tensors = [tensors];\n  } // Make Tensors at least 2D.\n\n\n  for (let i = 0; i < tensors.length; ++i) {\n    const tensor = tensors[i];\n\n    if (tensor.rank === 1) {\n      outs.push(expandDims(tensor, 1));\n    } else if (tensor.rank === 0) {\n      throw new Error('Expected tensor to be at least 1D, but received a 0D tensor ' + '(scalar).');\n    } else {\n      outs.push(tensor);\n    }\n  }\n\n  return outs;\n}\n/**\n * Compare a set of tensors with a reference (old) set, discard the ones\n * in the new set that are not present in the reference set.\n *\n * This method is used for memory clenaup during calls such as\n * LayersModel.fit().\n *\n * @param tensors New set which may contain Tensors not present in\n *   `refTensors`.\n * @param refTensors Reference Tensor set.\n */\n// TODO(cais, kangyizhang): Deduplicate with tfjs-data.\n\nexport function disposeNewTensors(tensors, refTensors) {\n  if (tensors == null) {\n    return;\n  }\n\n  const oldTensorIds = [];\n\n  if (refTensors instanceof Tensor) {\n    oldTensorIds.push(refTensors.id);\n  } else if (Array.isArray(refTensors)) {\n    refTensors.forEach(t => oldTensorIds.push(t.id));\n  } else if (refTensors != null) {\n    // `oldTensors` is a map from string name to Tensor.\n    for (const name in refTensors) {\n      const oldTensor = refTensors[name];\n      oldTensorIds.push(oldTensor.id);\n    }\n  }\n\n  const tensorsToDispose = [];\n\n  if (tensors instanceof Tensor) {\n    if (oldTensorIds.indexOf(tensors.id) === -1) {\n      tensorsToDispose.push(tensors);\n    }\n  } else if (Array.isArray(tensors)) {\n    tensors.forEach(t => {\n      if (oldTensorIds.indexOf(t.id) === -1) {\n        tensorsToDispose.push(t);\n      }\n    });\n  } else if (tensors != null) {\n    // `oldTensors` is a map from string name to Tensor.\n    for (const name in tensors) {\n      const tensor = tensors[name];\n\n      if (oldTensorIds.indexOf(tensor.id) === -1) {\n        tensorsToDispose.push(tensor);\n      }\n    }\n  }\n\n  tensorsToDispose.forEach(t => {\n    if (!t.isDisposed) {\n      t.dispose();\n    }\n  });\n}","map":{"version":3,"sources":["/Users/ryanliang/Downloads/main_movir_picker/node_modules/@tensorflow/tfjs-layers/dist/engine/training_tensors.js"],"names":["tfc","Tensor","tensor1d","util","expandDims","gather","sliceAlongFirstAxis","configureCallbacks","standardizeCallbacks","NotImplementedError","ValueError","disposeTensorsInLogs","range","checkBatchSize","batchSize","assert","Number","isInteger","sliceArrays","arrays","start","stop","Array","isArray","map","array","sliceArraysByIndices","indices","tidy","dtype","toInt","makeBatches","size","output","batchStart","batchEnd","push","fitLoop","model","f","ins","outLabels","epochs","verbose","callbacks","valF","valIns","shuffle","callbackMetrics","initialEpoch","stepsPerEpoch","validationSteps","doValidation","numTrainSamples","checkNumSamples","indexArray","callbackList","history","setModel","onTrainBegin","stopTraining_","epoch","onEpochBegin","epochLogs","epochIndexArray1D","batches","batchIndex","length","batchLogs","onBatchBegin","batchIds","insBatch","outs","i","label","out","keep","valOuts","testLoop","onBatchEnd","dispose","onEpochEnd","onTrainEnd","syncData","fitTensors","x","y","args","isTraining","Error","inputs","targets","inputValX","inputValY","valX","valY","sampleWeights","checkBatchAxis","standardizedOuts","standardizeUserData","sampleWeight","classWeight","validationData","valStandardized","concat","validationSplit","splitAt","Math","floor","shape","originalBatchSize","checkTrainableWeightsConsistency","trainFunction","makeTrainFunction","getDedupedMetricsNames","valFunction","makeTestFunction","testFunction","slice","n","yieldEvery","disposeNewTensors","ensureTensorsRank2OrHigher","tensors","tensor","rank","refTensors","oldTensorIds","id","forEach","t","name","oldTensor","tensorsToDispose","indexOf","isDisposed"],"mappings":";;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA;AACA;AACA;AACA,OAAO,KAAKA,GAAZ,MAAqB,uBAArB;AACA,SAASC,MAAT,EAAiBC,QAAjB,EAA2BC,IAA3B,QAAuC,uBAAvC;AACA,SAASC,UAAT,EAAqBC,MAArB,EAA6BC,mBAA7B,QAAwD,yBAAxD;AACA,SAASC,kBAAT,EAA6BC,oBAA7B,QAAyD,mBAAzD;AACA,SAASC,mBAAT,EAA8BC,UAA9B,QAAgD,WAAhD;AACA,SAASC,oBAAT,QAAqC,SAArC;AACA,SAASC,KAAT,QAAsB,qBAAtB;AACA,OAAO,SAASC,cAAT,CAAwBC,SAAxB,EAAmC;AACtCd,EAAAA,GAAG,CAACG,IAAJ,CAASY,MAAT,CAAgBD,SAAS,GAAG,CAAZ,IAAiBE,MAAM,CAACC,SAAP,CAAiBH,SAAjB,CAAjC,EAA8D,MAAO,2DAA0DA,SAAU,EAAzI;AACH;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASI,WAAT,CAAqBC,MAArB,EAA6BC,KAA7B,EAAoCC,IAApC,EAA0C;AAC7C,MAAIF,MAAM,IAAI,IAAd,EAAoB;AAChB,WAAO,CAAC,IAAD,CAAP;AACH,GAFD,MAGK,IAAIG,KAAK,CAACC,OAAN,CAAcJ,MAAd,CAAJ,EAA2B;AAC5B,WAAOA,MAAM,CAACK,GAAP,CAAWC,KAAK,IAAInB,mBAAmB,CAACmB,KAAD,EAAQL,KAAR,EAAeC,IAAI,GAAGD,KAAtB,CAAvC,CAAP;AACH,GAFI,MAGA;AAAE;AACH,WAAOd,mBAAmB,CAACa,MAAD,EAASC,KAAT,EAAgBC,IAAI,GAAGD,KAAvB,CAA1B;AACH;AACJ;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASM,oBAAT,CAA8BP,MAA9B,EAAsCQ,OAAtC,EAA+C;AAClD,SAAO3B,GAAG,CAAC4B,IAAJ,CAAS,MAAM;AAClB,QAAIT,MAAM,IAAI,IAAd,EAAoB;AAChB,aAAO,IAAP;AACH,KAFD,MAGK,IAAIG,KAAK,CAACC,OAAN,CAAcJ,MAAd,CAAJ,EAA2B;AAC5B,aAAOA,MAAM,CAACK,GAAP,CAAWC,KAAK,IAAIC,oBAAoB,CAACD,KAAD,EAAQE,OAAR,CAAxC,CAAP;AACH,KAFI,MAGA;AACD;AACA;AACA,aAAOtB,MAAM,CAACc,MAAD,EAASQ,OAAO,CAACE,KAAR,KAAkB,OAAlB,GAA4BF,OAA5B,GAAsCA,OAAO,CAACG,KAAR,EAA/C,CAAb;AACH;AACJ,GAZM,CAAP;AAaH;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASC,WAAT,CAAqBC,IAArB,EAA2BlB,SAA3B,EAAsC;AACzC,QAAMmB,MAAM,GAAG,EAAf;AACA,MAAIC,UAAU,GAAG,CAAjB;AACA,MAAIC,QAAQ,GAAG,IAAf;;AACA,SAAOD,UAAU,GAAGF,IAApB,EAA0B;AACtBG,IAAAA,QAAQ,GAAGD,UAAU,GAAGpB,SAAxB;;AACA,QAAIqB,QAAQ,IAAIH,IAAhB,EAAsB;AAClBG,MAAAA,QAAQ,GAAGH,IAAX;AACH;;AACDC,IAAAA,MAAM,CAACG,IAAP,CAAY,CAACF,UAAD,EAAaC,QAAb,CAAZ;AACAD,IAAAA,UAAU,GAAGC,QAAb;AACH;;AACD,SAAOF,MAAP;AACH;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;SACeI,O;;;;;+BAAf,YACA;AACA;AACAC,EAAAA,KAHA,EAGOC,CAHP,EAGUC,GAHV,EAGeC,SAHf,EAG0B3B,SAH1B,EAGqC4B,MAHrC,EAG6CC,OAH7C,EAGsDC,SAHtD,EAGiEC,IAHjE,EAGuEC,MAHvE,EAG+EC,OAH/E,EAGwFC,eAHxF,EAGyGC,YAHzG,EAGuHC,aAHvH,EAGsIC,eAHtI,EAGuJ;AACnJ,QAAIrC,SAAS,IAAI,IAAjB,EAAuB;AACnBA,MAAAA,SAAS,GAAG,EAAZ;AACH;;AACD,QAAI4B,MAAM,IAAI,IAAd,EAAoB;AAChBA,MAAAA,MAAM,GAAG,CAAT;AACH;;AACD,QAAIK,OAAO,IAAI,IAAf,EAAqB;AACjBA,MAAAA,OAAO,GAAG,IAAV;AACH;;AACD,QAAIE,YAAY,IAAI,IAApB,EAA0B;AACtBA,MAAAA,YAAY,GAAG,CAAf;AACH,KAZkJ,CAanJ;;;AACA,QAAIG,YAAY,GAAG,KAAnB;;AACA,QAAIP,IAAI,IAAI,IAAR,IAAgBC,MAAM,IAAI,IAA9B,EAAoC;AAChCM,MAAAA,YAAY,GAAG,IAAf,CADgC,CAEhC;AACH;;AACD,QAAID,eAAe,IAAI,IAAvB,EAA6B;AACzBC,MAAAA,YAAY,GAAG,IAAf;;AACA,UAAIF,aAAa,IAAI,IAArB,EAA2B;AACvB,cAAM,IAAIxC,UAAJ,CAAe,mEACjB,oCADE,CAAN;AAEH;AACJ;;AACD,UAAM2C,eAAe,GAAGf,KAAK,CAACgB,eAAN,CAAsBd,GAAtB,EAA2B1B,SAA3B,EAAsCoC,aAAtC,EAAqD,iBAArD,CAAxB;AACA,QAAIK,UAAJ;;AACA,QAAIF,eAAe,IAAI,IAAvB,EAA6B;AACzBE,MAAAA,UAAU,GAAG3C,KAAK,CAAC,CAAD,EAAIyC,eAAJ,CAAlB;AACH;;AACD,QAAIV,OAAO,IAAI,IAAf,EAAqB;AACjBA,MAAAA,OAAO,GAAG,CAAV;AACH;;AACD,UAAM;AAAEa,MAAAA,YAAF;AAAgBC,MAAAA;AAAhB,QAA4BlD,kBAAkB,CAACqC,SAAD,EAAYD,OAAZ,EAAqBD,MAArB,EAA6BO,YAA7B,EAA2CI,eAA3C,EAA4DH,aAA5D,EAA2EpC,SAA3E,EAAsFsC,YAAtF,EAAoGJ,eAApG,CAApD;AACAQ,IAAAA,YAAY,CAACE,QAAb,CAAsBpB,KAAtB;AACAA,IAAAA,KAAK,CAACmB,OAAN,GAAgBA,OAAhB;AACA,UAAMD,YAAY,CAACG,YAAb,EAAN;AACArB,IAAAA,KAAK,CAACsB,aAAN,GAAsB,KAAtB,CAtCmJ,CAuCnJ;AACA;;AACA,SAAK,IAAIC,KAAK,GAAGZ,YAAjB,EAA+BY,KAAK,GAAGnB,MAAvC,EAA+C,EAAEmB,KAAjD,EAAwD;AACpD,YAAML,YAAY,CAACM,YAAb,CAA0BD,KAA1B,CAAN;AACA,YAAME,SAAS,GAAG,EAAlB;;AACA,UAAIb,aAAa,IAAI,IAArB,EAA2B;AACvB,cAAM,IAAIzC,mBAAJ,CAAwB,4CAAxB,CAAN;AACH,OAFD,MAGK;AACD,YAAIsC,OAAO,KAAK,OAAhB,EAAyB;AACrB,gBAAM,IAAItC,mBAAJ,CAAwB,wCAAxB,CAAN;AACH,SAFD,MAGK,IAAIsC,OAAJ,EAAa;AACd5C,UAAAA,IAAI,CAAC4C,OAAL,CAAaQ,UAAb;AACH,SANA,CAOD;AACA;;;AACA,cAAMS,iBAAiB,GAAG9D,QAAQ,CAACqD,UAAD,CAAlC;AACA,cAAMU,OAAO,GAAGlC,WAAW,CAACsB,eAAD,EAAkBvC,SAAlB,CAA3B;;AACA,aAAK,IAAIoD,UAAU,GAAG,CAAtB,EAAyBA,UAAU,GAAGD,OAAO,CAACE,MAA9C,EAAsD,EAAED,UAAxD,EAAoE;AAChE,gBAAME,SAAS,GAAG,EAAlB;AACA,gBAAMZ,YAAY,CAACa,YAAb,CAA0BH,UAA1B,EAAsCE,SAAtC,CAAN;AACApE,UAAAA,GAAG,CAAC4B,IAAJ,CAAS,MAAM;AACX,kBAAMM,UAAU,GAAG+B,OAAO,CAACC,UAAD,CAAP,CAAoB,CAApB,CAAnB;AACA,kBAAM/B,QAAQ,GAAG8B,OAAO,CAACC,UAAD,CAAP,CAAoB,CAApB,CAAjB;AACA,kBAAMI,QAAQ,GAAGhE,mBAAmB,CAAC0D,iBAAD,EAAoB9B,UAApB,EAAgCC,QAAQ,GAAGD,UAA3C,CAApC;AACAkC,YAAAA,SAAS,CAAC,OAAD,CAAT,GAAqBF,UAArB;AACAE,YAAAA,SAAS,CAAC,MAAD,CAAT,GAAoBjC,QAAQ,GAAGD,UAA/B,CALW,CAMX;AACA;;AACA,kBAAMqC,QAAQ,GAAG7C,oBAAoB,CAACc,GAAD,EAAM8B,QAAN,CAArC;AACA,kBAAME,IAAI,GAAGjC,CAAC,CAACgC,QAAD,CAAd;;AACA,iBAAK,IAAIE,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGhC,SAAS,CAAC0B,MAA9B,EAAsC,EAAEM,CAAxC,EAA2C;AACvC,oBAAMC,KAAK,GAAGjC,SAAS,CAACgC,CAAD,CAAvB;AACA,oBAAME,GAAG,GAAGH,IAAI,CAACC,CAAD,CAAhB;AACAL,cAAAA,SAAS,CAACM,KAAD,CAAT,GAAmBC,GAAnB;AACA3E,cAAAA,GAAG,CAAC4E,IAAJ,CAASD,GAAT,EAJuC,CAKvC;AACH;;AACD,gBAAIT,UAAU,KAAKD,OAAO,CAACE,MAAR,GAAiB,CAApC,EAAuC;AAAE;AACrC,kBAAIf,YAAJ,EAAkB;AACd,sBAAMyB,OAAO,GAAGvC,KAAK,CAACwC,QAAN,CAAejC,IAAf,EAAqBC,MAArB,EAA6BhC,SAA7B,CAAhB,CADc,CAEd;;AACA,qBAAK,IAAI2D,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGhC,SAAS,CAAC0B,MAA9B,EAAsC,EAAEM,CAAxC,EAA2C;AACvC,wBAAMC,KAAK,GAAGjC,SAAS,CAACgC,CAAD,CAAvB;AACA,wBAAME,GAAG,GAAGE,OAAO,CAACJ,CAAD,CAAnB;AACAzE,kBAAAA,GAAG,CAAC4E,IAAJ,CAASD,GAAT,EAHuC,CAIvC;;AACAZ,kBAAAA,SAAS,CAAC,SAASW,KAAV,CAAT,GAA4BC,GAA5B;AACH;AACJ;AACJ;AACJ,WA9BD;AA+BA,gBAAMnB,YAAY,CAACuB,UAAb,CAAwBb,UAAxB,EAAoCE,SAApC,CAAN;AACAzD,UAAAA,oBAAoB,CAACyD,SAAD,CAApB;;AACA,cAAI9B,KAAK,CAACsB,aAAV,EAAyB;AACrB;AACH,WAtC+D,CAuChE;;AACH;;AACDI,QAAAA,iBAAiB,CAACgB,OAAlB;AACH,OA3DmD,CA4DpD;;;AACA,YAAMxB,YAAY,CAACyB,UAAb,CAAwBpB,KAAxB,EAA+BE,SAA/B,CAAN;;AACA,UAAIzB,KAAK,CAACsB,aAAV,EAAyB;AACrB;AACH;AACJ;;AACD,UAAMJ,YAAY,CAAC0B,UAAb,EAAN;AACA,UAAM5C,KAAK,CAACmB,OAAN,CAAc0B,QAAd,EAAN;AACA,WAAO7C,KAAK,CAACmB,OAAb;AACH,G;;;;AACD,gBAAsB2B,UAAtB;AAAA;AAAA;AAkHA;AACA;AACA;AACA;AACA;AACA;;;kCAvHO,YACP;AACA;AACA9C,EAAAA,KAHO,EAGA+C,CAHA,EAGGC,CAHH,EAGMC,IAAI,GAAG,EAHb,EAGiB;AACpB,QAAIjD,KAAK,CAACkD,UAAV,EAAsB;AAClB,YAAM,IAAIC,KAAJ,CAAU,8DAAV,CAAN;AACH;;AACDnD,IAAAA,KAAK,CAACkD,UAAN,GAAmB,IAAnB;AACA,QAAIE,MAAJ;AACA,QAAIC,OAAJ;AACA,QAAIC,SAAJ;AACA,QAAIC,SAAJ;AACA,QAAIC,IAAJ;AACA,QAAIC,IAAJ;AACA,QAAIC,aAAJ;;AACA,QAAI;AACA,YAAMlF,SAAS,GAAGyE,IAAI,CAACzE,SAAL,IAAkB,IAAlB,GAAyB,EAAzB,GAA8ByE,IAAI,CAACzE,SAArD;AACAD,MAAAA,cAAc,CAACC,SAAD,CAAd,CAFA,CAGA;AACA;;AACA,YAAMmF,cAAc,GAAG,KAAvB;AACA,YAAMC,gBAAgB,SAAS5D,KAAK,CAAC6D,mBAAN,CAA0Bd,CAA1B,EAA6BC,CAA7B,EAAgCC,IAAI,CAACa,YAArC,EAAmDb,IAAI,CAACc,WAAxD,EAAqEJ,cAArE,EAAqFnF,SAArF,CAA/B;AACA4E,MAAAA,MAAM,GAAGQ,gBAAgB,CAAC,CAAD,CAAzB;AACAP,MAAAA,OAAO,GAAGO,gBAAgB,CAAC,CAAD,CAA1B;AACAF,MAAAA,aAAa,GAAGE,gBAAgB,CAAC,CAAD,CAAhC,CATA,CAUA;;AACA,UAAI9C,YAAY,GAAG,KAAnB;AACA,UAAIN,MAAJ;;AACA,UAAIyC,IAAI,CAACe,cAAL,IAAuB,IAAvB,IAA+Bf,IAAI,CAACe,cAAL,CAAoBnC,MAApB,GAA6B,CAAhE,EAAmE;AAC/Df,QAAAA,YAAY,GAAG,IAAf;;AACA,YAAImC,IAAI,CAACe,cAAL,CAAoBnC,MAApB,KAA+B,CAAnC,EAAsC;AAClC;AACAyB,UAAAA,SAAS,GAAGL,IAAI,CAACe,cAAL,CAAoB,CAApB,CAAZ;AACAT,UAAAA,SAAS,GAAGN,IAAI,CAACe,cAAL,CAAoB,CAApB,CAAZ;AACH,SAJD,MAKK,IAAIf,IAAI,CAACe,cAAL,CAAoBnC,MAApB,KAA+B,CAAnC,EAAsC;AACvC,gBAAM,IAAI1D,mBAAJ,CAAwB,+DAAxB,CAAN;AACH,SAFI,MAGA;AACD,gBAAM,IAAIC,UAAJ,CAAgB,+DAAD,GAChB,4CADgB,GAEhB,GAAE6E,IAAI,CAACe,cAAe,cAFrB,CAAN;AAGH;;AACD,cAAML,cAAc,GAAG,IAAvB;AACA,cAAMM,eAAe,SAASjE,KAAK,CAAC6D,mBAAN,CAA0BP,SAA1B,EAAqCC,SAArC,EAAgD,IAAhD;AAAsD;AAA8B,YAApF;AAA0F;AAA6BI,QAAAA,cAAvH,EAAuInF,SAAvI,CAA9B;AACAgF,QAAAA,IAAI,GAAGS,eAAe,CAAC,CAAD,CAAtB;AACAR,QAAAA,IAAI,GAAGQ,eAAe,CAAC,CAAD,CAAtB;AACAzD,QAAAA,MAAM,GAAGgD,IAAI,CAACU,MAAL,CAAYT,IAAZ,CAAT,CAnB+D,CAoB/D;AACH,OArBD,MAsBK,IAAIR,IAAI,CAACkB,eAAL,IAAwB,IAAxB,IAAgClB,IAAI,CAACkB,eAAL,GAAuB,CAAvD,IACLlB,IAAI,CAACkB,eAAL,GAAuB,CADtB,EACyB;AAC1BrD,QAAAA,YAAY,GAAG,IAAf,CAD0B,CAE1B;;AACA,cAAMsD,OAAO,GAAGC,IAAI,CAACC,KAAL,CAAWlB,MAAM,CAAC,CAAD,CAAN,CAAUmB,KAAV,CAAgB,CAAhB,KAAsB,IAAItB,IAAI,CAACkB,eAA/B,CAAX,CAAhB;AACA,cAAMK,iBAAiB,GAAGpB,MAAM,CAAC,CAAD,CAAN,CAAUmB,KAAV,CAAgB,CAAhB,CAA1B;AACAf,QAAAA,IAAI,GAAG5E,WAAW,CAACwE,MAAD,EAASgB,OAAT,EAAkBI,iBAAlB,CAAlB;AACApB,QAAAA,MAAM,GAAGxE,WAAW,CAACwE,MAAD,EAAS,CAAT,EAAYgB,OAAZ,CAApB;AACAX,QAAAA,IAAI,GAAG7E,WAAW,CAACyE,OAAD,EAAUe,OAAV,EAAmBI,iBAAnB,CAAlB;AACAnB,QAAAA,OAAO,GAAGzE,WAAW,CAACyE,OAAD,EAAU,CAAV,EAAae,OAAb,CAArB,CAR0B,CAS1B;AACA;;AACA5D,QAAAA,MAAM,GAAGgD,IAAI,CAACU,MAAL,CAAYT,IAAZ,CAAT,CAX0B,CAY1B;AACH,OAdI,MAeA,IAAIR,IAAI,CAACpC,eAAL,IAAwB,IAA5B,EAAkC;AACnCC,QAAAA,YAAY,GAAG,IAAf,CADmC,CAEnC;AACH;;AACD,YAAMZ,GAAG,GAAGkD,MAAM,CAACc,MAAP,CAAcb,OAAd,EAAuBa,MAAvB,CAA8BR,aAA9B,CAAZ;AACA1D,MAAAA,KAAK,CAACyE,gCAAN,GAvDA,CAwDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,YAAMC,aAAa,GAAG1E,KAAK,CAAC2E,iBAAN,EAAtB;AACA,YAAMxE,SAAS,GAAGH,KAAK,CAAC4E,sBAAN,EAAlB;AACA,UAAIC,WAAJ;AACA,UAAInE,eAAJ;;AACA,UAAII,YAAJ,EAAkB;AACdd,QAAAA,KAAK,CAAC8E,gBAAN;AACAD,QAAAA,WAAW,GAAG7E,KAAK,CAAC+E,YAApB;AACArE,QAAAA,eAAe,GACXP,SAAS,CAAC6E,KAAV,GAAkBd,MAAlB,CAAyB/D,SAAS,CAACjB,GAAV,CAAc+F,CAAC,IAAI,SAASA,CAA5B,CAAzB,CADJ;AAEH,OALD,MAMK;AACDJ,QAAAA,WAAW,GAAG,IAAd;AACArE,QAAAA,MAAM,GAAG,EAAT;AACAE,QAAAA,eAAe,GAAGP,SAAS,CAAC6E,KAAV,EAAlB;AACH;;AACD,YAAM1E,SAAS,GAAGpC,oBAAoB,CAAC+E,IAAI,CAAC3C,SAAN,EAAiB2C,IAAI,CAACiC,UAAtB,CAAtC;AACA,YAAM7C,GAAG,SAAStC,OAAO,CAACC,KAAD,EAAQ0E,aAAR,EAAuBxE,GAAvB,EAA4BC,SAA5B,EAAuC3B,SAAvC,EAAkDyE,IAAI,CAAC7C,MAAvD,EAA+D6C,IAAI,CAAC5C,OAApE,EAA6EC,SAA7E,EAAwFuE,WAAxF,EAAqGrE,MAArG,EAA6GyC,IAAI,CAACxC,OAAlH,EAA2HC,eAA3H,EAA4IuC,IAAI,CAACtC,YAAjJ,EAA+J,IAA/J,EAAqK,IAArK,CAAzB;AACA,aAAO0B,GAAP;AACH,KArFD,SAsFQ;AACJrC,MAAAA,KAAK,CAACkD,UAAN,GAAmB,KAAnB,CADI,CAEJ;;AACAiC,MAAAA,iBAAiB,CAAC/B,MAAD,EAASL,CAAT,CAAjB;AACAoC,MAAAA,iBAAiB,CAAC9B,OAAD,EAAUL,CAAV,CAAjB;AACAmC,MAAAA,iBAAiB,CAAC3B,IAAD,EAAOF,SAAP,CAAjB;AACA6B,MAAAA,iBAAiB,CAAC1B,IAAD,EAAOF,SAAP,CAAjB;;AACA,UAAIG,aAAa,IAAI,IAArB,EAA2B;AACvBhG,QAAAA,GAAG,CAACgF,OAAJ,CAAYgB,aAAZ;AACH;AACJ,KA5GmB,CA6GpB;;AACH,G;;;;AAOD,OAAO,SAAS0B,0BAAT,CAAoCC,OAApC,EAA6C;AAChD,QAAMnD,IAAI,GAAG,EAAb;;AACA,MAAImD,OAAO,YAAY1H,MAAvB,EAA+B;AAC3B0H,IAAAA,OAAO,GAAG,CAACA,OAAD,CAAV;AACH,GAJ+C,CAKhD;;;AACA,OAAK,IAAIlD,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGkD,OAAO,CAACxD,MAA5B,EAAoC,EAAEM,CAAtC,EAAyC;AACrC,UAAMmD,MAAM,GAAGD,OAAO,CAAClD,CAAD,CAAtB;;AACA,QAAImD,MAAM,CAACC,IAAP,KAAgB,CAApB,EAAuB;AACnBrD,MAAAA,IAAI,CAACpC,IAAL,CAAUhC,UAAU,CAACwH,MAAD,EAAS,CAAT,CAApB;AACH,KAFD,MAGK,IAAIA,MAAM,CAACC,IAAP,KAAgB,CAApB,EAAuB;AACxB,YAAM,IAAIpC,KAAJ,CAAU,iEACZ,WADE,CAAN;AAEH,KAHI,MAIA;AACDjB,MAAAA,IAAI,CAACpC,IAAL,CAAUwF,MAAV;AACH;AACJ;;AACD,SAAOpD,IAAP;AACH;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASiD,iBAAT,CAA2BE,OAA3B,EAAoCG,UAApC,EAAgD;AACnD,MAAIH,OAAO,IAAI,IAAf,EAAqB;AACjB;AACH;;AACD,QAAMI,YAAY,GAAG,EAArB;;AACA,MAAID,UAAU,YAAY7H,MAA1B,EAAkC;AAC9B8H,IAAAA,YAAY,CAAC3F,IAAb,CAAkB0F,UAAU,CAACE,EAA7B;AACH,GAFD,MAGK,IAAI1G,KAAK,CAACC,OAAN,CAAcuG,UAAd,CAAJ,EAA+B;AAChCA,IAAAA,UAAU,CAACG,OAAX,CAAmBC,CAAC,IAAIH,YAAY,CAAC3F,IAAb,CAAkB8F,CAAC,CAACF,EAApB,CAAxB;AACH,GAFI,MAGA,IAAIF,UAAU,IAAI,IAAlB,EAAwB;AACzB;AACA,SAAK,MAAMK,IAAX,IAAmBL,UAAnB,EAA+B;AAC3B,YAAMM,SAAS,GAAGN,UAAU,CAACK,IAAD,CAA5B;AACAJ,MAAAA,YAAY,CAAC3F,IAAb,CAAkBgG,SAAS,CAACJ,EAA5B;AACH;AACJ;;AACD,QAAMK,gBAAgB,GAAG,EAAzB;;AACA,MAAIV,OAAO,YAAY1H,MAAvB,EAA+B;AAC3B,QAAI8H,YAAY,CAACO,OAAb,CAAqBX,OAAO,CAACK,EAA7B,MAAqC,CAAC,CAA1C,EAA6C;AACzCK,MAAAA,gBAAgB,CAACjG,IAAjB,CAAsBuF,OAAtB;AACH;AACJ,GAJD,MAKK,IAAIrG,KAAK,CAACC,OAAN,CAAcoG,OAAd,CAAJ,EAA4B;AAC7BA,IAAAA,OAAO,CAACM,OAAR,CAAgBC,CAAC,IAAI;AACjB,UAAIH,YAAY,CAACO,OAAb,CAAqBJ,CAAC,CAACF,EAAvB,MAA+B,CAAC,CAApC,EAAuC;AACnCK,QAAAA,gBAAgB,CAACjG,IAAjB,CAAsB8F,CAAtB;AACH;AACJ,KAJD;AAKH,GANI,MAOA,IAAIP,OAAO,IAAI,IAAf,EAAqB;AACtB;AACA,SAAK,MAAMQ,IAAX,IAAmBR,OAAnB,EAA4B;AACxB,YAAMC,MAAM,GAAGD,OAAO,CAACQ,IAAD,CAAtB;;AACA,UAAIJ,YAAY,CAACO,OAAb,CAAqBV,MAAM,CAACI,EAA5B,MAAoC,CAAC,CAAzC,EAA4C;AACxCK,QAAAA,gBAAgB,CAACjG,IAAjB,CAAsBwF,MAAtB;AACH;AACJ;AACJ;;AACDS,EAAAA,gBAAgB,CAACJ,OAAjB,CAAyBC,CAAC,IAAI;AAC1B,QAAI,CAACA,CAAC,CAACK,UAAP,EAAmB;AACfL,MAAAA,CAAC,CAAClD,OAAF;AACH;AACJ,GAJD;AAKH","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/**\n * Interfaces and methods for training models using tf.Tensor objects.\n */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { Tensor, tensor1d, util } from '@tensorflow/tfjs-core';\nimport { expandDims, gather, sliceAlongFirstAxis } from '../backend/tfjs_backend';\nimport { configureCallbacks, standardizeCallbacks } from '../base_callbacks';\nimport { NotImplementedError, ValueError } from '../errors';\nimport { disposeTensorsInLogs } from '../logs';\nimport { range } from '../utils/math_utils';\nexport function checkBatchSize(batchSize) {\n    tfc.util.assert(batchSize > 0 && Number.isInteger(batchSize), () => `batchSize is required to be a positive integer, but got ${batchSize}`);\n}\n/**\n * Slice a Tensor or an Array of Tensors, by start and stop indices.\n *\n * Porting Note: The `_slice_arrays` function in PyKeras is covered by this\n *   function and `sliceArraysByIndices()` together.\n *\n * @param arrays: the input.\n * @param start: the starting index (inclusive).\n * @param stop: the stopping index (exclusive).\n * @returns The result of the slicing. If `arrays` is an `Array` of\n *   `tf.Tensor`s, the slicing will be applied to all elements of the `Array`\n *   in the same way.\n */\nexport function sliceArrays(arrays, start, stop) {\n    if (arrays == null) {\n        return [null];\n    }\n    else if (Array.isArray(arrays)) {\n        return arrays.map(array => sliceAlongFirstAxis(array, start, stop - start));\n    }\n    else { // Tensor.\n        return sliceAlongFirstAxis(arrays, start, stop - start);\n    }\n}\n/**\n * Slice a Tensor or an Array of Tensors, by random-order indices.\n *\n * Porting Note: The `_slice_arrays` function in PyKeras is covered by this\n *   function and `sliceArrays()` together.\n *\n * @param arrays The input `tf.Tensor` or `Array` of `tf.Tensor`s to slice.\n *   If an `Array` of `tf.Tensor`s, all `tf.Tensor`s will be sliced in the\n *   same fashion.\n * @param indices The indices to use for slicing along the first (batch)\n *   dimension.\n * @returns Result(s) of the slicing.\n */\nexport function sliceArraysByIndices(arrays, indices) {\n    return tfc.tidy(() => {\n        if (arrays == null) {\n            return null;\n        }\n        else if (Array.isArray(arrays)) {\n            return arrays.map(array => sliceArraysByIndices(array, indices));\n        }\n        else {\n            // TODO(cais): indices should be a pre-constructed Tensor1D to avoid\n            //   tensor1d() calls.\n            return gather(arrays, indices.dtype === 'int32' ? indices : indices.toInt());\n        }\n    });\n}\n/**\n * Returns a list of batch indices (tuples of indices).\n * @param size: Integer, total size of the data to slice into batches.\n * @param batchSize: Integer, batch size.\n * @returns An Array of [batchStart, batchEnd] tuples. batchStart is\n *   inclusive; batchEnd is exclusive. I.e., each batch consists of indices x\n *   that satisfy batchStart <= x < batchEnd.\n */\nexport function makeBatches(size, batchSize) {\n    const output = [];\n    let batchStart = 0;\n    let batchEnd = null;\n    while (batchStart < size) {\n        batchEnd = batchStart + batchSize;\n        if (batchEnd >= size) {\n            batchEnd = size;\n        }\n        output.push([batchStart, batchEnd]);\n        batchStart = batchEnd;\n    }\n    return output;\n}\n/**\n * Abstract fit function for `f(ins)`.\n * @param f A Function returning a list of tensors. For training, this\n *   function is expected to perform the updates to the variables.\n * @param ins List of tensors to be fed to `f`.\n * @param outLabels List of strings, display names of the outputs of `f`.\n * @param batchSize Integer batch size or `== null` if unknown. Default : 32.\n * @param epochs Number of times to iterate over the data. Default : 1.\n * @param verbose Verbosity mode: 0, 1, or 2. Default: 1.\n * @param callbacks List of callbacks to be called during training.\n * @param valF Function to call for validation.\n * @param valIns List of tensors to be fed to `valF`.\n * @param shuffle Whether to shuffle the data at the beginning of every\n * epoch. Default : true.\n * @param callbackMetrics List of strings, the display names of the metrics\n *   passed to the callbacks. They should be the concatenation of the\n *   display names of the outputs of `f` and the list of display names\n *   of the outputs of `valF`.\n * @param initialEpoch Epoch at which to start training (useful for\n *   resuming a previous training run). Default : 0.\n * @param stepsPerEpoch Total number of steps (batches on samples) before\n *   declaring one epoch finished and starting the next epoch. Ignored with\n *   the default value of `undefined` or `null`.\n * @param validationSteps Number of steps to run validation for (only if\n *   doing validation from data tensors). Not applicable for tfjs-layers.\n * @returns A `History` object.\n */\nasync function fitLoop(\n// Type `model` as `any` here to avoid circular dependency w/ training.ts.\n// tslint:disable-next-line:no-any\nmodel, f, ins, outLabels, batchSize, epochs, verbose, callbacks, valF, valIns, shuffle, callbackMetrics, initialEpoch, stepsPerEpoch, validationSteps) {\n    if (batchSize == null) {\n        batchSize = 32;\n    }\n    if (epochs == null) {\n        epochs = 1;\n    }\n    if (shuffle == null) {\n        shuffle = true;\n    }\n    if (initialEpoch == null) {\n        initialEpoch = 0;\n    }\n    // TODO(cais): Change const to let below when implementing validation.\n    let doValidation = false;\n    if (valF != null && valIns != null) {\n        doValidation = true;\n        // TODO(cais): verbose message.\n    }\n    if (validationSteps != null) {\n        doValidation = true;\n        if (stepsPerEpoch == null) {\n            throw new ValueError('Can only use `validationSteps` when doing step-wise training, ' +\n                'i.e., `stepsPerEpoch` must be set.');\n        }\n    }\n    const numTrainSamples = model.checkNumSamples(ins, batchSize, stepsPerEpoch, 'steps_per_epoch');\n    let indexArray;\n    if (numTrainSamples != null) {\n        indexArray = range(0, numTrainSamples);\n    }\n    if (verbose == null) {\n        verbose = 1;\n    }\n    const { callbackList, history } = configureCallbacks(callbacks, verbose, epochs, initialEpoch, numTrainSamples, stepsPerEpoch, batchSize, doValidation, callbackMetrics);\n    callbackList.setModel(model);\n    model.history = history;\n    await callbackList.onTrainBegin();\n    model.stopTraining_ = false;\n    // TODO(cais): Take care of callbacks.validation_data as in PyKeras.\n    // TODO(cais): Pre-convert feeds for performance as in PyKeras.\n    for (let epoch = initialEpoch; epoch < epochs; ++epoch) {\n        await callbackList.onEpochBegin(epoch);\n        const epochLogs = {};\n        if (stepsPerEpoch != null) {\n            throw new NotImplementedError('stepsPerEpoch mode is not implemented yet.');\n        }\n        else {\n            if (shuffle === 'batch') {\n                throw new NotImplementedError('batch shuffling is not implemneted yet');\n            }\n            else if (shuffle) {\n                util.shuffle(indexArray);\n            }\n            // Convert the potentially shuffled indices to Tensor1D, to avoid the\n            // cost of repeated creation of Array1Ds later on.\n            const epochIndexArray1D = tensor1d(indexArray);\n            const batches = makeBatches(numTrainSamples, batchSize);\n            for (let batchIndex = 0; batchIndex < batches.length; ++batchIndex) {\n                const batchLogs = {};\n                await callbackList.onBatchBegin(batchIndex, batchLogs);\n                tfc.tidy(() => {\n                    const batchStart = batches[batchIndex][0];\n                    const batchEnd = batches[batchIndex][1];\n                    const batchIds = sliceAlongFirstAxis(epochIndexArray1D, batchStart, batchEnd - batchStart);\n                    batchLogs['batch'] = batchIndex;\n                    batchLogs['size'] = batchEnd - batchStart;\n                    // TODO(cais): In ins, train flag can be a number, instead of an\n                    //   Tensor? Do we need to handle this in tfjs-layers?\n                    const insBatch = sliceArraysByIndices(ins, batchIds);\n                    const outs = f(insBatch);\n                    for (let i = 0; i < outLabels.length; ++i) {\n                        const label = outLabels[i];\n                        const out = outs[i];\n                        batchLogs[label] = out;\n                        tfc.keep(out);\n                        // TODO(cais): Use scope() to avoid ownership.\n                    }\n                    if (batchIndex === batches.length - 1) { // Last batch.\n                        if (doValidation) {\n                            const valOuts = model.testLoop(valF, valIns, batchSize);\n                            // Porting Notes: In tfjs-layers, valOuts is always an Array.\n                            for (let i = 0; i < outLabels.length; ++i) {\n                                const label = outLabels[i];\n                                const out = valOuts[i];\n                                tfc.keep(out);\n                                // TODO(cais): Use scope() to avoid ownership.\n                                epochLogs['val_' + label] = out;\n                            }\n                        }\n                    }\n                });\n                await callbackList.onBatchEnd(batchIndex, batchLogs);\n                disposeTensorsInLogs(batchLogs);\n                if (model.stopTraining_) {\n                    break;\n                }\n                // TODO(cais): return outs as list of Tensor.\n            }\n            epochIndexArray1D.dispose();\n        }\n        // TODO(cais): Run validation at the end of the epoch.\n        await callbackList.onEpochEnd(epoch, epochLogs);\n        if (model.stopTraining_) {\n            break;\n        }\n    }\n    await callbackList.onTrainEnd();\n    await model.history.syncData();\n    return model.history;\n}\nexport async function fitTensors(\n// Type `model` as `any` here to avoid circular dependency w/ training.ts.\n// tslint:disable-next-line:no-any\nmodel, x, y, args = {}) {\n    if (model.isTraining) {\n        throw new Error('Cannot start training because another fit() call is ongoing.');\n    }\n    model.isTraining = true;\n    let inputs;\n    let targets;\n    let inputValX;\n    let inputValY;\n    let valX;\n    let valY;\n    let sampleWeights;\n    try {\n        const batchSize = args.batchSize == null ? 32 : args.batchSize;\n        checkBatchSize(batchSize);\n        // Validate user data.\n        // TODO(cais): Support sampleWeight.\n        const checkBatchAxis = false;\n        const standardizedOuts = await model.standardizeUserData(x, y, args.sampleWeight, args.classWeight, checkBatchAxis, batchSize);\n        inputs = standardizedOuts[0];\n        targets = standardizedOuts[1];\n        sampleWeights = standardizedOuts[2];\n        // Prepare validation data.\n        let doValidation = false;\n        let valIns;\n        if (args.validationData != null && args.validationData.length > 0) {\n            doValidation = true;\n            if (args.validationData.length === 2) {\n                // config.validationData consists of valX and valY.\n                inputValX = args.validationData[0];\n                inputValY = args.validationData[1];\n            }\n            else if (args.validationData.length === 3) {\n                throw new NotImplementedError('validationData including sample weights is not supported yet.');\n            }\n            else {\n                throw new ValueError(`When passing validation data, it must contain 2 (valX, valY) ` +\n                    `or 3 (valX, valY, valSampleWeight) items; ` +\n                    `${args.validationData} is invalid.`);\n            }\n            const checkBatchAxis = true;\n            const valStandardized = await model.standardizeUserData(inputValX, inputValY, null, /** Unused sample weights. */ null, /** Unused class weights. */ checkBatchAxis, batchSize);\n            valX = valStandardized[0];\n            valY = valStandardized[1];\n            valIns = valX.concat(valY);\n            // TODO(cais): Add useLearningPhase data properly.\n        }\n        else if (args.validationSplit != null && args.validationSplit > 0 &&\n            args.validationSplit < 1) {\n            doValidation = true;\n            // Porting Note: In tfjs-layers, inputs[0] is always a Tensor.\n            const splitAt = Math.floor(inputs[0].shape[0] * (1 - args.validationSplit));\n            const originalBatchSize = inputs[0].shape[0];\n            valX = sliceArrays(inputs, splitAt, originalBatchSize);\n            inputs = sliceArrays(inputs, 0, splitAt);\n            valY = sliceArrays(targets, splitAt, originalBatchSize);\n            targets = sliceArrays(targets, 0, splitAt);\n            // TODO(cais): Once sampleWeights becomes available, slice it to get\n            //   valSampleWeights.\n            valIns = valX.concat(valY);\n            // TODO(cais): Add useLearningPhase data properly.\n        }\n        else if (args.validationSteps != null) {\n            doValidation = true;\n            // TODO(cais): Add useLearningPhase.\n        }\n        const ins = inputs.concat(targets).concat(sampleWeights);\n        model.checkTrainableWeightsConsistency();\n        // TODO(cais): Handle use_learning_phase and learning_phase?\n        // Porting Note: Here we see a key deviation of tfjs-layers from\n        // Keras.\n        //  Due to the imperative nature of tfjs-layers' backend (tfjs-core),\n        //  we do not construct symbolic computation graphs to embody the\n        //  training process. Instead, we define a function that performs the\n        //  training action. In PyKeras, the data (inputs and targets) are fed\n        //  through graph placeholders. In tfjs-layers, the data are fed as\n        //  function arguments. Since the function are defined below in the\n        //  scope, we don't have equivalents of PyKeras's\n        //  `_make_train_funciton`.\n        const trainFunction = model.makeTrainFunction();\n        const outLabels = model.getDedupedMetricsNames();\n        let valFunction;\n        let callbackMetrics;\n        if (doValidation) {\n            model.makeTestFunction();\n            valFunction = model.testFunction;\n            callbackMetrics =\n                outLabels.slice().concat(outLabels.map(n => 'val_' + n));\n        }\n        else {\n            valFunction = null;\n            valIns = [];\n            callbackMetrics = outLabels.slice();\n        }\n        const callbacks = standardizeCallbacks(args.callbacks, args.yieldEvery);\n        const out = await fitLoop(model, trainFunction, ins, outLabels, batchSize, args.epochs, args.verbose, callbacks, valFunction, valIns, args.shuffle, callbackMetrics, args.initialEpoch, null, null);\n        return out;\n    }\n    finally {\n        model.isTraining = false;\n        // Memory clean up.\n        disposeNewTensors(inputs, x);\n        disposeNewTensors(targets, y);\n        disposeNewTensors(valX, inputValX);\n        disposeNewTensors(valY, inputValY);\n        if (sampleWeights != null) {\n            tfc.dispose(sampleWeights);\n        }\n    }\n    // TODO(cais): Add value to outLabels.\n}\n/**\n * Ensure tensors all have a rank of at least 2.\n *\n * If a tensor has a rank of 1, it is dimension-expanded to rank 2.\n * If any tensor has a rank of 0 (i.e., is a scalar), an error will be thrown.\n */\nexport function ensureTensorsRank2OrHigher(tensors) {\n    const outs = [];\n    if (tensors instanceof Tensor) {\n        tensors = [tensors];\n    }\n    // Make Tensors at least 2D.\n    for (let i = 0; i < tensors.length; ++i) {\n        const tensor = tensors[i];\n        if (tensor.rank === 1) {\n            outs.push(expandDims(tensor, 1));\n        }\n        else if (tensor.rank === 0) {\n            throw new Error('Expected tensor to be at least 1D, but received a 0D tensor ' +\n                '(scalar).');\n        }\n        else {\n            outs.push(tensor);\n        }\n    }\n    return outs;\n}\n/**\n * Compare a set of tensors with a reference (old) set, discard the ones\n * in the new set that are not present in the reference set.\n *\n * This method is used for memory clenaup during calls such as\n * LayersModel.fit().\n *\n * @param tensors New set which may contain Tensors not present in\n *   `refTensors`.\n * @param refTensors Reference Tensor set.\n */\n// TODO(cais, kangyizhang): Deduplicate with tfjs-data.\nexport function disposeNewTensors(tensors, refTensors) {\n    if (tensors == null) {\n        return;\n    }\n    const oldTensorIds = [];\n    if (refTensors instanceof Tensor) {\n        oldTensorIds.push(refTensors.id);\n    }\n    else if (Array.isArray(refTensors)) {\n        refTensors.forEach(t => oldTensorIds.push(t.id));\n    }\n    else if (refTensors != null) {\n        // `oldTensors` is a map from string name to Tensor.\n        for (const name in refTensors) {\n            const oldTensor = refTensors[name];\n            oldTensorIds.push(oldTensor.id);\n        }\n    }\n    const tensorsToDispose = [];\n    if (tensors instanceof Tensor) {\n        if (oldTensorIds.indexOf(tensors.id) === -1) {\n            tensorsToDispose.push(tensors);\n        }\n    }\n    else if (Array.isArray(tensors)) {\n        tensors.forEach(t => {\n            if (oldTensorIds.indexOf(t.id) === -1) {\n                tensorsToDispose.push(t);\n            }\n        });\n    }\n    else if (tensors != null) {\n        // `oldTensors` is a map from string name to Tensor.\n        for (const name in tensors) {\n            const tensor = tensors[name];\n            if (oldTensorIds.indexOf(tensor.id) === -1) {\n                tensorsToDispose.push(tensor);\n            }\n        }\n    }\n    tensorsToDispose.forEach(t => {\n        if (!t.isDisposed) {\n            t.dispose();\n        }\n    });\n}\n"]},"metadata":{},"sourceType":"module"}