{"ast":null,"code":"import _asyncToGenerator from \"/Users/ryanliang/Downloads/main_movir_picker/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { dispose, tidy } from '../globals';\nimport { add } from '../ops/add';\nimport { div } from '../ops/div';\nimport { mul } from '../ops/mul';\nimport { pow } from '../ops/pow';\nimport { scalar } from '../ops/scalar';\nimport { sqrt } from '../ops/sqrt';\nimport { square } from '../ops/square';\nimport { sub } from '../ops/sub';\nimport { zerosLike } from '../ops/zeros_like';\nimport { registerClass } from '../serialization';\nimport { Optimizer } from './optimizer';\nexport class AdamOptimizer extends Optimizer {\n  constructor(learningRate, beta1, beta2, epsilon = null) {\n    super();\n    this.learningRate = learningRate;\n    this.beta1 = beta1;\n    this.beta2 = beta2;\n    this.epsilon = epsilon;\n    this.accumulatedFirstMoment = [];\n    this.accumulatedSecondMoment = [];\n    tidy(() => {\n      // accB* will be updated by batch.\n      this.accBeta1 = scalar(beta1).variable();\n      this.accBeta2 = scalar(beta2).variable();\n    });\n\n    if (epsilon == null) {\n      this.epsilon = ENGINE.backend.epsilon();\n    }\n  }\n\n  applyGradients(variableGradients) {\n    const varNames = Array.isArray(variableGradients) ? variableGradients.map(v => v.name) : Object.keys(variableGradients);\n    tidy(() => {\n      const oneMinusAccBeta1 = sub(1, this.accBeta1);\n      const oneMinusAccBeta2 = sub(1, this.accBeta2);\n      varNames.forEach((name, i) => {\n        const value = ENGINE.registeredVariables[name];\n        const trainable = false;\n\n        if (this.accumulatedFirstMoment[i] == null) {\n          this.accumulatedFirstMoment[i] = {\n            originalName: `${name}/m`,\n            variable: tidy(() => zerosLike(value).variable(trainable))\n          };\n        }\n\n        if (this.accumulatedSecondMoment[i] == null) {\n          this.accumulatedSecondMoment[i] = {\n            originalName: `${name}/v`,\n            variable: tidy(() => zerosLike(value).variable(trainable))\n          };\n        }\n\n        const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];\n\n        if (gradient == null) {\n          return;\n        }\n\n        const firstMoment = this.accumulatedFirstMoment[i].variable;\n        const secondMoment = this.accumulatedSecondMoment[i].variable;\n        const newFirstMoment = add(mul(firstMoment, this.beta1), mul(gradient, 1 - this.beta1));\n        const newSecondMoment = add(mul(secondMoment, this.beta2), mul(square(gradient), 1 - this.beta2));\n        const biasCorrectedFirstMoment = div(newFirstMoment, oneMinusAccBeta1);\n        const biasCorrectedSecondMoment = div(newSecondMoment, oneMinusAccBeta2);\n        firstMoment.assign(newFirstMoment);\n        secondMoment.assign(newSecondMoment);\n        const newValue = add(mul(div(biasCorrectedFirstMoment, add(sqrt(biasCorrectedSecondMoment), this.epsilon)), -this.learningRate), value);\n        value.assign(newValue);\n      });\n      this.accBeta1.assign(mul(this.accBeta1, this.beta1));\n      this.accBeta2.assign(mul(this.accBeta2, this.beta2));\n    });\n    this.incrementIterations();\n  }\n\n  dispose() {\n    this.accBeta1.dispose();\n    this.accBeta2.dispose();\n\n    if (this.accumulatedFirstMoment != null) {\n      dispose(this.accumulatedFirstMoment.map(v => v.variable));\n    }\n\n    if (this.accumulatedSecondMoment != null) {\n      dispose(this.accumulatedSecondMoment.map(v => v.variable));\n    }\n  }\n\n  getWeights() {\n    var _this = this;\n\n    return _asyncToGenerator(function* () {\n      // Order matters for Python compatibility.\n      const variables = [..._this.accumulatedFirstMoment, ..._this.accumulatedSecondMoment];\n      return [yield _this.saveIterations()].concat(variables.map(v => ({\n        name: v.originalName,\n        tensor: v.variable\n      })));\n    })();\n  }\n\n  setWeights(weightValues) {\n    var _this2 = this;\n\n    return _asyncToGenerator(function* () {\n      weightValues = yield _this2.extractIterations(weightValues);\n      tidy(() => {\n        _this2.accBeta1.assign(pow(_this2.beta1, _this2.iterations_ + 1));\n\n        _this2.accBeta2.assign(pow(_this2.beta2, _this2.iterations_ + 1));\n      });\n      const variableCount = weightValues.length / 2;\n      const trainable = false;\n      _this2.accumulatedFirstMoment = weightValues.slice(0, variableCount).map(v => ({\n        originalName: v.name,\n        variable: v.tensor.variable(trainable)\n      }));\n      _this2.accumulatedSecondMoment = weightValues.slice(variableCount, variableCount * 2).map(v => ({\n        originalName: v.name,\n        variable: v.tensor.variable(trainable)\n      }));\n    })();\n  }\n\n  getConfig() {\n    return {\n      'learningRate': this.learningRate,\n      'beta1': this.beta1,\n      'beta2': this.beta2,\n      'epsilon': this.epsilon\n    };\n  }\n  /** @nocollapse */\n\n\n  static fromConfig(cls, config) {\n    return new cls(config['learningRate'], config['beta1'], config['beta2'], config['epsilon']);\n  }\n\n}\n/** @nocollapse */\n\nAdamOptimizer.className = 'Adam'; // Note: Name matters for Python compatibility.\n\nregisterClass(AdamOptimizer);","map":{"version":3,"sources":["/Users/ryanliang/Downloads/main_movir_picker/node_modules/@tensorflow/tfjs-core/dist/optimizers/adam_optimizer.js"],"names":["ENGINE","dispose","tidy","add","div","mul","pow","scalar","sqrt","square","sub","zerosLike","registerClass","Optimizer","AdamOptimizer","constructor","learningRate","beta1","beta2","epsilon","accumulatedFirstMoment","accumulatedSecondMoment","accBeta1","variable","accBeta2","backend","applyGradients","variableGradients","varNames","Array","isArray","map","v","name","Object","keys","oneMinusAccBeta1","oneMinusAccBeta2","forEach","i","value","registeredVariables","trainable","originalName","gradient","tensor","firstMoment","secondMoment","newFirstMoment","newSecondMoment","biasCorrectedFirstMoment","biasCorrectedSecondMoment","assign","newValue","incrementIterations","getWeights","variables","saveIterations","concat","setWeights","weightValues","extractIterations","iterations_","variableCount","length","slice","getConfig","fromConfig","cls","config","className"],"mappings":";;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASA,MAAT,QAAuB,WAAvB;AACA,SAASC,OAAT,EAAkBC,IAAlB,QAA8B,YAA9B;AACA,SAASC,GAAT,QAAoB,YAApB;AACA,SAASC,GAAT,QAAoB,YAApB;AACA,SAASC,GAAT,QAAoB,YAApB;AACA,SAASC,GAAT,QAAoB,YAApB;AACA,SAASC,MAAT,QAAuB,eAAvB;AACA,SAASC,IAAT,QAAqB,aAArB;AACA,SAASC,MAAT,QAAuB,eAAvB;AACA,SAASC,GAAT,QAAoB,YAApB;AACA,SAASC,SAAT,QAA0B,mBAA1B;AACA,SAASC,aAAT,QAA8B,kBAA9B;AACA,SAASC,SAAT,QAA0B,aAA1B;AACA,OAAO,MAAMC,aAAN,SAA4BD,SAA5B,CAAsC;AACzCE,EAAAA,WAAW,CAACC,YAAD,EAAeC,KAAf,EAAsBC,KAAtB,EAA6BC,OAAO,GAAG,IAAvC,EAA6C;AACpD;AACA,SAAKH,YAAL,GAAoBA,YAApB;AACA,SAAKC,KAAL,GAAaA,KAAb;AACA,SAAKC,KAAL,GAAaA,KAAb;AACA,SAAKC,OAAL,GAAeA,OAAf;AACA,SAAKC,sBAAL,GAA8B,EAA9B;AACA,SAAKC,uBAAL,GAA+B,EAA/B;AACAnB,IAAAA,IAAI,CAAC,MAAM;AACP;AACA,WAAKoB,QAAL,GAAgBf,MAAM,CAACU,KAAD,CAAN,CAAcM,QAAd,EAAhB;AACA,WAAKC,QAAL,GAAgBjB,MAAM,CAACW,KAAD,CAAN,CAAcK,QAAd,EAAhB;AACH,KAJG,CAAJ;;AAKA,QAAIJ,OAAO,IAAI,IAAf,EAAqB;AACjB,WAAKA,OAAL,GAAenB,MAAM,CAACyB,OAAP,CAAeN,OAAf,EAAf;AACH;AACJ;;AACDO,EAAAA,cAAc,CAACC,iBAAD,EAAoB;AAC9B,UAAMC,QAAQ,GAAGC,KAAK,CAACC,OAAN,CAAcH,iBAAd,IACbA,iBAAiB,CAACI,GAAlB,CAAsBC,CAAC,IAAIA,CAAC,CAACC,IAA7B,CADa,GAEbC,MAAM,CAACC,IAAP,CAAYR,iBAAZ,CAFJ;AAGAzB,IAAAA,IAAI,CAAC,MAAM;AACP,YAAMkC,gBAAgB,GAAG1B,GAAG,CAAC,CAAD,EAAI,KAAKY,QAAT,CAA5B;AACA,YAAMe,gBAAgB,GAAG3B,GAAG,CAAC,CAAD,EAAI,KAAKc,QAAT,CAA5B;AACAI,MAAAA,QAAQ,CAACU,OAAT,CAAiB,CAACL,IAAD,EAAOM,CAAP,KAAa;AAC1B,cAAMC,KAAK,GAAGxC,MAAM,CAACyC,mBAAP,CAA2BR,IAA3B,CAAd;AACA,cAAMS,SAAS,GAAG,KAAlB;;AACA,YAAI,KAAKtB,sBAAL,CAA4BmB,CAA5B,KAAkC,IAAtC,EAA4C;AACxC,eAAKnB,sBAAL,CAA4BmB,CAA5B,IAAiC;AAC7BI,YAAAA,YAAY,EAAG,GAAEV,IAAK,IADO;AAE7BV,YAAAA,QAAQ,EAAErB,IAAI,CAAC,MAAMS,SAAS,CAAC6B,KAAD,CAAT,CAAiBjB,QAAjB,CAA0BmB,SAA1B,CAAP;AAFe,WAAjC;AAIH;;AACD,YAAI,KAAKrB,uBAAL,CAA6BkB,CAA7B,KAAmC,IAAvC,EAA6C;AACzC,eAAKlB,uBAAL,CAA6BkB,CAA7B,IAAkC;AAC9BI,YAAAA,YAAY,EAAG,GAAEV,IAAK,IADQ;AAE9BV,YAAAA,QAAQ,EAAErB,IAAI,CAAC,MAAMS,SAAS,CAAC6B,KAAD,CAAT,CAAiBjB,QAAjB,CAA0BmB,SAA1B,CAAP;AAFgB,WAAlC;AAIH;;AACD,cAAME,QAAQ,GAAGf,KAAK,CAACC,OAAN,CAAcH,iBAAd,IACbA,iBAAiB,CAACY,CAAD,CAAjB,CAAqBM,MADR,GAEblB,iBAAiB,CAACM,IAAD,CAFrB;;AAGA,YAAIW,QAAQ,IAAI,IAAhB,EAAsB;AAClB;AACH;;AACD,cAAME,WAAW,GAAG,KAAK1B,sBAAL,CAA4BmB,CAA5B,EAA+BhB,QAAnD;AACA,cAAMwB,YAAY,GAAG,KAAK1B,uBAAL,CAA6BkB,CAA7B,EAAgChB,QAArD;AACA,cAAMyB,cAAc,GAAG7C,GAAG,CAACE,GAAG,CAACyC,WAAD,EAAc,KAAK7B,KAAnB,CAAJ,EAA+BZ,GAAG,CAACuC,QAAD,EAAW,IAAI,KAAK3B,KAApB,CAAlC,CAA1B;AACA,cAAMgC,eAAe,GAAG9C,GAAG,CAACE,GAAG,CAAC0C,YAAD,EAAe,KAAK7B,KAApB,CAAJ,EAAgCb,GAAG,CAACI,MAAM,CAACmC,QAAD,CAAP,EAAmB,IAAI,KAAK1B,KAA5B,CAAnC,CAA3B;AACA,cAAMgC,wBAAwB,GAAG9C,GAAG,CAAC4C,cAAD,EAAiBZ,gBAAjB,CAApC;AACA,cAAMe,yBAAyB,GAAG/C,GAAG,CAAC6C,eAAD,EAAkBZ,gBAAlB,CAArC;AACAS,QAAAA,WAAW,CAACM,MAAZ,CAAmBJ,cAAnB;AACAD,QAAAA,YAAY,CAACK,MAAb,CAAoBH,eAApB;AACA,cAAMI,QAAQ,GAAGlD,GAAG,CAACE,GAAG,CAACD,GAAG,CAAC8C,wBAAD,EAA2B/C,GAAG,CAACK,IAAI,CAAC2C,yBAAD,CAAL,EAAkC,KAAKhC,OAAvC,CAA9B,CAAJ,EAAoF,CAAC,KAAKH,YAA1F,CAAJ,EAA6GwB,KAA7G,CAApB;AACAA,QAAAA,KAAK,CAACY,MAAN,CAAaC,QAAb;AACH,OA/BD;AAgCA,WAAK/B,QAAL,CAAc8B,MAAd,CAAqB/C,GAAG,CAAC,KAAKiB,QAAN,EAAgB,KAAKL,KAArB,CAAxB;AACA,WAAKO,QAAL,CAAc4B,MAAd,CAAqB/C,GAAG,CAAC,KAAKmB,QAAN,EAAgB,KAAKN,KAArB,CAAxB;AACH,KArCG,CAAJ;AAsCA,SAAKoC,mBAAL;AACH;;AACDrD,EAAAA,OAAO,GAAG;AACN,SAAKqB,QAAL,CAAcrB,OAAd;AACA,SAAKuB,QAAL,CAAcvB,OAAd;;AACA,QAAI,KAAKmB,sBAAL,IAA+B,IAAnC,EAAyC;AACrCnB,MAAAA,OAAO,CAAC,KAAKmB,sBAAL,CAA4BW,GAA5B,CAAgCC,CAAC,IAAIA,CAAC,CAACT,QAAvC,CAAD,CAAP;AACH;;AACD,QAAI,KAAKF,uBAAL,IAAgC,IAApC,EAA0C;AACtCpB,MAAAA,OAAO,CAAC,KAAKoB,uBAAL,CAA6BU,GAA7B,CAAiCC,CAAC,IAAIA,CAAC,CAACT,QAAxC,CAAD,CAAP;AACH;AACJ;;AACKgC,EAAAA,UAAU,GAAG;AAAA;;AAAA;AACf;AACA,YAAMC,SAAS,GAAG,CAAC,GAAG,KAAI,CAACpC,sBAAT,EAAiC,GAAG,KAAI,CAACC,uBAAzC,CAAlB;AACA,aAAO,OAAO,KAAI,CAACoC,cAAL,EAAP,EAA8BC,MAA9B,CAAqCF,SAAS,CAACzB,GAAV,CAAcC,CAAC,KAAK;AAAEC,QAAAA,IAAI,EAAED,CAAC,CAACW,YAAV;AAAwBE,QAAAA,MAAM,EAAEb,CAAC,CAACT;AAAlC,OAAL,CAAf,CAArC,CAAP;AAHe;AAIlB;;AACKoC,EAAAA,UAAU,CAACC,YAAD,EAAe;AAAA;;AAAA;AAC3BA,MAAAA,YAAY,SAAS,MAAI,CAACC,iBAAL,CAAuBD,YAAvB,CAArB;AACA1D,MAAAA,IAAI,CAAC,MAAM;AACP,QAAA,MAAI,CAACoB,QAAL,CAAc8B,MAAd,CAAqB9C,GAAG,CAAC,MAAI,CAACW,KAAN,EAAa,MAAI,CAAC6C,WAAL,GAAmB,CAAhC,CAAxB;;AACA,QAAA,MAAI,CAACtC,QAAL,CAAc4B,MAAd,CAAqB9C,GAAG,CAAC,MAAI,CAACY,KAAN,EAAa,MAAI,CAAC4C,WAAL,GAAmB,CAAhC,CAAxB;AACH,OAHG,CAAJ;AAIA,YAAMC,aAAa,GAAGH,YAAY,CAACI,MAAb,GAAsB,CAA5C;AACA,YAAMtB,SAAS,GAAG,KAAlB;AACA,MAAA,MAAI,CAACtB,sBAAL,GACIwC,YAAY,CAACK,KAAb,CAAmB,CAAnB,EAAsBF,aAAtB,EAAqChC,GAArC,CAAyCC,CAAC,KAAK;AAC3CW,QAAAA,YAAY,EAAEX,CAAC,CAACC,IAD2B;AAE3CV,QAAAA,QAAQ,EAAES,CAAC,CAACa,MAAF,CAAStB,QAAT,CAAkBmB,SAAlB;AAFiC,OAAL,CAA1C,CADJ;AAKA,MAAA,MAAI,CAACrB,uBAAL,GACIuC,YAAY,CAACK,KAAb,CAAmBF,aAAnB,EAAkCA,aAAa,GAAG,CAAlD,EACKhC,GADL,CACSC,CAAC,KAAK;AACXW,QAAAA,YAAY,EAAEX,CAAC,CAACC,IADL;AAEXV,QAAAA,QAAQ,EAAES,CAAC,CAACa,MAAF,CAAStB,QAAT,CAAkBmB,SAAlB;AAFC,OAAL,CADV,CADJ;AAb2B;AAmB9B;;AACDwB,EAAAA,SAAS,GAAG;AACR,WAAO;AACH,sBAAgB,KAAKlD,YADlB;AAEH,eAAS,KAAKC,KAFX;AAGH,eAAS,KAAKC,KAHX;AAIH,iBAAW,KAAKC;AAJb,KAAP;AAMH;AACD;;;AACiB,SAAVgD,UAAU,CAACC,GAAD,EAAMC,MAAN,EAAc;AAC3B,WAAO,IAAID,GAAJ,CAAQC,MAAM,CAAC,cAAD,CAAd,EAAgCA,MAAM,CAAC,OAAD,CAAtC,EAAiDA,MAAM,CAAC,OAAD,CAAvD,EAAkEA,MAAM,CAAC,SAAD,CAAxE,CAAP;AACH;;AA5GwC;AA8G7C;;AACAvD,aAAa,CAACwD,SAAd,GAA0B,MAA1B,C,CAAkC;;AAClC1D,aAAa,CAACE,aAAD,CAAb","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { dispose, tidy } from '../globals';\nimport { add } from '../ops/add';\nimport { div } from '../ops/div';\nimport { mul } from '../ops/mul';\nimport { pow } from '../ops/pow';\nimport { scalar } from '../ops/scalar';\nimport { sqrt } from '../ops/sqrt';\nimport { square } from '../ops/square';\nimport { sub } from '../ops/sub';\nimport { zerosLike } from '../ops/zeros_like';\nimport { registerClass } from '../serialization';\nimport { Optimizer } from './optimizer';\nexport class AdamOptimizer extends Optimizer {\n    constructor(learningRate, beta1, beta2, epsilon = null) {\n        super();\n        this.learningRate = learningRate;\n        this.beta1 = beta1;\n        this.beta2 = beta2;\n        this.epsilon = epsilon;\n        this.accumulatedFirstMoment = [];\n        this.accumulatedSecondMoment = [];\n        tidy(() => {\n            // accB* will be updated by batch.\n            this.accBeta1 = scalar(beta1).variable();\n            this.accBeta2 = scalar(beta2).variable();\n        });\n        if (epsilon == null) {\n            this.epsilon = ENGINE.backend.epsilon();\n        }\n    }\n    applyGradients(variableGradients) {\n        const varNames = Array.isArray(variableGradients) ?\n            variableGradients.map(v => v.name) :\n            Object.keys(variableGradients);\n        tidy(() => {\n            const oneMinusAccBeta1 = sub(1, this.accBeta1);\n            const oneMinusAccBeta2 = sub(1, this.accBeta2);\n            varNames.forEach((name, i) => {\n                const value = ENGINE.registeredVariables[name];\n                const trainable = false;\n                if (this.accumulatedFirstMoment[i] == null) {\n                    this.accumulatedFirstMoment[i] = {\n                        originalName: `${name}/m`,\n                        variable: tidy(() => zerosLike(value).variable(trainable))\n                    };\n                }\n                if (this.accumulatedSecondMoment[i] == null) {\n                    this.accumulatedSecondMoment[i] = {\n                        originalName: `${name}/v`,\n                        variable: tidy(() => zerosLike(value).variable(trainable))\n                    };\n                }\n                const gradient = Array.isArray(variableGradients) ?\n                    variableGradients[i].tensor :\n                    variableGradients[name];\n                if (gradient == null) {\n                    return;\n                }\n                const firstMoment = this.accumulatedFirstMoment[i].variable;\n                const secondMoment = this.accumulatedSecondMoment[i].variable;\n                const newFirstMoment = add(mul(firstMoment, this.beta1), mul(gradient, 1 - this.beta1));\n                const newSecondMoment = add(mul(secondMoment, this.beta2), mul(square(gradient), 1 - this.beta2));\n                const biasCorrectedFirstMoment = div(newFirstMoment, oneMinusAccBeta1);\n                const biasCorrectedSecondMoment = div(newSecondMoment, oneMinusAccBeta2);\n                firstMoment.assign(newFirstMoment);\n                secondMoment.assign(newSecondMoment);\n                const newValue = add(mul(div(biasCorrectedFirstMoment, add(sqrt(biasCorrectedSecondMoment), this.epsilon)), -this.learningRate), value);\n                value.assign(newValue);\n            });\n            this.accBeta1.assign(mul(this.accBeta1, this.beta1));\n            this.accBeta2.assign(mul(this.accBeta2, this.beta2));\n        });\n        this.incrementIterations();\n    }\n    dispose() {\n        this.accBeta1.dispose();\n        this.accBeta2.dispose();\n        if (this.accumulatedFirstMoment != null) {\n            dispose(this.accumulatedFirstMoment.map(v => v.variable));\n        }\n        if (this.accumulatedSecondMoment != null) {\n            dispose(this.accumulatedSecondMoment.map(v => v.variable));\n        }\n    }\n    async getWeights() {\n        // Order matters for Python compatibility.\n        const variables = [...this.accumulatedFirstMoment, ...this.accumulatedSecondMoment];\n        return [await this.saveIterations()].concat(variables.map(v => ({ name: v.originalName, tensor: v.variable })));\n    }\n    async setWeights(weightValues) {\n        weightValues = await this.extractIterations(weightValues);\n        tidy(() => {\n            this.accBeta1.assign(pow(this.beta1, this.iterations_ + 1));\n            this.accBeta2.assign(pow(this.beta2, this.iterations_ + 1));\n        });\n        const variableCount = weightValues.length / 2;\n        const trainable = false;\n        this.accumulatedFirstMoment =\n            weightValues.slice(0, variableCount).map(v => ({\n                originalName: v.name,\n                variable: v.tensor.variable(trainable)\n            }));\n        this.accumulatedSecondMoment =\n            weightValues.slice(variableCount, variableCount * 2)\n                .map(v => ({\n                originalName: v.name,\n                variable: v.tensor.variable(trainable)\n            }));\n    }\n    getConfig() {\n        return {\n            'learningRate': this.learningRate,\n            'beta1': this.beta1,\n            'beta2': this.beta2,\n            'epsilon': this.epsilon,\n        };\n    }\n    /** @nocollapse */\n    static fromConfig(cls, config) {\n        return new cls(config['learningRate'], config['beta1'], config['beta2'], config['epsilon']);\n    }\n}\n/** @nocollapse */\nAdamOptimizer.className = 'Adam'; // Note: Name matters for Python compatibility.\nregisterClass(AdamOptimizer);\n"]},"metadata":{},"sourceType":"module"}