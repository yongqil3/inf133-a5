{"ast":null,"code":"import _asyncToGenerator from \"/Users/ryanliang/Downloads/main_movir_picker/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\n\n/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/* Original Source: engine/training.py */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { io, Optimizer, scalar, serialization, Tensor, tensor1d, util } from '@tensorflow/tfjs-core';\nimport * as K from '../backend/tfjs_backend';\nimport { nameScope } from '../common';\nimport { NotImplementedError, RuntimeError, ValueError } from '../errors';\nimport { deserialize } from '../layers/serialization';\nimport * as losses from '../losses';\nimport * as Metrics from '../metrics';\nimport * as optimizers from '../optimizers';\nimport { checkUserDefinedMetadata } from '../user_defined_metadata';\nimport { count, pyListRepeat, singletonOrArray, toCamelCase, toSnakeCase, unique } from '../utils/generic_utils';\nimport { printSummary } from '../utils/layer_utils';\nimport { range } from '../utils/math_utils';\nimport { convertPythonicToTs } from '../utils/serialization_utils';\nimport { version } from '../version';\nimport { Container } from './container';\nimport { execute, FeedDict } from './executor';\nimport { evaluateDataset, fitDataset } from './training_dataset';\nimport { checkBatchSize, disposeNewTensors, ensureTensorsRank2OrHigher, fitTensors, makeBatches, sliceArrays, sliceArraysByIndices } from './training_tensors';\nimport { computeWeightedLoss, standardizeClassWeights, standardizeWeights } from './training_utils';\n/**\n * Helper function for polymorphic input data: 1. singleton Tensor.\n */\n\nexport function isDataTensor(x) {\n  return x instanceof Tensor;\n}\n/**\n * Helper function for polymorphic input data: 2. Array of Tensor.\n */\n\nexport function isDataArray(x) {\n  return Array.isArray(x);\n}\n/**\n * Helper function for polymorphic input data: 3. \"dict\" of Tensor.\n */\n\nexport function isDataDict(x) {\n  return !isDataTensor(x) && !isDataArray(x);\n}\n/**\n * Normalizes inputs and targets provided by users.\n * @param data User-provided input data (polymorphic).\n * @param names An Array of expected Tensor names.\n * @param shapes Optional Array of expected Tensor shapes.\n * @param checkBatchAxis Whether to check that the batch axis of the arrays\n *   match  the expected value found in `shapes`.\n * @param exceptionPrefix String prefix used for exception formatting.\n * @returns List of standardized input Tensors (one Tensor per model input).\n * @throws ValueError: in case of improperly formatted user data.\n */\n\nexport function standardizeInputData(data, names, shapes, checkBatchAxis = true, exceptionPrefix = '') {\n  if (names == null || names.length === 0) {\n    // Check for the case where the model expected no data, but some data got\n    // sent.\n    if (data != null) {\n      let gotUnexpectedData = false;\n\n      if (isDataArray(data) && data.length > 0) {\n        gotUnexpectedData = true;\n      } else if (isDataDict(data)) {\n        for (const key in data) {\n          if (data.hasOwnProperty(key)) {\n            gotUnexpectedData = true;\n            break;\n          }\n        }\n      } else {\n        // `data` is a singleton Tensor in this case.\n        gotUnexpectedData = true;\n      }\n\n      if (gotUnexpectedData) {\n        throw new ValueError(`Error when checking model ${exceptionPrefix} expected no data, ` + `but got ${data}`);\n      }\n    }\n\n    return [];\n  }\n\n  if (data == null) {\n    return names.map(name => null);\n  }\n\n  let arrays;\n\n  if (isDataDict(data)) {\n    data = data;\n    arrays = [];\n\n    for (const name of names) {\n      if (data[name] == null) {\n        throw new ValueError(`No data provided for \"${name}\". Need data for each key in: ` + `${names}`);\n      }\n\n      arrays.push(data[name]);\n    }\n  } else if (isDataArray(data)) {\n    data = data;\n\n    if (data.length !== names.length) {\n      throw new ValueError(`Error when checking model ${exceptionPrefix}: the Array of ` + `Tensors that you are passing to your model is not the size the ` + `model expected. Expected to see ${names.length} Tensor(s), but ` + `instead got the following list of Tensor(s): ${data}`);\n    }\n\n    arrays = data;\n  } else {\n    data = data;\n\n    if (names.length > 1) {\n      throw new ValueError(`The model ${exceptionPrefix} expects ${names.length} Tensor(s), ` + `but only received one Tensor. Found: Tensor with shape ${data.shape}`);\n    }\n\n    arrays = [data];\n  }\n\n  arrays = ensureTensorsRank2OrHigher(arrays); // Check shape compatibility.\n\n  if (shapes != null) {\n    for (let i = 0; i < names.length; ++i) {\n      if (shapes[i] == null) {\n        continue;\n      }\n\n      const array = arrays[i];\n\n      if (array.shape.length !== shapes[i].length) {\n        throw new ValueError(`Error when checking ${exceptionPrefix}: expected ${names[i]} ` + `to have ${shapes[i].length} dimension(s). but got array with ` + `shape ${array.shape}`);\n      }\n\n      for (let j = 0; j < shapes[i].length; ++j) {\n        if (j === 0 && !checkBatchAxis) {\n          // Skip the first (batch) axis.\n          continue;\n        }\n\n        const dim = array.shape[j];\n        const refDim = shapes[i][j];\n\n        if (refDim != null && refDim >= 0 && dim !== refDim) {\n          throw new ValueError(`Error when checking ${exceptionPrefix}: expected ${names[i]} ` + `to have shape [${shapes[i]}], but got array with shape ` + `[${array.shape}].`);\n        }\n      }\n    }\n  }\n\n  return arrays;\n}\n/**\n * User input validation for Tensors.\n * @param inputs `Array` of `tf.Tensor`s for inputs.\n * @param targets `Array` of `tf.Tensor`s for targets.\n * @param weights Optional `Array` of `tf.Tensor`s for sample weights.\n * @throws ValueError: in case of incorrectly formatted data.\n */\n\nexport function checkArrayLengths(inputs, targets, weights) {\n  const setX = unique(inputs.map(input => input.shape[0]));\n  setX.sort();\n  const setY = unique(targets.map(target => target.shape[0]));\n  setY.sort(); // TODO(cais): Check `weights` as well.\n\n  if (setX.length > 1) {\n    throw new ValueError(`All input Tensors (x) should have the same number of samples. ` + `Got array shapes: ` + `${JSON.stringify(inputs.map(input => input.shape))}`);\n  }\n\n  if (setY.length > 1) {\n    throw new ValueError(`All target Tensors (y) should have the same number of samples. ` + `Got array shapes: ` + `${JSON.stringify(targets.map(target => target.shape))}`);\n  }\n\n  if (setX.length > 0 && setY.length > 0 && !util.arraysEqual(setX, setY)) {\n    throw new ValueError(`Input Tensors should have the same number of samples as target ` + `Tensors. Found ${setX[0]} input sample(s) and ${setY[0]} target ` + `sample(s).`);\n  }\n}\n/**\n * Validation on the compatibility of targes and loss functions.\n *\n * This helps prevent users from using loss functions incorrectly.\n *\n * @param targets `Array` of `tf.Tensor`s of targets.\n * @param lossFns `Array` of loss functions.\n * @param outputShapes `Array` of shapes of model outputs.\n */\n\nfunction checkLossAndTargetCompatibility(targets, lossFns, outputShapes) {\n  // TODO(cais): Dedicated test coverage?\n  const keyLosses = [losses.meanSquaredError, losses.binaryCrossentropy, losses.categoricalCrossentropy];\n\n  for (let i = 0; i < targets.length; ++i) {\n    const y = targets[i];\n    const loss = lossFns[i];\n    const shape = outputShapes[i];\n\n    if (loss == null) {\n      continue;\n    }\n\n    if (loss === losses.categoricalCrossentropy) {\n      if (y.shape[y.shape.length - 1] === 1) {\n        throw new ValueError(`You are passing a target array of shape ${y.shape} while using ` + `a loss 'categorical_crossentropy'. 'categorical_crossentropy'` + `expects targets to be binary matrices (1s and 0s) of shape ` + `[samples, classes].`); // TODO(cais): Example code in error message.\n      }\n    }\n\n    if (keyLosses.indexOf(loss) !== -1) {\n      const slicedYShape = y.shape.slice(1);\n      const slicedShape = shape.slice(1);\n\n      for (let j = 0; j < slicedYShape.length; ++j) {\n        const targetDim = slicedYShape[j];\n        const outDim = slicedShape[j];\n\n        if (outDim != null && targetDim !== outDim) {\n          throw new ValueError(`A target Tensor with shape ${y.shape} was passed for an ` + `output of shape ${shape}, while using a loss function that ` + `expects targets to have the same shape as the output.`);\n        }\n      }\n    }\n  }\n}\n/**\n * Check inputs provided by the user.\n *\n * Porting Note: This corresponds to _standardize_input_data() in Python\n *   Keras. Because of the strong typing in TF.js, we do not need to convert\n *   the data. Specifically:\n *   1) in PyKeras, `data` can be `DataFrame` instances from pandas, for\n *      example. We don't need to worry about that here because there is no\n *      widely popular javascript/typesdcript equivalent of pandas (so far).\n *      If one becomes available in the future, we can add support.\n *   2) in PyKeras, inputs can be Python dict. But here we are stipulating\n * that the data is either a single `tf.Tensor` or an Array of `tf.Tensor`s. We\n * may add support for `Object` data inputs in the future when the need\n * arises.\n *\n * Instead, we perform basic checks for number of parameters and shapes.\n *\n * @param data: The input data.\n * @param names: Name for the inputs, from the model.\n * @param shapes: Expected shapes for the input data, from the model.\n * @param checkBatchAxis: Whether the size along the batch axis (i.e., the\n *   first dimension) will be checked for matching.\n * @param exceptionPrefix: Execption prefix message, used in generating error\n *   messages.\n * @throws ValueError: on incorrect number of inputs or mismatches in shapes.\n */\n\n\nfunction checkInputData(data, names, shapes, checkBatchAxis = true, exceptionPrefix = '') {\n  let arrays;\n\n  if (Array.isArray(data)) {\n    if (data.length !== names.length) {\n      throw new ValueError(`Error when checking model ${exceptionPrefix}: the Array of ` + `Tensors that you are passing to your model is not the size the ` + `the model expected. Expected to see ${names.length} Tensor(s),` + ` but instead got ${data.length} Tensors(s).`);\n    }\n\n    arrays = data;\n  } else {\n    if (names.length > 1) {\n      throw new ValueError(`The model expects ${names.length} ${exceptionPrefix} Tensors, ` + `but only received one Tensor. Found: array with shape ` + `${JSON.stringify(data.shape)}.`);\n    }\n\n    arrays = [data];\n  }\n\n  if (shapes != null) {\n    for (let i = 0; i < names.length; ++i) {\n      if (shapes[i] == null) {\n        continue;\n      }\n\n      const array = arrays[i];\n\n      if (array.shape.length !== shapes[i].length) {\n        throw new ValueError(`Error when checking ${exceptionPrefix}: expected ${names[i]} ` + `to have ${shapes[i].length} dimension(s), but got array with ` + `shape ${JSON.stringify(array.shape)}`);\n      }\n\n      for (let j = 0; j < shapes[i].length; ++j) {\n        if (j === 0 && !checkBatchAxis) {\n          continue;\n        }\n\n        const dim = array.shape[j];\n        const refDim = shapes[i][j];\n\n        if (refDim != null) {\n          if (refDim !== dim) {\n            throw new ValueError(`Error when checking ${exceptionPrefix}: expected ` + `${names[i]} to have shape ${JSON.stringify(shapes[i])} but ` + `got array with shape ${JSON.stringify(array.shape)}.`);\n          }\n        }\n      }\n    }\n  }\n}\n/**\n * Maps metric functions to model outputs.\n * @param metrics An shortcut strings name, metric function, `Array` or dict\n *   (`Object`) of metric functions.\n * @param outputNames An `Array` of the names of model outputs.\n * @returns An `Array` (one entry per model output) of `Array` of metric\n *   functions. For instance, if the model has 2 outputs, and for the first\n *   output we want to compute `binaryAccuracy` and `binaryCrossentropy`,\n *   and just `binaryAccuracy` for the second output, the `Array` would look\n *   like:\n *     `[[binaryAccuracy, binaryCrossentropy],  [binaryAccuracy]]`\n * @throws TypeError: incompatible metrics format.\n */\n\n\nexport function collectMetrics(metrics, outputNames) {\n  if (metrics == null || Array.isArray(metrics) && metrics.length === 0) {\n    return outputNames.map(name => []);\n  }\n\n  let wrappedMetrics;\n\n  if (typeof metrics === 'string' || typeof metrics === 'function') {\n    wrappedMetrics = [metrics];\n  } else if (Array.isArray(metrics) || typeof metrics === 'object') {\n    wrappedMetrics = metrics;\n  } else {\n    throw new TypeError('Type of metrics argument not understood. Expected an string,' + `function, Array, or Object, found: ${metrics}`);\n  }\n\n  if (Array.isArray(wrappedMetrics)) {\n    // We then apply all metrics to all outputs.\n    return outputNames.map(name => wrappedMetrics);\n  } else {\n    // In this case, metrics is a dict.\n    const nestedMetrics = [];\n\n    for (const name of outputNames) {\n      let outputMetrics = wrappedMetrics.hasOwnProperty(name) ? wrappedMetrics[name] : [];\n\n      if (!Array.isArray(outputMetrics)) {\n        outputMetrics = [outputMetrics];\n      }\n\n      nestedMetrics.push(outputMetrics);\n    }\n\n    return nestedMetrics;\n  }\n}\nconst LAYERS_MODEL_FORMAT_NAME = 'layers-model';\n/**\n * A `tf.LayersModel` is a directed, acyclic graph of `tf.Layer`s plus methods\n * for training, evaluation, prediction and saving.\n *\n * `tf.LayersModel` is the basic unit of training, inference and evaluation in\n * TensorFlow.js. To create a `tf.LayersModel`, use `tf.LayersModel`.\n *\n * See also:\n *   `tf.Sequential`, `tf.loadLayersModel`.\n *\n * @doc {heading: 'Models', subheading: 'Classes'}\n */\n\nexport class LayersModel extends Container {\n  constructor(args) {\n    super(args);\n    this.isTraining = false;\n  }\n  /**\n   * Print a text summary of the model's layers.\n   *\n   * The summary includes\n   * - Name and type of all layers that comprise the model.\n   * - Output shape(s) of the layers\n   * - Number of weight parameters of each layer\n   * - If the model has non-sequential-like topology, the inputs each layer\n   *   receives\n   * - The total number of trainable and non-trainable parameters of the model.\n   *\n   * ```js\n   * const input1 = tf.input({shape: [10]});\n   * const input2 = tf.input({shape: [20]});\n   * const dense1 = tf.layers.dense({units: 4}).apply(input1);\n   * const dense2 = tf.layers.dense({units: 8}).apply(input2);\n   * const concat = tf.layers.concatenate().apply([dense1, dense2]);\n   * const output =\n   *     tf.layers.dense({units: 3, activation: 'softmax'}).apply(concat);\n   *\n   * const model = tf.model({inputs: [input1, input2], outputs: output});\n   * model.summary();\n   * ```\n   *\n   * @param lineLength Custom line length, in number of characters.\n   * @param positions Custom widths of each of the columns, as either\n   *   fractions of `lineLength` (e.g., `[0.5, 0.75, 1]`) or absolute number\n   *   of characters (e.g., `[30, 50, 65]`). Each number corresponds to\n   *   right-most (i.e., ending) position of a column.\n   * @param printFn Custom print function. Can be used to replace the default\n   *   `console.log`. For example, you can use `x => {}` to mute the printed\n   *   messages in the console.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n\n\n  summary(lineLength, positions, printFn = console.log) {\n    if (!this.built) {\n      throw new ValueError(`This model has never been called, thus its weights have not been ` + `created yet. So no summary can be displayed. Build the model ` + `first (e.g., by calling it on some test data).`);\n    }\n\n    printSummary(this, lineLength, positions, printFn);\n  }\n  /**\n   * Configures and prepares the model for training and evaluation.  Compiling\n   * outfits the model with an optimizer, loss, and/or metrics.  Calling `fit`\n   * or `evaluate` on an un-compiled model will throw an error.\n   *\n   * @param args a `ModelCompileArgs` specifying the loss, optimizer, and\n   * metrics to be used for fitting and evaluating this model.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n\n\n  compile(args) {\n    if (args.loss == null) {\n      args.loss = [];\n    }\n\n    this.loss = args.loss;\n\n    if (typeof args.optimizer === 'string') {\n      this.optimizer_ = optimizers.getOptimizer(args.optimizer);\n      this.isOptimizerOwned = true;\n    } else {\n      if (!(args.optimizer instanceof Optimizer)) {\n        throw new ValueError(`User-defined optimizer must be an instance of tf.Optimizer.`);\n      }\n\n      this.optimizer_ = args.optimizer;\n      this.isOptimizerOwned = false;\n    } // TODO(cais): Add lossWeights.\n    // TODO(cais): Add sampleWeightMode.\n    // Prepare loss functions.\n\n\n    let lossFunctions = [];\n\n    if (!Array.isArray(args.loss) && typeof args.loss !== 'string' && typeof args.loss !== 'function') {\n      args.loss = args.loss;\n\n      for (const name in args.loss) {\n        if (this.outputNames.indexOf(name) === -1) {\n          throw new ValueError(`Unknown entry in loss dictionary: \"${name}\". ` + `Only expected the following keys: ${this.outputNames}`);\n        }\n      }\n\n      for (const name of this.outputNames) {\n        if (args.loss[name] == null) {\n          console.warn(`Output \"${name}\" is missing from loss dictionary. We assume ` + `this was done on purpose, and we will not be expecting data ` + `to be passed to ${name} during training`);\n        }\n\n        lossFunctions.push(losses.get(args.loss[name]));\n      }\n    } else if (Array.isArray(args.loss)) {\n      if (args.loss.length !== this.outputs.length) {\n        throw new ValueError(`When passing an Array as loss, it should have one entry per ` + `model output. The model has ${this.outputs.length} output(s), ` + `but you passed loss=${args.loss}.`);\n      }\n\n      const theLosses = args.loss;\n      lossFunctions = theLosses.map(l => losses.get(l));\n    } else {\n      const lossFunction = losses.get(args.loss);\n      this.outputs.forEach(_ => {\n        lossFunctions.push(lossFunction);\n      });\n    }\n\n    this.lossFunctions = lossFunctions;\n    this.feedOutputNames = [];\n    this.feedOutputShapes = [];\n    this.feedLossFns = [];\n\n    for (let i = 0; i < this.outputs.length; ++i) {\n      // TODO(cais): Logic for skipping target(s).\n      const shape = this.internalOutputShapes[i];\n      const name = this.outputNames[i];\n      this.feedOutputNames.push(name);\n      this.feedOutputShapes.push(shape);\n      this.feedLossFns.push(this.lossFunctions[i]);\n    } // TODO(cais): Add logic for output masks.\n    // TODO(cais): Add logic for sample weights.\n\n\n    const skipTargetIndices = []; // Prepare metrics.\n\n    this.metrics = args.metrics; // TODO(cais): Add weightedMetrics.\n\n    this.metricsNames = ['loss'];\n    this.metricsTensors = []; // Compute total loss.\n    // Porting Note: In PyKeras, metrics_tensors are symbolic tensor objects.\n    //   Here, metricsTensors are TypeScript functions. This difference is due\n    //   to the difference in symbolic/imperative property of the backends.\n\n    nameScope('loss', () => {\n      for (let i = 0; i < this.outputs.length; ++i) {\n        if (skipTargetIndices.indexOf(i) !== -1) {\n          continue;\n        } // TODO(cais): Add weightedLoss, sampleWeight and mask.\n        //   The following line should be weightedLoss\n\n\n        const weightedLoss = this.lossFunctions[i];\n\n        if (this.outputs.length > 1) {\n          this.metricsTensors.push([weightedLoss, i]);\n          this.metricsNames.push(this.outputNames[i] + '_loss');\n        }\n      } // Porting Note: Due to the imperative nature of the backend, we calculate\n      //   the regularizer penalties in the totalLossFunction, instead of here.\n\n    });\n    const nestedMetrics = collectMetrics(args.metrics, this.outputNames); // TODO(cais): Add nestedWeightedMetrics.\n\n    /**\n     * Helper function used in loop below.\n     */\n\n    const appendMetric = (outputIndex, metricName, metricTensor) => {\n      if (this.outputNames.length > 1) {\n        metricName = this.outputNames[outputIndex] + '_' + metricName;\n      }\n\n      this.metricsNames.push(metricName);\n      this.metricsTensors.push([metricTensor, outputIndex]);\n    };\n\n    nameScope('metric', () => {\n      for (let i = 0; i < this.outputs.length; ++i) {\n        if (skipTargetIndices.indexOf(i) !== -1) {\n          continue;\n        }\n\n        const outputMetrics = nestedMetrics[i]; // TODO(cais): Add weights and outputWeightedMetrics.\n        // TODO(cais): Add optional arg `weights` to the following function.\n\n        const handleMetrics = metrics => {\n          const metricNamePrefix = '';\n          let metricName;\n          let accFn;\n          let weightedMetricFn; //  TODO(cais): Use 'weights_' for weighted metrics.\n\n          for (const metric of metrics) {\n            if (typeof metric === 'string' && ['accuracy', 'acc', 'crossentropy', 'ce'].indexOf(metric) !== -1) {\n              const outputShape = this.internalOutputShapes[i];\n\n              if (outputShape[outputShape.length - 1] === 1 || this.lossFunctions[i] === losses.binaryCrossentropy) {\n                // case: binary accuracy/crossentropy.\n                if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                  accFn = Metrics.binaryAccuracy;\n                } else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                  accFn = Metrics.binaryCrossentropy;\n                }\n              } else if (this.lossFunctions[i] === losses.sparseCategoricalCrossentropy) {\n                // case: categorical accuracy / crossentropy with sparse\n                // targets.\n                if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                  accFn = Metrics.sparseCategoricalAccuracy;\n                } else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                  accFn = Metrics.sparseCategoricalCrossentropy;\n                }\n              } else {\n                // case: categorical accuracy / crossentropy.\n                if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                  accFn = Metrics.categoricalAccuracy;\n                } else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                  accFn = Metrics.categoricalCrossentropy;\n                }\n              }\n\n              let suffix;\n\n              if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                suffix = 'acc';\n              } else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                suffix = 'ce';\n              } // TODO(cais): Add weighting actually.\n\n\n              weightedMetricFn = accFn;\n              metricName = metricNamePrefix + suffix;\n            } else {\n              const metricFn = Metrics.get(metric); // TODO(cais): Add weighting actually.\n\n              weightedMetricFn = metricFn;\n              metricName = metricNamePrefix + Metrics.getLossOrMetricName(metric);\n            } // TODO(cais): Add weighting and masking to metricResult.\n\n\n            let metricResult;\n            nameScope(metricName, () => {\n              metricResult = weightedMetricFn;\n            });\n            appendMetric(i, metricName, metricResult);\n          }\n        };\n\n        handleMetrics(outputMetrics); // TODO(cais): Call handleMetrics with weights.\n      }\n    }); // Porting Notes: Given the imperative backend of tfjs-core,\n    //   there is no need for constructing the symbolic graph and placeholders.\n\n    this.collectedTrainableWeights = this.trainableWeights;\n  }\n  /**\n   * Check trainable weights count consistency.\n   *\n   * This will raise a warning if `this.trainableWeights` and\n   * `this.collectedTrainableWeights` are inconsistent (i.e., have different\n   * numbers of parameters).\n   * Inconsistency will typically arise when one modifies `model.trainable`\n   * without calling `model.compile()` again.\n   */\n\n\n  checkTrainableWeightsConsistency() {\n    if (this.collectedTrainableWeights == null) {\n      return;\n    }\n\n    if (this.trainableWeights.length !== this.collectedTrainableWeights.length) {\n      console.warn('Discrepancy between trainableweights and collected trainable ' + 'weights. Did you set `model.trainable` without calling ' + '`model.compile()` afterwards?');\n    }\n  }\n  /**\n   * Returns the loss value & metrics values for the model in test mode.\n   *\n   * Loss and metrics are specified during `compile()`, which needs to happen\n   * before calls to `evaluate()`.\n   *\n   * Computation is done in batches.\n   *\n   * ```js\n   * const model = tf.sequential({\n   *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]\n   * });\n   * model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});\n   * const result = model.evaluate(\n   *     tf.ones([8, 10]), tf.ones([8, 1]), {batchSize: 4});\n   * result.print();\n   * ```\n   *\n   * @param x `tf.Tensor` of test data, or an `Array` of `tf.Tensor`s if the\n   * model has multiple inputs.\n   * @param y `tf.Tensor` of target data, or an `Array` of `tf.Tensor`s if the\n   * model has multiple outputs.\n   * @param args A `ModelEvaluateArgs`, containing optional fields.\n   *\n   * @return `Scalar` test loss (if the model has a single output and no\n   *   metrics) or `Array` of `Scalar`s (if the model has multiple outputs\n   *   and/or metrics). The attribute `model.metricsNames`\n   *   will give you the display labels for the scalar outputs.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n\n\n  evaluate(x, y, args = {}) {\n    const batchSize = args.batchSize == null ? 32 : args.batchSize;\n    checkBatchSize(batchSize); // TODO(cais): Standardize `config.sampleWeights` as well.\n    // Validate user data.\n\n    const checkBatchAxis = true;\n    const standardizedOuts = this.standardizeUserDataXY(x, y, checkBatchAxis, batchSize);\n\n    try {\n      // TODO(cais): If uses `useLearningPhase`, set the corresponding element\n      // of the input to 0.\n      const ins = standardizedOuts[0].concat(standardizedOuts[1]);\n      this.makeTestFunction();\n      const f = this.testFunction;\n      const testOuts = this.testLoop(f, ins, batchSize, args.verbose, args.steps);\n      return singletonOrArray(testOuts);\n    } finally {\n      disposeNewTensors(standardizedOuts[0], x);\n      disposeNewTensors(standardizedOuts[1], y);\n    }\n  } // TODO(cais): Add code snippet below once real dataset objects are\n  //   available.\n\n  /**\n   * Evaluate model using a dataset object.\n   *\n   * Note: Unlike `evaluate()`, this method is asynchronous (`async`);\n   *\n   * @param dataset A dataset object. Its `iterator()` method is expected\n   *   to generate a dataset iterator object, the `next()` method of which\n   *   is expected to produce data batches for evaluation. The return value\n   *   of the `next()` call ought to contain a boolean `done` field and a\n   *   `value` field. The `value` field is expected to be an array of two\n   *   `tf.Tensor`s or an array of two nested `tf.Tensor` structures. The former\n   *   case is for models with exactly one input and one output (e.g..\n   *   a sequential model). The latter case is for models with multiple\n   *   inputs and/or multiple outputs. Of the two items in the array, the\n   *   first is the input feature(s) and the second is the output target(s).\n   * @param args A configuration object for the dataset-based evaluation.\n   * @returns Loss and metric values as an Array of `Scalar` objects.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n\n\n  evaluateDataset(dataset, args) {\n    var _this = this;\n\n    return _asyncToGenerator(function* () {\n      _this.makeTestFunction();\n\n      return evaluateDataset(_this, dataset, args);\n    })();\n  }\n  /**\n   * Get number of samples provided for training, evaluation or prediction.\n   *\n   * @param ins Input `tf.Tensor`.\n   * @param batchSize Integer batch size, optional.\n   * @param steps Total number of steps (batches of samples) before\n   * declaring loop finished. Optional.\n   * @param stepsName The public API's parameter name for `steps`.\n   * @returns Number of samples provided.\n   */\n\n\n  checkNumSamples(ins, batchSize, steps, stepsName = 'steps') {\n    let numSamples;\n\n    if (steps != null) {\n      numSamples = null;\n\n      if (batchSize != null) {\n        throw new ValueError(`If ${stepsName} is set, batchSize must be null or undefined.` + `Got batchSize = ${batchSize}`);\n      }\n    } else if (ins != null) {\n      if (Array.isArray(ins)) {\n        numSamples = ins[0].shape[0];\n      } else {\n        numSamples = ins.shape[0];\n      }\n    } else {\n      throw new ValueError(`Either the input data should have a defined shape, or ` + `${stepsName} shoud be specified.`);\n    }\n\n    return numSamples;\n  }\n  /**\n   * Execute internal tensors of the model with input data feed.\n   * @param inputs Input data feed. Must match the inputs of the model.\n   * @param outputs Names of the output tensors to be fetched. Must match\n   *   names of the SymbolicTensors that belong to the graph.\n   * @returns Fetched values for `outputs`.\n   */\n\n\n  execute(inputs, outputs) {\n    if (Array.isArray(outputs) && outputs.length === 0) {\n      throw new ValueError('`outputs` is an empty Array, which is not allowed.');\n    }\n\n    const outputsIsArray = Array.isArray(outputs);\n    const outputNames = outputsIsArray ? outputs : [outputs];\n    const outputSymbolicTensors = this.retrieveSymbolicTensors(outputNames); // Format the input into a FeedDict.\n\n    const feedDict = new FeedDict();\n\n    if (inputs instanceof Tensor) {\n      inputs = [inputs];\n    }\n\n    if (Array.isArray(inputs)) {\n      if (inputs.length !== this.inputs.length) {\n        throw new ValueError(`The number of inputs provided (${inputs.length}) ` + `does not match the number of inputs of this model ` + `(${this.inputs.length}).`);\n      }\n\n      for (let i = 0; i < this.inputs.length; ++i) {\n        feedDict.add(this.inputs[i], inputs[i]);\n      }\n    } else {\n      for (const input of this.inputs) {\n        const tensorValue = inputs[input.name];\n\n        if (tensorValue == null) {\n          throw new ValueError(`No value is provided for the model's input ${input.name}`);\n        }\n\n        feedDict.add(input, tensorValue);\n      }\n    } // Run execution.\n\n\n    const executeOutputs = execute(outputSymbolicTensors, feedDict);\n    return outputsIsArray ? executeOutputs : executeOutputs[0];\n  }\n  /**\n   * Retrieve the model's internal symbolic tensors from symbolic-tensor names.\n   */\n\n\n  retrieveSymbolicTensors(symbolicTensorNames) {\n    const outputSymbolicTensors = pyListRepeat(null, symbolicTensorNames.length);\n    let outputsRemaining = symbolicTensorNames.length;\n\n    for (const layer of this.layers) {\n      const layerOutputs = Array.isArray(layer.output) ? layer.output : [layer.output];\n      const layerOutputNames = layerOutputs.map(output => output.name);\n\n      for (let i = 0; i < symbolicTensorNames.length; ++i) {\n        const index = layerOutputNames.indexOf(symbolicTensorNames[i]);\n\n        if (index !== -1) {\n          outputSymbolicTensors[i] = layerOutputs[index];\n          outputsRemaining--;\n        }\n\n        if (outputsRemaining === 0) {\n          break;\n        }\n      }\n\n      if (outputsRemaining === 0) {\n        break;\n      }\n    }\n\n    if (outputsRemaining > 0) {\n      const remainingNames = [];\n      outputSymbolicTensors.forEach((tensor, i) => {\n        if (tensor == null) {\n          remainingNames.push(symbolicTensorNames[i]);\n        }\n      });\n      throw new ValueError(`Cannot find SymbolicTensors for output name(s): ` + `${JSON.stringify(remainingNames)}`);\n    }\n\n    return outputSymbolicTensors;\n  }\n  /**\n   * Helper method to loop over some data in batches.\n   *\n   * Porting Note: Not using the functional approach in the Python equivalent\n   *   due to the imperative backend.\n   * Porting Note: Does not support step mode currently.\n   *\n   * @param ins: input data\n   * @param batchSize: integer batch size.\n   * @param verbose: verbosity model\n   * @returns: Predictions as `tf.Tensor` (if a single output) or an `Array` of\n   *   `tf.Tensor` (if multipe outputs).\n   */\n\n\n  predictLoop(ins, batchSize = 32, verbose = false) {\n    return tfc.tidy(() => {\n      const numSamples = this.checkNumSamples(ins);\n\n      if (verbose) {\n        throw new NotImplementedError('Verbose predictLoop() is not implemented yet.');\n      } // Sample-based predictions.\n      // Porting Note: Tensor currently does not support sliced assignments as\n      //   in numpy, e.g., x[1:3] = y. Therefore we use concatenation while\n      //   iterating over the batches.\n\n\n      const batches = makeBatches(numSamples, batchSize);\n      const outsBatches = this.outputs.map(output => []); // TODO(cais): Can the scope() be pushed down inside the for loop?\n\n      for (let batchIndex = 0; batchIndex < batches.length; ++batchIndex) {\n        const batchOuts = tfc.tidy(() => {\n          const batchStart = batches[batchIndex][0];\n          const batchEnd = batches[batchIndex][1]; // TODO(cais): Take care of the case of the last element is a flag for\n          //   training/test.\n\n          const insBatch = sliceArrays(ins, batchStart, batchEnd); // Construct the feeds for execute();\n\n          const feeds = [];\n\n          if (Array.isArray(insBatch)) {\n            for (let i = 0; i < insBatch.length; ++i) {\n              feeds.push({\n                key: this.inputs[i],\n                value: insBatch[i]\n              });\n            }\n          } else {\n            feeds.push({\n              key: this.inputs[0],\n              value: insBatch\n            });\n          }\n\n          const feedDict = new FeedDict(feeds);\n          return execute(this.outputs, feedDict);\n        });\n        batchOuts.forEach((batchOut, i) => outsBatches[i].push(batchOut));\n      }\n\n      return singletonOrArray(outsBatches.map(batches => tfc.concat(batches, 0)));\n    });\n  }\n  /**\n   * Generates output predictions for the input samples.\n   *\n   * Computation is done in batches.\n   *\n   * Note: the \"step\" mode of predict() is currently not supported.\n   *   This is because the TensorFlow.js core backend is imperative only.\n   *\n   * ```js\n   * const model = tf.sequential({\n   *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]\n   * });\n   * model.predict(tf.ones([8, 10]), {batchSize: 4}).print();\n   * ```\n   *\n   * @param x The input data, as a Tensor, or an `Array` of `tf.Tensor`s if\n   *   the model has multiple inputs.\n   * @param args A `ModelPredictArgs` object containing optional fields.\n   *\n   * @return Prediction results as a `tf.Tensor`(s).\n   *\n   * @exception ValueError In case of mismatch between the provided input data\n   *   and the model's expectations, or in case a stateful model receives a\n   *   number of samples that is not a multiple of the batch size.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n\n\n  predict(x, args = {}) {\n    const xsRank2OrHigher = ensureTensorsRank2OrHigher(x);\n    checkInputData(xsRank2OrHigher, this.inputNames, this.feedInputShapes, false);\n\n    try {\n      // TODO(cais): Take care of stateful models.\n      //   if (this.stateful) ...\n      // TODO(cais): Take care of the learning_phase boolean flag.\n      //   if (this.useLearningPhase) ...\n      const batchSize = args.batchSize == null ? 32 : args.batchSize;\n      checkBatchSize(batchSize);\n      return this.predictLoop(xsRank2OrHigher, batchSize);\n    } finally {\n      disposeNewTensors(xsRank2OrHigher, x);\n    }\n  }\n  /**\n   * Returns predictions for a single batch of samples.\n   *\n   * ```js\n   * const model = tf.sequential({\n   *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]\n   * });\n   * model.predictOnBatch(tf.ones([8, 10])).print();\n   * ```\n   * @param x: Input samples, as a Tensor (for models with exactly one\n   *   input) or an array of Tensors (for models with more than one input).\n   * @return Tensor(s) of predictions\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n\n\n  predictOnBatch(x) {\n    checkInputData(x, this.inputNames, this.feedInputShapes, true); // TODO(cais): Take care of the learning_phase boolean flag.\n    //   if (this.useLearningPhase) ...\n\n    const batchSize = (Array.isArray(x) ? x[0] : x).shape[0];\n    return this.predictLoop(x, batchSize);\n  }\n\n  standardizeUserDataXY(x, y, checkBatchAxis = true, batchSize) {\n    // TODO(cais): Add sampleWeight, classWeight\n    if (this.optimizer_ == null) {\n      throw new RuntimeError('You must compile a model before training/testing. Use ' + 'LayersModel.compile(modelCompileArgs).');\n    }\n\n    const outputShapes = [];\n\n    for (let i = 0; i < this.feedOutputShapes.length; ++i) {\n      const outputShape = this.feedOutputShapes[i];\n      const lossFn = this.feedLossFns[i];\n\n      if (lossFn === losses.sparseCategoricalCrossentropy) {\n        outputShapes.push(outputShape.slice(0, outputShape.length - 1).concat([1]));\n      } else {\n        // Porting Note: Because of strong typing `lossFn` must be a function.\n        outputShapes.push(outputShape);\n      }\n    }\n\n    x = standardizeInputData(x, this.feedInputNames, this.feedInputShapes, false, 'input');\n    y = standardizeInputData(y, this.feedOutputNames, outputShapes, false, 'target'); // TODO(cais): Standardize sampleWeights & classWeights.\n\n    checkArrayLengths(x, y, null); // TODO(cais): Check sampleWeights as well.\n\n    checkLossAndTargetCompatibility(y, this.feedLossFns, this.feedOutputShapes);\n\n    if (this.stateful && batchSize != null && batchSize > 0) {\n      if (x[0].shape[0] % batchSize !== 0) {\n        throw new ValueError(`In a stateful network, you should only pass inputs with a ` + `number of samples that is divisible by the batch size ` + `${batchSize}. Found: ${x[0].shape[0]} sample(s).`);\n      }\n    }\n\n    return [x, y];\n  }\n\n  standardizeUserData(x, y, sampleWeight, classWeight, checkBatchAxis = true, batchSize) {\n    var _this2 = this;\n\n    return _asyncToGenerator(function* () {\n      const [standardXs, standardYs] = _this2.standardizeUserDataXY(x, y, checkBatchAxis, batchSize); // TODO(cais): Handle sampleWeights.\n\n\n      if (sampleWeight != null) {\n        throw new Error('sample weight is not supported yet.');\n      }\n\n      let standardSampleWeights = null;\n\n      if (classWeight != null) {\n        const classWeights = standardizeClassWeights(classWeight, _this2.outputNames);\n        standardSampleWeights = [];\n\n        for (let i = 0; i < classWeights.length; ++i) {\n          standardSampleWeights.push(yield standardizeWeights(standardYs[i], null, classWeights[i]));\n        }\n      } // TODO(cais): Deal with the case of model.stateful == true.\n\n\n      return [standardXs, standardYs, standardSampleWeights];\n    })();\n  }\n  /**\n   * Loop over some test data in batches.\n   * @param f A Function returning a list of tensors.\n   * @param ins Array of tensors to be fed to `f`.\n   * @param batchSize Integer batch size or `null` / `undefined`.\n   * @param verbose verbosity mode.\n   * @param steps Total number of steps (batches of samples) before\n   * declaring test finished. Ignored with the default value of `null` /\n   * `undefined`.\n   * @returns Array of Scalars.\n   */\n\n\n  testLoop(f, ins, batchSize, verbose = 0, steps) {\n    return tfc.tidy(() => {\n      const numSamples = this.checkNumSamples(ins, batchSize, steps, 'steps');\n      const outs = [];\n\n      if (verbose > 0) {\n        throw new NotImplementedError('Verbose mode is not implemented yet.');\n      } // TODO(cais): Use `indicesForConversionToDense' to prevent slow down.\n\n\n      if (steps != null) {\n        throw new NotImplementedError('steps mode in testLoop() is not implemented yet');\n      } else {\n        const batches = makeBatches(numSamples, batchSize);\n        const indexArray = tensor1d(range(0, numSamples));\n\n        for (let batchIndex = 0; batchIndex < batches.length; ++batchIndex) {\n          const batchStart = batches[batchIndex][0];\n          const batchEnd = batches[batchIndex][1];\n          const batchIds = K.sliceAlongFirstAxis(indexArray, batchStart, batchEnd - batchStart); // TODO(cais): In ins, train flag can be a number, instead of an\n          //   Tensor? Do we need to handle this in tfjs-layers?\n\n          const insBatch = sliceArraysByIndices(ins, batchIds);\n          const batchOuts = f(insBatch);\n\n          if (batchIndex === 0) {\n            for (let i = 0; i < batchOuts.length; ++i) {\n              outs.push(scalar(0));\n            }\n          }\n\n          for (let i = 0; i < batchOuts.length; ++i) {\n            const batchOut = batchOuts[i];\n            outs[i] = tfc.add(outs[i], tfc.mul(batchEnd - batchStart, batchOut));\n          }\n        }\n\n        for (let i = 0; i < outs.length; ++i) {\n          outs[i] = tfc.div(outs[i], numSamples);\n        }\n      }\n\n      return outs;\n    });\n  }\n\n  getDedupedMetricsNames() {\n    const outLabels = this.metricsNames; // Rename duplicated metrics names (can happen with an output layer\n    // shared among multiple dataflows).\n\n    const dedupedOutLabels = [];\n\n    for (let i = 0; i < outLabels.length; ++i) {\n      const label = outLabels[i];\n      let newLabel = label;\n\n      if (count(outLabels, label) > 1) {\n        const dupIndex = count(outLabels.slice(0, i), label);\n        newLabel += `_${dupIndex}`;\n      }\n\n      dedupedOutLabels.push(newLabel);\n    }\n\n    return dedupedOutLabels;\n  }\n  /**\n   * Creates a function that performs the following actions:\n   *\n   * 1. computes the losses\n   * 2. sums them to get the total loss\n   * 3. call the optimizer computes the gradients of the LayersModel's\n   *    trainable weights w.r.t. the total loss and update the variables\n   * 4. calculates the metrics\n   * 5. returns the values of the losses and metrics.\n   */\n\n\n  makeTrainFunction() {\n    return data => {\n      const lossValues = [];\n      const inputs = data.slice(0, this.inputs.length);\n      const targets = data.slice(this.inputs.length, this.inputs.length + this.outputs.length);\n      const sampleWeights = data.slice(this.inputs.length + this.outputs.length, this.inputs.length + this.outputs.length * 2);\n      const metricsValues = []; // Create a function that computes the total loss based on the\n      // inputs. This function is used for obtaining gradients through\n      // backprop.\n\n      const totalLossFunction = () => {\n        const feeds = [];\n\n        for (let i = 0; i < this.inputs.length; ++i) {\n          feeds.push({\n            key: this.inputs[i],\n            value: inputs[i]\n          });\n        }\n\n        const feedDict = new FeedDict(feeds);\n        const outputs = execute(this.outputs, feedDict, {\n          'training': true\n        }); // TODO(cais): Take care of the case of multiple outputs from a\n        //   single layer?\n\n        let totalLoss;\n\n        for (let i = 0; i < this.lossFunctions.length; ++i) {\n          const lossFunction = this.lossFunctions[i];\n          let loss = lossFunction(targets[i], outputs[i]);\n\n          if (sampleWeights[i] != null) {\n            loss = computeWeightedLoss(loss, sampleWeights[i]);\n          } // TODO(cais): push Scalar instead.\n\n\n          const meanLoss = tfc.mean(loss); // TODO(cais): Use a scope() instead, to avoid ownership.\n\n          lossValues.push(meanLoss);\n\n          if (i === 0) {\n            totalLoss = loss;\n          } else {\n            totalLoss = tfc.add(totalLoss, loss);\n          }\n        } // Compute the metrics.\n        // TODO(cais): These should probably be calculated outside\n        //   totalLossFunction to benefit speed?\n\n\n        for (let i = 0; i < this.metricsTensors.length; ++i) {\n          let weightedMetric;\n\n          if (this.outputs.length > 1 && i < this.outputs.length) {\n            weightedMetric = lossValues[i];\n          } else {\n            const metric = this.metricsTensors[i][0];\n            const outputIndex = this.metricsTensors[i][1];\n            weightedMetric = tfc.mean(metric(targets[outputIndex], outputs[outputIndex]));\n          }\n\n          tfc.keep(weightedMetric); // TODO(cais): Use a scope() instead, to avoid ownership.\n\n          metricsValues.push(weightedMetric);\n        }\n\n        totalLoss = tfc.mean(totalLoss); // Add regularizer penalties.\n\n        this.calculateLosses().forEach(regularizerLoss => {\n          totalLoss = tfc.add(totalLoss, regularizerLoss);\n        });\n        return totalLoss;\n      };\n\n      const variables = this.collectedTrainableWeights.map(param => param.read());\n      const returnCost = true;\n      const totalLossValue = this.optimizer_.minimize(totalLossFunction, returnCost, variables);\n      return [totalLossValue].concat(metricsValues);\n    };\n  }\n  /**\n   * Create a function which, when invoked with an array of `tf.Tensor`s as a\n   * batch of inputs, returns the prespecified loss and metrics of the model\n   * under the batch of input data.\n   */\n\n\n  makeTestFunction() {\n    this.testFunction = data => {\n      return tfc.tidy(() => {\n        const valOutputs = [];\n        let totalLoss;\n        const inputs = data.slice(0, this.inputs.length);\n        const targets = data.slice(this.inputs.length, this.inputs.length + this.outputs.length);\n        const feeds = [];\n\n        for (let i = 0; i < this.inputs.length; ++i) {\n          feeds.push({\n            key: this.inputs[i],\n            value: inputs[i]\n          });\n        }\n\n        const feedDict = new FeedDict(feeds);\n        const outputs = execute(this.outputs, feedDict); // Compute total loss.\n\n        for (let i = 0; i < this.lossFunctions.length; ++i) {\n          const lossFunction = this.lossFunctions[i]; // TODO(cais): Add sample weighting and replace the simple\n          // averaging.\n\n          const loss = tfc.mean(lossFunction(targets[i], outputs[i]));\n\n          if (i === 0) {\n            totalLoss = loss;\n          } else {\n            totalLoss = tfc.add(totalLoss, loss);\n          }\n\n          valOutputs.push(totalLoss);\n        } // Compute the metrics.\n\n\n        for (let i = 0; i < this.metricsTensors.length; ++i) {\n          const metric = this.metricsTensors[i][0];\n          const outputIndex = this.metricsTensors[i][1]; // TODO(cais): Replace K.mean() with a proper weighting function.\n\n          const meanMetric = tfc.mean(metric(targets[outputIndex], outputs[outputIndex]));\n          valOutputs.push(meanMetric);\n        }\n\n        return valOutputs;\n      });\n    };\n  }\n  /**\n   * Trains the model for a fixed number of epochs (iterations on a\n   * dataset).\n   *\n   * ```js\n   * const model = tf.sequential({\n   *     layers: [tf.layers.dense({units: 1, inputShape: [10]})]\n   * });\n   * model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});\n   * for (let i = 1; i < 5 ; ++i) {\n   *   const h = await model.fit(tf.ones([8, 10]), tf.ones([8, 1]), {\n   *       batchSize: 4,\n   *       epochs: 3\n   *   });\n   *   console.log(\"Loss after Epoch \" + i + \" : \" + h.history.loss[0]);\n   * }\n   * ```\n   *\n   * @param x `tf.Tensor` of training data, or an array of `tf.Tensor`s if the\n   * model has multiple inputs. If all inputs in the model are named, you\n   * can also pass a dictionary mapping input names to `tf.Tensor`s.\n   * @param y `tf.Tensor` of target (label) data, or an array of `tf.Tensor`s if\n   * the model has multiple outputs. If all outputs in the model are named,\n   * you can also pass a dictionary mapping output names to `tf.Tensor`s.\n   * @param args A `ModelFitArgs`, containing optional fields.\n   *\n   * @return A `History` instance. Its `history` attribute contains all\n   *   information collected during training.\n   *\n   * @exception ValueError In case of mismatch between the provided input\n   * data and what the model expects.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n\n\n  fit(x, y, args = {}) {\n    var _this3 = this;\n\n    return _asyncToGenerator(function* () {\n      return fitTensors(_this3, x, y, args);\n    })();\n  } // TODO(cais): Add code snippet below when it's possible to instantiate\n  //   actual dataset objects.\n\n  /**\n   * Trains the model using a dataset object.\n   *\n   * @param dataset A dataset object. Its `iterator()` method is expected\n   *   to generate a dataset iterator object, the `next()` method of which\n   *   is expected to produce data batches for training. The return value\n   *   of the `next()` call ought to contain a boolean `done` field and a\n   *   `value` field. The `value` field is expected to be an array of two\n   *   `tf.Tensor`s or an array of two nested `tf.Tensor` structures. The former\n   *   case is for models with exactly one input and one output (e.g..\n   *   a sequential model). The latter case is for models with multiple\n   *   inputs and/or multiple outputs.\n   *   Of the two items in the array, the first is the input feature(s) and\n   *   the second is the output target(s).\n   * @param args A `ModelFitDatasetArgs`, containing optional fields.\n   *\n   * @return A `History` instance. Its `history` attribute contains all\n   *   information collected during training.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n\n\n  fitDataset(dataset, args) {\n    var _this4 = this;\n\n    return _asyncToGenerator(function* () {\n      return fitDataset(_this4, dataset, args);\n    })();\n  }\n  /**\n   * Runs a single gradient update on a single batch of data.\n   *\n   * This method differs from `fit()` and `fitDataset()` in the following\n   * regards:\n   *   - It operates on exactly one batch of data.\n   *   - It returns only the loss and matric values, instead of\n   *     returning the batch-by-batch loss and metric values.\n   *   - It doesn't support fine-grained options such as verbosity and\n   *     callbacks.\n   *\n   * @param x Input data. It could be one of the following:\n   *   - A `tf.Tensor`, or an Array of `tf.Tensor`s (in case the model has\n   *     multiple inputs).\n   *   - An Object mapping input names to corresponding `tf.Tensor` (if the\n   *     model has named inputs).\n   * @param y Target darta. It could be either a `tf.Tensor` a multiple\n   *   `tf.Tensor`s. It should be consistent with `x`.\n   * @returns Training loss or losses (in case the model has\n   *   multiple outputs), along with metrics (if any), as numbers.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n\n\n  trainOnBatch(x, y) {\n    var _this5 = this;\n\n    return _asyncToGenerator(function* () {\n      // TODO(cais): Support sampleWeight and classWeight.\n      // TODO(cais): Support Dataset objects.\n      const standardizeOut = yield _this5.standardizeUserData(x, y);\n      const inputs = standardizeOut[0];\n      const targets = standardizeOut[1];\n\n      const trainFunction = _this5.makeTrainFunction();\n\n      const losses = trainFunction(inputs.concat(targets));\n      const lossValues = [];\n\n      for (const loss of losses) {\n        const v = yield loss.data();\n        lossValues.push(v[0]);\n      }\n\n      tfc.dispose(losses);\n      return singletonOrArray(lossValues);\n    })();\n  }\n  /**\n   * Extract weight values of the model.\n   *\n   * @param config: An instance of `io.SaveConfig`, which specifies\n   * model-saving options such as whether only trainable weights are to be\n   * saved.\n   * @returns A `NamedTensorMap` mapping original weight names (i.e.,\n   *   non-uniqueified weight names) to their values.\n   */\n\n\n  getNamedWeights(config) {\n    const namedWeights = [];\n    const trainableOnly = config != null && config.trainableOnly;\n    const weights = trainableOnly ? this.trainableWeights : this.weights;\n    const weightValues = this.getWeights(trainableOnly);\n\n    for (let i = 0; i < weights.length; ++i) {\n      if (trainableOnly && !weights[i].trainable) {\n        // Optionally skip non-trainable weights.\n        continue;\n      }\n\n      namedWeights.push({\n        name: weights[i].originalName,\n        tensor: weightValues[i]\n      });\n    }\n\n    return namedWeights;\n  }\n  /**\n   * Setter used for force stopping of LayersModel.fit() (i.e., training).\n   *\n   * Example:\n   *\n   * ```js\n   * const input = tf.input({shape: [10]});\n   * const output = tf.layers.dense({units: 1}).apply(input);\n   * const model = tf.model({inputs: [input], outputs: [output]});\n   * model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});\n   * const xs = tf.ones([8, 10]);\n   * const ys = tf.zeros([8, 1]);\n   *\n   * const history = await model.fit(xs, ys, {\n   *   epochs: 10,\n   *   callbacks: {\n   *     onEpochEnd: async (epoch, logs) => {\n   *       if (epoch === 2) {\n   *         model.stopTraining = true;\n   *       }\n   *     }\n   *   }\n   * });\n   *\n   * // There should be only 3 values in the loss array, instead of 10\n   * values,\n   * // due to the stopping after 3 epochs.\n   * console.log(history.history.loss);\n   * ```\n   */\n\n\n  set stopTraining(stop) {\n    this.stopTraining_ = stop;\n  }\n\n  get stopTraining() {\n    return this.stopTraining_;\n  }\n\n  get optimizer() {\n    return this.optimizer_;\n  }\n\n  set optimizer(optimizer) {\n    if (this.optimizer_ !== optimizer) {\n      this.optimizer_ = optimizer;\n      this.isOptimizerOwned = false;\n    }\n  }\n\n  dispose() {\n    const result = super.dispose();\n\n    if (result.refCountAfterDispose === 0 && this.optimizer != null && this.isOptimizerOwned) {\n      const numTensorsBeforeOptmizerDisposal = tfc.memory().numTensors;\n      this.optimizer_.dispose();\n      result.numDisposedVariables += numTensorsBeforeOptmizerDisposal - tfc.memory().numTensors;\n    }\n\n    return result;\n  }\n\n  getLossIdentifiers() {\n    let lossNames;\n\n    if (typeof this.loss === 'string') {\n      lossNames = toSnakeCase(this.loss);\n    } else if (Array.isArray(this.loss)) {\n      for (const loss of this.loss) {\n        if (typeof loss !== 'string') {\n          throw new Error('Serialization of non-string loss is not supported.');\n        }\n      }\n\n      lossNames = this.loss.map(name => toSnakeCase(name));\n    } else {\n      const outputNames = Object.keys(this.loss);\n      lossNames = {};\n      const losses = this.loss;\n\n      for (const outputName of outputNames) {\n        if (typeof losses[outputName] === 'string') {\n          lossNames[outputName] = toSnakeCase(losses[outputName]);\n        } else {\n          throw new Error('Serialization of non-string loss is not supported.');\n        }\n      }\n    }\n\n    return lossNames;\n  }\n\n  getMetricIdentifiers() {\n    if (typeof this.metrics === 'string' || typeof this.metrics === 'function') {\n      return [toSnakeCase(Metrics.getLossOrMetricName(this.metrics))];\n    } else if (Array.isArray(this.metrics)) {\n      return this.metrics.map(metric => toSnakeCase(Metrics.getLossOrMetricName(metric)));\n    } else {\n      const metricsIdentifiers = {};\n\n      for (const key in this.metrics) {\n        metricsIdentifiers[key] = toSnakeCase(Metrics.getLossOrMetricName(this.metrics[key]));\n      }\n\n      return metricsIdentifiers;\n    }\n  }\n\n  getTrainingConfig() {\n    return {\n      loss: this.getLossIdentifiers(),\n      metrics: this.getMetricIdentifiers(),\n      optimizer_config: {\n        class_name: this.optimizer.getClassName(),\n        config: this.optimizer.getConfig()\n      }\n    }; // TODO(cais): Add weight_metrics when they are supported.\n    // TODO(cais): Add sample_weight_mode when it's supported.\n    // TODO(cais): Add loss_weights when it's supported.\n  }\n\n  loadTrainingConfig(trainingConfig) {\n    if (trainingConfig.weighted_metrics != null) {\n      throw new Error('Loading weight_metrics is not supported yet.');\n    }\n\n    if (trainingConfig.loss_weights != null) {\n      throw new Error('Loading loss_weights is not supported yet.');\n    }\n\n    if (trainingConfig.sample_weight_mode != null) {\n      throw new Error('Loading sample_weight_mode is not supported yet.');\n    }\n\n    const tsConfig = convertPythonicToTs(trainingConfig.optimizer_config);\n    const optimizer = deserialize(tsConfig);\n    let loss;\n\n    if (typeof trainingConfig.loss === 'string') {\n      loss = toCamelCase(trainingConfig.loss);\n    } else if (Array.isArray(trainingConfig.loss)) {\n      loss = trainingConfig.loss.map(lossEntry => toCamelCase(lossEntry));\n    } else if (trainingConfig.loss != null) {\n      loss = {};\n\n      for (const key in trainingConfig.loss) {\n        loss[key] = toCamelCase(trainingConfig.loss[key]);\n      }\n    }\n\n    let metrics;\n\n    if (Array.isArray(trainingConfig.metrics)) {\n      metrics = trainingConfig.metrics.map(metric => toCamelCase(metric));\n    } else if (trainingConfig.metrics != null) {\n      metrics = {};\n\n      for (const key in trainingConfig.metrics) {\n        metrics[key] = toCamelCase(trainingConfig.metrics[key]);\n      }\n    }\n\n    this.compile({\n      loss,\n      metrics,\n      optimizer\n    });\n  }\n  /**\n   * Save the configuration and/or weights of the LayersModel.\n   *\n   * An `IOHandler` is an object that has a `save` method of the proper\n   * signature defined. The `save` method manages the storing or\n   * transmission of serialized data (\"artifacts\") that represent the\n   * model's topology and weights onto or via a specific medium, such as\n   * file downloads, local storage, IndexedDB in the web browser and HTTP\n   * requests to a server. TensorFlow.js provides `IOHandler`\n   * implementations for a number of frequently used saving mediums, such as\n   * `tf.io.browserDownloads` and `tf.io.browserLocalStorage`. See `tf.io`\n   * for more details.\n   *\n   * This method also allows you to refer to certain types of `IOHandler`s\n   * as URL-like string shortcuts, such as 'localstorage://' and\n   * 'indexeddb://'.\n   *\n   * Example 1: Save `model`'s topology and weights to browser [local\n   * storage](https://developer.mozilla.org/en-US/docs/Web/API/Window/localStorage);\n   * then load it back.\n   *\n   * ```js\n   * const model = tf.sequential(\n   *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});\n   * console.log('Prediction from original model:');\n   * model.predict(tf.ones([1, 3])).print();\n   *\n   * const saveResults = await model.save('localstorage://my-model-1');\n   *\n   * const loadedModel = await tf.loadLayersModel('localstorage://my-model-1');\n   * console.log('Prediction from loaded model:');\n   * loadedModel.predict(tf.ones([1, 3])).print();\n   * ```\n   *\n   * Example 2. Saving `model`'s topology and weights to browser\n   * [IndexedDB](https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API);\n   * then load it back.\n   *\n   * ```js\n   * const model = tf.sequential(\n   *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});\n   * console.log('Prediction from original model:');\n   * model.predict(tf.ones([1, 3])).print();\n   *\n   * const saveResults = await model.save('indexeddb://my-model-1');\n   *\n   * const loadedModel = await tf.loadLayersModel('indexeddb://my-model-1');\n   * console.log('Prediction from loaded model:');\n   * loadedModel.predict(tf.ones([1, 3])).print();\n   * ```\n   *\n   * Example 3. Saving `model`'s topology and weights as two files\n   * (`my-model-1.json` and `my-model-1.weights.bin`) downloaded from\n   * browser.\n   *\n   * ```js\n   * const model = tf.sequential(\n   *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});\n   * const saveResults = await model.save('downloads://my-model-1');\n   * ```\n   *\n   * Example 4. Send  `model`'s topology and weights to an HTTP server.\n   * See the documentation of `tf.io.http` for more details\n   * including specifying request parameters and implementation of the\n   * server.\n   *\n   * ```js\n   * const model = tf.sequential(\n   *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});\n   * const saveResults = await model.save('http://my-server/model/upload');\n   * ```\n   *\n   * @param handlerOrURL An instance of `IOHandler` or a URL-like,\n   * scheme-based string shortcut for `IOHandler`.\n   * @param config Options for saving the model.\n   * @returns A `Promise` of `SaveResult`, which summarizes the result of\n   * the saving, such as byte sizes of the saved artifacts for the model's\n   *   topology and weight values.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes', ignoreCI: true}\n   */\n\n\n  save(handlerOrURL, config) {\n    var _this6 = this;\n\n    return _asyncToGenerator(function* () {\n      if (typeof handlerOrURL === 'string') {\n        const handlers = io.getSaveHandlers(handlerOrURL);\n\n        if (handlers.length === 0) {\n          throw new ValueError(`Cannot find any save handlers for URL '${handlerOrURL}'`);\n        } else if (handlers.length > 1) {\n          throw new ValueError(`Found more than one (${handlers.length}) save handlers for ` + `URL '${handlerOrURL}'`);\n        }\n\n        handlerOrURL = handlers[0];\n      }\n\n      if (handlerOrURL.save == null) {\n        throw new ValueError('LayersModel.save() cannot proceed because the IOHandler ' + 'provided does not have the `save` attribute defined.');\n      }\n\n      const weightDataAndSpecs = yield io.encodeWeights(_this6.getNamedWeights(config));\n      const returnString = false;\n      const unusedArg = null;\n\n      const modelConfig = _this6.toJSON(unusedArg, returnString);\n\n      const modelArtifacts = {\n        modelTopology: modelConfig,\n        format: LAYERS_MODEL_FORMAT_NAME,\n        generatedBy: `TensorFlow.js tfjs-layers v${version}`,\n        convertedBy: null\n      };\n      const includeOptimizer = config == null ? false : config.includeOptimizer;\n\n      if (includeOptimizer && _this6.optimizer != null) {\n        modelArtifacts.trainingConfig = _this6.getTrainingConfig();\n        const weightType = 'optimizer';\n        const {\n          data: optimizerWeightData,\n          specs: optimizerWeightSpecs\n        } = yield io.encodeWeights(yield _this6.optimizer.getWeights(), weightType);\n        weightDataAndSpecs.specs.push(...optimizerWeightSpecs);\n        weightDataAndSpecs.data = io.concatenateArrayBuffers([weightDataAndSpecs.data, optimizerWeightData]);\n      }\n\n      if (_this6.userDefinedMetadata != null) {\n        // Check serialized size of user-defined metadata.\n        const checkSize = true;\n        checkUserDefinedMetadata(_this6.userDefinedMetadata, _this6.name, checkSize);\n        modelArtifacts.userDefinedMetadata = _this6.userDefinedMetadata;\n      }\n\n      modelArtifacts.weightData = weightDataAndSpecs.data;\n      modelArtifacts.weightSpecs = weightDataAndSpecs.specs;\n      return handlerOrURL.save(modelArtifacts);\n    })();\n  }\n  /**\n   * Set user-defined metadata.\n   *\n   * The set metadata will be serialized together with the topology\n   * and weights of the model during `save()` calls.\n   *\n   * @param setUserDefinedMetadata\n   */\n\n\n  setUserDefinedMetadata(userDefinedMetadata) {\n    checkUserDefinedMetadata(userDefinedMetadata, this.name);\n    this.userDefinedMetadata = userDefinedMetadata;\n  }\n  /**\n   * Get user-defined metadata.\n   *\n   * The metadata is supplied via one of the two routes:\n   *   1. By calling `setUserDefinedMetadata()`.\n   *   2. Loaded during model loading (if the model is constructed\n   *      via `tf.loadLayersModel()`.)\n   *\n   * If no user-defined metadata is available from either of the\n   * two routes, this function will return `undefined`.\n   */\n\n\n  getUserDefinedMetadata() {\n    return this.userDefinedMetadata;\n  }\n\n} // The class name is 'Model' rather than 'LayersModel' for backwards\n// compatibility since this class name shows up in the serialization format.\n\n/** @nocollapse */\n\nLayersModel.className = 'Model';\nserialization.registerClass(LayersModel);\n/**\n * A `tf.Functional` is an alias to `tf.LayersModel`.\n *\n * See also:\n *   `tf.LayersModel`, `tf.Sequential`, `tf.loadLayersModel`.\n */\n\n/** @doc {heading: 'Models', subheading: 'Classes'} */\n\nexport class Functional extends LayersModel {}\nFunctional.className = 'Functional';\nserialization.registerClass(Functional);","map":{"version":3,"sources":["/Users/ryanliang/Downloads/main_movir_picker/node_modules/@tensorflow/tfjs-layers/dist/engine/training.js"],"names":["tfc","io","Optimizer","scalar","serialization","Tensor","tensor1d","util","K","nameScope","NotImplementedError","RuntimeError","ValueError","deserialize","losses","Metrics","optimizers","checkUserDefinedMetadata","count","pyListRepeat","singletonOrArray","toCamelCase","toSnakeCase","unique","printSummary","range","convertPythonicToTs","version","Container","execute","FeedDict","evaluateDataset","fitDataset","checkBatchSize","disposeNewTensors","ensureTensorsRank2OrHigher","fitTensors","makeBatches","sliceArrays","sliceArraysByIndices","computeWeightedLoss","standardizeClassWeights","standardizeWeights","isDataTensor","x","isDataArray","Array","isArray","isDataDict","standardizeInputData","data","names","shapes","checkBatchAxis","exceptionPrefix","length","gotUnexpectedData","key","hasOwnProperty","map","name","arrays","push","shape","i","array","j","dim","refDim","checkArrayLengths","inputs","targets","weights","setX","input","sort","setY","target","JSON","stringify","arraysEqual","checkLossAndTargetCompatibility","lossFns","outputShapes","keyLosses","meanSquaredError","binaryCrossentropy","categoricalCrossentropy","y","loss","indexOf","slicedYShape","slice","slicedShape","targetDim","outDim","checkInputData","collectMetrics","metrics","outputNames","wrappedMetrics","TypeError","nestedMetrics","outputMetrics","LAYERS_MODEL_FORMAT_NAME","LayersModel","constructor","args","isTraining","summary","lineLength","positions","printFn","console","log","built","compile","optimizer","optimizer_","getOptimizer","isOptimizerOwned","lossFunctions","warn","get","outputs","theLosses","l","lossFunction","forEach","_","feedOutputNames","feedOutputShapes","feedLossFns","internalOutputShapes","skipTargetIndices","metricsNames","metricsTensors","weightedLoss","appendMetric","outputIndex","metricName","metricTensor","handleMetrics","metricNamePrefix","accFn","weightedMetricFn","metric","outputShape","binaryAccuracy","sparseCategoricalCrossentropy","sparseCategoricalAccuracy","categoricalAccuracy","suffix","metricFn","getLossOrMetricName","metricResult","collectedTrainableWeights","trainableWeights","checkTrainableWeightsConsistency","evaluate","batchSize","standardizedOuts","standardizeUserDataXY","ins","concat","makeTestFunction","f","testFunction","testOuts","testLoop","verbose","steps","dataset","checkNumSamples","stepsName","numSamples","outputsIsArray","outputSymbolicTensors","retrieveSymbolicTensors","feedDict","add","tensorValue","executeOutputs","symbolicTensorNames","outputsRemaining","layer","layers","layerOutputs","output","layerOutputNames","index","remainingNames","tensor","predictLoop","tidy","batches","outsBatches","batchIndex","batchOuts","batchStart","batchEnd","insBatch","feeds","value","batchOut","predict","xsRank2OrHigher","inputNames","feedInputShapes","predictOnBatch","lossFn","feedInputNames","stateful","standardizeUserData","sampleWeight","classWeight","standardXs","standardYs","Error","standardSampleWeights","classWeights","outs","indexArray","batchIds","sliceAlongFirstAxis","mul","div","getDedupedMetricsNames","outLabels","dedupedOutLabels","label","newLabel","dupIndex","makeTrainFunction","lossValues","sampleWeights","metricsValues","totalLossFunction","totalLoss","meanLoss","mean","weightedMetric","keep","calculateLosses","regularizerLoss","variables","param","read","returnCost","totalLossValue","minimize","valOutputs","meanMetric","fit","trainOnBatch","standardizeOut","trainFunction","v","dispose","getNamedWeights","config","namedWeights","trainableOnly","weightValues","getWeights","trainable","originalName","stopTraining","stop","stopTraining_","result","refCountAfterDispose","numTensorsBeforeOptmizerDisposal","memory","numTensors","numDisposedVariables","getLossIdentifiers","lossNames","Object","keys","outputName","getMetricIdentifiers","metricsIdentifiers","getTrainingConfig","optimizer_config","class_name","getClassName","getConfig","loadTrainingConfig","trainingConfig","weighted_metrics","loss_weights","sample_weight_mode","tsConfig","lossEntry","save","handlerOrURL","handlers","getSaveHandlers","weightDataAndSpecs","encodeWeights","returnString","unusedArg","modelConfig","toJSON","modelArtifacts","modelTopology","format","generatedBy","convertedBy","includeOptimizer","weightType","optimizerWeightData","specs","optimizerWeightSpecs","concatenateArrayBuffers","userDefinedMetadata","checkSize","weightData","weightSpecs","setUserDefinedMetadata","getUserDefinedMetadata","className","registerClass","Functional"],"mappings":";;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA;AACA,OAAO,KAAKA,GAAZ,MAAqB,uBAArB;AACA,SAASC,EAAT,EAAaC,SAAb,EAAwBC,MAAxB,EAAgCC,aAAhC,EAA+CC,MAA/C,EAAuDC,QAAvD,EAAiEC,IAAjE,QAA6E,uBAA7E;AACA,OAAO,KAAKC,CAAZ,MAAmB,yBAAnB;AACA,SAASC,SAAT,QAA0B,WAA1B;AACA,SAASC,mBAAT,EAA8BC,YAA9B,EAA4CC,UAA5C,QAA8D,WAA9D;AACA,SAASC,WAAT,QAA4B,yBAA5B;AACA,OAAO,KAAKC,MAAZ,MAAwB,WAAxB;AACA,OAAO,KAAKC,OAAZ,MAAyB,YAAzB;AACA,OAAO,KAAKC,UAAZ,MAA4B,eAA5B;AACA,SAASC,wBAAT,QAAyC,0BAAzC;AACA,SAASC,KAAT,EAAgBC,YAAhB,EAA8BC,gBAA9B,EAAgDC,WAAhD,EAA6DC,WAA7D,EAA0EC,MAA1E,QAAwF,wBAAxF;AACA,SAASC,YAAT,QAA6B,sBAA7B;AACA,SAASC,KAAT,QAAsB,qBAAtB;AACA,SAASC,mBAAT,QAAoC,8BAApC;AACA,SAASC,OAAT,QAAwB,YAAxB;AACA,SAASC,SAAT,QAA0B,aAA1B;AACA,SAASC,OAAT,EAAkBC,QAAlB,QAAkC,YAAlC;AACA,SAASC,eAAT,EAA0BC,UAA1B,QAA4C,oBAA5C;AACA,SAASC,cAAT,EAAyBC,iBAAzB,EAA4CC,0BAA5C,EAAwEC,UAAxE,EAAoFC,WAApF,EAAiGC,WAAjG,EAA8GC,oBAA9G,QAA0I,oBAA1I;AACA,SAASC,mBAAT,EAA8BC,uBAA9B,EAAuDC,kBAAvD,QAAiF,kBAAjF;AACA;AACA;AACA;;AACA,OAAO,SAASC,YAAT,CAAsBC,CAAtB,EAAyB;AAC5B,SAAOA,CAAC,YAAYvC,MAApB;AACH;AACD;AACA;AACA;;AACA,OAAO,SAASwC,WAAT,CAAqBD,CAArB,EAAwB;AAC3B,SAAOE,KAAK,CAACC,OAAN,CAAcH,CAAd,CAAP;AACH;AACD;AACA;AACA;;AACA,OAAO,SAASI,UAAT,CAAoBJ,CAApB,EAAuB;AAC1B,SAAO,CAACD,YAAY,CAACC,CAAD,CAAb,IAAoB,CAACC,WAAW,CAACD,CAAD,CAAvC;AACH;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASK,oBAAT,CAA8BC,IAA9B,EAAoCC,KAApC,EAA2CC,MAA3C,EAAmDC,cAAc,GAAG,IAApE,EAA0EC,eAAe,GAAG,EAA5F,EAAgG;AACnG,MAAIH,KAAK,IAAI,IAAT,IAAiBA,KAAK,CAACI,MAAN,KAAiB,CAAtC,EAAyC;AACrC;AACA;AACA,QAAIL,IAAI,IAAI,IAAZ,EAAkB;AACd,UAAIM,iBAAiB,GAAG,KAAxB;;AACA,UAAIX,WAAW,CAACK,IAAD,CAAX,IAAqBA,IAAI,CAACK,MAAL,GAAc,CAAvC,EAA0C;AACtCC,QAAAA,iBAAiB,GAAG,IAApB;AACH,OAFD,MAGK,IAAIR,UAAU,CAACE,IAAD,CAAd,EAAsB;AACvB,aAAK,MAAMO,GAAX,IAAkBP,IAAlB,EAAwB;AACpB,cAAIA,IAAI,CAACQ,cAAL,CAAoBD,GAApB,CAAJ,EAA8B;AAC1BD,YAAAA,iBAAiB,GAAG,IAApB;AACA;AACH;AACJ;AACJ,OAPI,MAQA;AACD;AACAA,QAAAA,iBAAiB,GAAG,IAApB;AACH;;AACD,UAAIA,iBAAJ,EAAuB;AACnB,cAAM,IAAI5C,UAAJ,CAAgB,6BAA4B0C,eAAgB,qBAA7C,GAChB,WAAUJ,IAAK,EADd,CAAN;AAEH;AACJ;;AACD,WAAO,EAAP;AACH;;AACD,MAAIA,IAAI,IAAI,IAAZ,EAAkB;AACd,WAAOC,KAAK,CAACQ,GAAN,CAAUC,IAAI,IAAI,IAAlB,CAAP;AACH;;AACD,MAAIC,MAAJ;;AACA,MAAIb,UAAU,CAACE,IAAD,CAAd,EAAsB;AAClBA,IAAAA,IAAI,GAAGA,IAAP;AACAW,IAAAA,MAAM,GAAG,EAAT;;AACA,SAAK,MAAMD,IAAX,IAAmBT,KAAnB,EAA0B;AACtB,UAAID,IAAI,CAACU,IAAD,CAAJ,IAAc,IAAlB,EAAwB;AACpB,cAAM,IAAIhD,UAAJ,CAAgB,yBAAwBgD,IAAK,gCAA9B,GAChB,GAAET,KAAM,EADP,CAAN;AAEH;;AACDU,MAAAA,MAAM,CAACC,IAAP,CAAYZ,IAAI,CAACU,IAAD,CAAhB;AACH;AACJ,GAVD,MAWK,IAAIf,WAAW,CAACK,IAAD,CAAf,EAAuB;AACxBA,IAAAA,IAAI,GAAGA,IAAP;;AACA,QAAIA,IAAI,CAACK,MAAL,KAAgBJ,KAAK,CAACI,MAA1B,EAAkC;AAC9B,YAAM,IAAI3C,UAAJ,CAAgB,6BAA4B0C,eAAgB,iBAA7C,GAChB,iEADgB,GAEhB,mCAAkCH,KAAK,CAACI,MAAO,kBAF/B,GAGhB,gDAA+CL,IAAK,EAHnD,CAAN;AAIH;;AACDW,IAAAA,MAAM,GAAGX,IAAT;AACH,GATI,MAUA;AACDA,IAAAA,IAAI,GAAGA,IAAP;;AACA,QAAIC,KAAK,CAACI,MAAN,GAAe,CAAnB,EAAsB;AAClB,YAAM,IAAI3C,UAAJ,CAAgB,aAAY0C,eAAgB,YAAWH,KAAK,CAACI,MAAO,cAArD,GAChB,0DAAyDL,IAAI,CAACa,KAAM,EADnE,CAAN;AAEH;;AACDF,IAAAA,MAAM,GAAG,CAACX,IAAD,CAAT;AACH;;AACDW,EAAAA,MAAM,GAAG1B,0BAA0B,CAAC0B,MAAD,CAAnC,CA7DmG,CA8DnG;;AACA,MAAIT,MAAM,IAAI,IAAd,EAAoB;AAChB,SAAK,IAAIY,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGb,KAAK,CAACI,MAA1B,EAAkC,EAAES,CAApC,EAAuC;AACnC,UAAIZ,MAAM,CAACY,CAAD,CAAN,IAAa,IAAjB,EAAuB;AACnB;AACH;;AACD,YAAMC,KAAK,GAAGJ,MAAM,CAACG,CAAD,CAApB;;AACA,UAAIC,KAAK,CAACF,KAAN,CAAYR,MAAZ,KAAuBH,MAAM,CAACY,CAAD,CAAN,CAAUT,MAArC,EAA6C;AACzC,cAAM,IAAI3C,UAAJ,CAAgB,uBAAsB0C,eAAgB,cAAaH,KAAK,CAACa,CAAD,CAAI,GAA7D,GAChB,WAAUZ,MAAM,CAACY,CAAD,CAAN,CAAUT,MAAO,oCADX,GAEhB,SAAQU,KAAK,CAACF,KAAM,EAFnB,CAAN;AAGH;;AACD,WAAK,IAAIG,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGd,MAAM,CAACY,CAAD,CAAN,CAAUT,MAA9B,EAAsC,EAAEW,CAAxC,EAA2C;AACvC,YAAIA,CAAC,KAAK,CAAN,IAAW,CAACb,cAAhB,EAAgC;AAC5B;AACA;AACH;;AACD,cAAMc,GAAG,GAAGF,KAAK,CAACF,KAAN,CAAYG,CAAZ,CAAZ;AACA,cAAME,MAAM,GAAGhB,MAAM,CAACY,CAAD,CAAN,CAAUE,CAAV,CAAf;;AACA,YAAIE,MAAM,IAAI,IAAV,IAAkBA,MAAM,IAAI,CAA5B,IAAiCD,GAAG,KAAKC,MAA7C,EAAqD;AACjD,gBAAM,IAAIxD,UAAJ,CAAgB,uBAAsB0C,eAAgB,cAAaH,KAAK,CAACa,CAAD,CAAI,GAA7D,GAChB,kBAAiBZ,MAAM,CAACY,CAAD,CAAI,8BADX,GAEhB,IAAGC,KAAK,CAACF,KAAM,IAFd,CAAN;AAGH;AACJ;AACJ;AACJ;;AACD,SAAOF,MAAP;AACH;AACD;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASQ,iBAAT,CAA2BC,MAA3B,EAAmCC,OAAnC,EAA4CC,OAA5C,EAAqD;AACxD,QAAMC,IAAI,GAAGlD,MAAM,CAAC+C,MAAM,CAACX,GAAP,CAAWe,KAAK,IAAIA,KAAK,CAACX,KAAN,CAAY,CAAZ,CAApB,CAAD,CAAnB;AACAU,EAAAA,IAAI,CAACE,IAAL;AACA,QAAMC,IAAI,GAAGrD,MAAM,CAACgD,OAAO,CAACZ,GAAR,CAAYkB,MAAM,IAAIA,MAAM,CAACd,KAAP,CAAa,CAAb,CAAtB,CAAD,CAAnB;AACAa,EAAAA,IAAI,CAACD,IAAL,GAJwD,CAKxD;;AACA,MAAIF,IAAI,CAAClB,MAAL,GAAc,CAAlB,EAAqB;AACjB,UAAM,IAAI3C,UAAJ,CAAgB,gEAAD,GAChB,oBADgB,GAEhB,GAAEkE,IAAI,CAACC,SAAL,CAAeT,MAAM,CAACX,GAAP,CAAWe,KAAK,IAAIA,KAAK,CAACX,KAA1B,CAAf,CAAiD,EAFlD,CAAN;AAGH;;AACD,MAAIa,IAAI,CAACrB,MAAL,GAAc,CAAlB,EAAqB;AACjB,UAAM,IAAI3C,UAAJ,CAAgB,iEAAD,GAChB,oBADgB,GAEhB,GAAEkE,IAAI,CAACC,SAAL,CAAeR,OAAO,CAACZ,GAAR,CAAYkB,MAAM,IAAIA,MAAM,CAACd,KAA7B,CAAf,CAAoD,EAFrD,CAAN;AAGH;;AACD,MAAIU,IAAI,CAAClB,MAAL,GAAc,CAAd,IAAmBqB,IAAI,CAACrB,MAAL,GAAc,CAAjC,IAAsC,CAAChD,IAAI,CAACyE,WAAL,CAAiBP,IAAjB,EAAuBG,IAAvB,CAA3C,EAAyE;AACrE,UAAM,IAAIhE,UAAJ,CAAgB,iEAAD,GAChB,kBAAiB6D,IAAI,CAAC,CAAD,CAAI,wBAAuBG,IAAI,CAAC,CAAD,CAAI,UADxC,GAEhB,YAFC,CAAN;AAGH;AACJ;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,SAASK,+BAAT,CAAyCV,OAAzC,EAAkDW,OAAlD,EAA2DC,YAA3D,EAAyE;AACrE;AACA,QAAMC,SAAS,GAAG,CACdtE,MAAM,CAACuE,gBADO,EACWvE,MAAM,CAACwE,kBADlB,EAEdxE,MAAM,CAACyE,uBAFO,CAAlB;;AAIA,OAAK,IAAIvB,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGO,OAAO,CAAChB,MAA5B,EAAoC,EAAES,CAAtC,EAAyC;AACrC,UAAMwB,CAAC,GAAGjB,OAAO,CAACP,CAAD,CAAjB;AACA,UAAMyB,IAAI,GAAGP,OAAO,CAAClB,CAAD,CAApB;AACA,UAAMD,KAAK,GAAGoB,YAAY,CAACnB,CAAD,CAA1B;;AACA,QAAIyB,IAAI,IAAI,IAAZ,EAAkB;AACd;AACH;;AACD,QAAIA,IAAI,KAAK3E,MAAM,CAACyE,uBAApB,EAA6C;AACzC,UAAIC,CAAC,CAACzB,KAAF,CAAQyB,CAAC,CAACzB,KAAF,CAAQR,MAAR,GAAiB,CAAzB,MAAgC,CAApC,EAAuC;AACnC,cAAM,IAAI3C,UAAJ,CAAgB,2CAA0C4E,CAAC,CAACzB,KAAM,eAAnD,GAChB,+DADgB,GAEhB,6DAFgB,GAGhB,qBAHC,CAAN,CADmC,CAKnC;AACH;AACJ;;AACD,QAAIqB,SAAS,CAACM,OAAV,CAAkBD,IAAlB,MAA4B,CAAC,CAAjC,EAAoC;AAChC,YAAME,YAAY,GAAGH,CAAC,CAACzB,KAAF,CAAQ6B,KAAR,CAAc,CAAd,CAArB;AACA,YAAMC,WAAW,GAAG9B,KAAK,CAAC6B,KAAN,CAAY,CAAZ,CAApB;;AACA,WAAK,IAAI1B,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGyB,YAAY,CAACpC,MAAjC,EAAyC,EAAEW,CAA3C,EAA8C;AAC1C,cAAM4B,SAAS,GAAGH,YAAY,CAACzB,CAAD,CAA9B;AACA,cAAM6B,MAAM,GAAGF,WAAW,CAAC3B,CAAD,CAA1B;;AACA,YAAI6B,MAAM,IAAI,IAAV,IAAkBD,SAAS,KAAKC,MAApC,EAA4C;AACxC,gBAAM,IAAInF,UAAJ,CAAgB,8BAA6B4E,CAAC,CAACzB,KAAM,qBAAtC,GAChB,mBAAkBA,KAAM,qCADR,GAEhB,uDAFC,CAAN;AAGH;AACJ;AACJ;AACJ;AACJ;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,SAASiC,cAAT,CAAwB9C,IAAxB,EAA8BC,KAA9B,EAAqCC,MAArC,EAA6CC,cAAc,GAAG,IAA9D,EAAoEC,eAAe,GAAG,EAAtF,EAA0F;AACtF,MAAIO,MAAJ;;AACA,MAAIf,KAAK,CAACC,OAAN,CAAcG,IAAd,CAAJ,EAAyB;AACrB,QAAIA,IAAI,CAACK,MAAL,KAAgBJ,KAAK,CAACI,MAA1B,EAAkC;AAC9B,YAAM,IAAI3C,UAAJ,CAAgB,6BAA4B0C,eAAgB,iBAA7C,GAChB,iEADgB,GAEhB,uCAAsCH,KAAK,CAACI,MAAO,aAFnC,GAGhB,oBAAmBL,IAAI,CAACK,MAAO,cAH9B,CAAN;AAIH;;AACDM,IAAAA,MAAM,GAAGX,IAAT;AACH,GARD,MASK;AACD,QAAIC,KAAK,CAACI,MAAN,GAAe,CAAnB,EAAsB;AAClB,YAAM,IAAI3C,UAAJ,CAAgB,qBAAoBuC,KAAK,CAACI,MAAO,IAAGD,eAAgB,YAArD,GAChB,wDADgB,GAEhB,GAAEwB,IAAI,CAACC,SAAL,CAAe7B,IAAI,CAACa,KAApB,CAA2B,GAF5B,CAAN;AAGH;;AACDF,IAAAA,MAAM,GAAG,CAACX,IAAD,CAAT;AACH;;AACD,MAAIE,MAAM,IAAI,IAAd,EAAoB;AAChB,SAAK,IAAIY,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGb,KAAK,CAACI,MAA1B,EAAkC,EAAES,CAApC,EAAuC;AACnC,UAAIZ,MAAM,CAACY,CAAD,CAAN,IAAa,IAAjB,EAAuB;AACnB;AACH;;AACD,YAAMC,KAAK,GAAGJ,MAAM,CAACG,CAAD,CAApB;;AACA,UAAIC,KAAK,CAACF,KAAN,CAAYR,MAAZ,KAAuBH,MAAM,CAACY,CAAD,CAAN,CAAUT,MAArC,EAA6C;AACzC,cAAM,IAAI3C,UAAJ,CAAgB,uBAAsB0C,eAAgB,cAAaH,KAAK,CAACa,CAAD,CAAI,GAA7D,GAChB,WAAUZ,MAAM,CAACY,CAAD,CAAN,CAAUT,MAAO,oCADX,GAEhB,SAAQuB,IAAI,CAACC,SAAL,CAAed,KAAK,CAACF,KAArB,CAA4B,EAFnC,CAAN;AAGH;;AACD,WAAK,IAAIG,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGd,MAAM,CAACY,CAAD,CAAN,CAAUT,MAA9B,EAAsC,EAAEW,CAAxC,EAA2C;AACvC,YAAIA,CAAC,KAAK,CAAN,IAAW,CAACb,cAAhB,EAAgC;AAC5B;AACH;;AACD,cAAMc,GAAG,GAAGF,KAAK,CAACF,KAAN,CAAYG,CAAZ,CAAZ;AACA,cAAME,MAAM,GAAGhB,MAAM,CAACY,CAAD,CAAN,CAAUE,CAAV,CAAf;;AACA,YAAIE,MAAM,IAAI,IAAd,EAAoB;AAChB,cAAIA,MAAM,KAAKD,GAAf,EAAoB;AAChB,kBAAM,IAAIvD,UAAJ,CAAgB,uBAAsB0C,eAAgB,aAAvC,GAChB,GAAEH,KAAK,CAACa,CAAD,CAAI,kBAAiBc,IAAI,CAACC,SAAL,CAAe3B,MAAM,CAACY,CAAD,CAArB,CAA0B,OADtC,GAEhB,wBAAuBc,IAAI,CAACC,SAAL,CAAed,KAAK,CAACF,KAArB,CAA4B,GAFlD,CAAN;AAGH;AACJ;AACJ;AACJ;AACJ;AACJ;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,OAAO,SAASkC,cAAT,CAAwBC,OAAxB,EAAiCC,WAAjC,EAA8C;AACjD,MAAID,OAAO,IAAI,IAAX,IAAmBpD,KAAK,CAACC,OAAN,CAAcmD,OAAd,KAA0BA,OAAO,CAAC3C,MAAR,KAAmB,CAApE,EAAuE;AACnE,WAAO4C,WAAW,CAACxC,GAAZ,CAAgBC,IAAI,IAAI,EAAxB,CAAP;AACH;;AACD,MAAIwC,cAAJ;;AACA,MAAI,OAAOF,OAAP,KAAmB,QAAnB,IAA+B,OAAOA,OAAP,KAAmB,UAAtD,EAAkE;AAC9DE,IAAAA,cAAc,GAAG,CAACF,OAAD,CAAjB;AACH,GAFD,MAGK,IAAIpD,KAAK,CAACC,OAAN,CAAcmD,OAAd,KAA0B,OAAOA,OAAP,KAAmB,QAAjD,EAA2D;AAC5DE,IAAAA,cAAc,GAAGF,OAAjB;AACH,GAFI,MAGA;AACD,UAAM,IAAIG,SAAJ,CAAc,iEACf,sCAAqCH,OAAQ,EAD5C,CAAN;AAEH;;AACD,MAAIpD,KAAK,CAACC,OAAN,CAAcqD,cAAd,CAAJ,EAAmC;AAC/B;AACA,WAAOD,WAAW,CAACxC,GAAZ,CAAgBC,IAAI,IAAIwC,cAAxB,CAAP;AACH,GAHD,MAIK;AACD;AACA,UAAME,aAAa,GAAG,EAAtB;;AACA,SAAK,MAAM1C,IAAX,IAAmBuC,WAAnB,EAAgC;AAC5B,UAAII,aAAa,GAAGH,cAAc,CAAC1C,cAAf,CAA8BE,IAA9B,IAAsCwC,cAAc,CAACxC,IAAD,CAApD,GAA6D,EAAjF;;AACA,UAAI,CAACd,KAAK,CAACC,OAAN,CAAcwD,aAAd,CAAL,EAAmC;AAC/BA,QAAAA,aAAa,GAAG,CAACA,aAAD,CAAhB;AACH;;AACDD,MAAAA,aAAa,CAACxC,IAAd,CAAmByC,aAAnB;AACH;;AACD,WAAOD,aAAP;AACH;AACJ;AACD,MAAME,wBAAwB,GAAG,cAAjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,MAAMC,WAAN,SAA0B7E,SAA1B,CAAoC;AACvC8E,EAAAA,WAAW,CAACC,IAAD,EAAO;AACd,UAAMA,IAAN;AACA,SAAKC,UAAL,GAAkB,KAAlB;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACIC,EAAAA,OAAO,CAACC,UAAD,EAAaC,SAAb,EAAwBC,OAAO,GAAGC,OAAO,CAACC,GAA1C,EAA+C;AAClD,QAAI,CAAC,KAAKC,KAAV,EAAiB;AACb,YAAM,IAAIvG,UAAJ,CAAgB,mEAAD,GAChB,+DADgB,GAEhB,gDAFC,CAAN;AAGH;;AACDY,IAAAA,YAAY,CAAC,IAAD,EAAOsF,UAAP,EAAmBC,SAAnB,EAA8BC,OAA9B,CAAZ;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACII,EAAAA,OAAO,CAACT,IAAD,EAAO;AACV,QAAIA,IAAI,CAAClB,IAAL,IAAa,IAAjB,EAAuB;AACnBkB,MAAAA,IAAI,CAAClB,IAAL,GAAY,EAAZ;AACH;;AACD,SAAKA,IAAL,GAAYkB,IAAI,CAAClB,IAAjB;;AACA,QAAI,OAAOkB,IAAI,CAACU,SAAZ,KAA0B,QAA9B,EAAwC;AACpC,WAAKC,UAAL,GAAkBtG,UAAU,CAACuG,YAAX,CAAwBZ,IAAI,CAACU,SAA7B,CAAlB;AACA,WAAKG,gBAAL,GAAwB,IAAxB;AACH,KAHD,MAIK;AACD,UAAI,EAAEb,IAAI,CAACU,SAAL,YAA0BnH,SAA5B,CAAJ,EAA4C;AACxC,cAAM,IAAIU,UAAJ,CAAgB,6DAAhB,CAAN;AACH;;AACD,WAAK0G,UAAL,GAAkBX,IAAI,CAACU,SAAvB;AACA,WAAKG,gBAAL,GAAwB,KAAxB;AACH,KAfS,CAgBV;AACA;AACA;;;AACA,QAAIC,aAAa,GAAG,EAApB;;AACA,QAAI,CAAC3E,KAAK,CAACC,OAAN,CAAc4D,IAAI,CAAClB,IAAnB,CAAD,IAA6B,OAAOkB,IAAI,CAAClB,IAAZ,KAAqB,QAAlD,IACA,OAAOkB,IAAI,CAAClB,IAAZ,KAAqB,UADzB,EACqC;AACjCkB,MAAAA,IAAI,CAAClB,IAAL,GAAYkB,IAAI,CAAClB,IAAjB;;AACA,WAAK,MAAM7B,IAAX,IAAmB+C,IAAI,CAAClB,IAAxB,EAA8B;AAC1B,YAAI,KAAKU,WAAL,CAAiBT,OAAjB,CAAyB9B,IAAzB,MAAmC,CAAC,CAAxC,EAA2C;AACvC,gBAAM,IAAIhD,UAAJ,CAAgB,sCAAqCgD,IAAK,KAA3C,GAChB,qCAAoC,KAAKuC,WAAY,EADpD,CAAN;AAEH;AACJ;;AACD,WAAK,MAAMvC,IAAX,IAAmB,KAAKuC,WAAxB,EAAqC;AACjC,YAAIQ,IAAI,CAAClB,IAAL,CAAU7B,IAAV,KAAmB,IAAvB,EAA6B;AACzBqD,UAAAA,OAAO,CAACS,IAAR,CAAc,WAAU9D,IAAK,+CAAhB,GACR,8DADQ,GAER,mBAAkBA,IAAK,kBAF5B;AAGH;;AACD6D,QAAAA,aAAa,CAAC3D,IAAd,CAAmBhD,MAAM,CAAC6G,GAAP,CAAWhB,IAAI,CAAClB,IAAL,CAAU7B,IAAV,CAAX,CAAnB;AACH;AACJ,KAjBD,MAkBK,IAAId,KAAK,CAACC,OAAN,CAAc4D,IAAI,CAAClB,IAAnB,CAAJ,EAA8B;AAC/B,UAAIkB,IAAI,CAAClB,IAAL,CAAUlC,MAAV,KAAqB,KAAKqE,OAAL,CAAarE,MAAtC,EAA8C;AAC1C,cAAM,IAAI3C,UAAJ,CAAgB,8DAAD,GAChB,+BAA8B,KAAKgH,OAAL,CAAarE,MAAO,cADlC,GAEhB,uBAAsBoD,IAAI,CAAClB,IAAK,GAF/B,CAAN;AAGH;;AACD,YAAMoC,SAAS,GAAGlB,IAAI,CAAClB,IAAvB;AACAgC,MAAAA,aAAa,GAAGI,SAAS,CAAClE,GAAV,CAAcmE,CAAC,IAAIhH,MAAM,CAAC6G,GAAP,CAAWG,CAAX,CAAnB,CAAhB;AACH,KARI,MASA;AACD,YAAMC,YAAY,GAAGjH,MAAM,CAAC6G,GAAP,CAAWhB,IAAI,CAAClB,IAAhB,CAArB;AACA,WAAKmC,OAAL,CAAaI,OAAb,CAAqBC,CAAC,IAAI;AACtBR,QAAAA,aAAa,CAAC3D,IAAd,CAAmBiE,YAAnB;AACH,OAFD;AAGH;;AACD,SAAKN,aAAL,GAAqBA,aAArB;AACA,SAAKS,eAAL,GAAuB,EAAvB;AACA,SAAKC,gBAAL,GAAwB,EAAxB;AACA,SAAKC,WAAL,GAAmB,EAAnB;;AACA,SAAK,IAAIpE,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG,KAAK4D,OAAL,CAAarE,MAAjC,EAAyC,EAAES,CAA3C,EAA8C;AAC1C;AACA,YAAMD,KAAK,GAAG,KAAKsE,oBAAL,CAA0BrE,CAA1B,CAAd;AACA,YAAMJ,IAAI,GAAG,KAAKuC,WAAL,CAAiBnC,CAAjB,CAAb;AACA,WAAKkE,eAAL,CAAqBpE,IAArB,CAA0BF,IAA1B;AACA,WAAKuE,gBAAL,CAAsBrE,IAAtB,CAA2BC,KAA3B;AACA,WAAKqE,WAAL,CAAiBtE,IAAjB,CAAsB,KAAK2D,aAAL,CAAmBzD,CAAnB,CAAtB;AACH,KAhES,CAiEV;AACA;;;AACA,UAAMsE,iBAAiB,GAAG,EAA1B,CAnEU,CAoEV;;AACA,SAAKpC,OAAL,GAAeS,IAAI,CAACT,OAApB,CArEU,CAsEV;;AACA,SAAKqC,YAAL,GAAoB,CAAC,MAAD,CAApB;AACA,SAAKC,cAAL,GAAsB,EAAtB,CAxEU,CAyEV;AACA;AACA;AACA;;AACA/H,IAAAA,SAAS,CAAC,MAAD,EAAS,MAAM;AACpB,WAAK,IAAIuD,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG,KAAK4D,OAAL,CAAarE,MAAjC,EAAyC,EAAES,CAA3C,EAA8C;AAC1C,YAAIsE,iBAAiB,CAAC5C,OAAlB,CAA0B1B,CAA1B,MAAiC,CAAC,CAAtC,EAAyC;AACrC;AACH,SAHyC,CAI1C;AACA;;;AACA,cAAMyE,YAAY,GAAG,KAAKhB,aAAL,CAAmBzD,CAAnB,CAArB;;AACA,YAAI,KAAK4D,OAAL,CAAarE,MAAb,GAAsB,CAA1B,EAA6B;AACzB,eAAKiF,cAAL,CAAoB1E,IAApB,CAAyB,CAAC2E,YAAD,EAAezE,CAAf,CAAzB;AACA,eAAKuE,YAAL,CAAkBzE,IAAlB,CAAuB,KAAKqC,WAAL,CAAiBnC,CAAjB,IAAsB,OAA7C;AACH;AACJ,OAZmB,CAapB;AACA;;AACH,KAfQ,CAAT;AAgBA,UAAMsC,aAAa,GAAGL,cAAc,CAACU,IAAI,CAACT,OAAN,EAAe,KAAKC,WAApB,CAApC,CA7FU,CA8FV;;AACA;AACR;AACA;;AACQ,UAAMuC,YAAY,GAAG,CAACC,WAAD,EAAcC,UAAd,EAA0BC,YAA1B,KAA2C;AAC5D,UAAI,KAAK1C,WAAL,CAAiB5C,MAAjB,GAA0B,CAA9B,EAAiC;AAC7BqF,QAAAA,UAAU,GAAG,KAAKzC,WAAL,CAAiBwC,WAAjB,IAAgC,GAAhC,GAAsCC,UAAnD;AACH;;AACD,WAAKL,YAAL,CAAkBzE,IAAlB,CAAuB8E,UAAvB;AACA,WAAKJ,cAAL,CAAoB1E,IAApB,CAAyB,CAAC+E,YAAD,EAAeF,WAAf,CAAzB;AACH,KAND;;AAOAlI,IAAAA,SAAS,CAAC,QAAD,EAAW,MAAM;AACtB,WAAK,IAAIuD,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG,KAAK4D,OAAL,CAAarE,MAAjC,EAAyC,EAAES,CAA3C,EAA8C;AAC1C,YAAIsE,iBAAiB,CAAC5C,OAAlB,CAA0B1B,CAA1B,MAAiC,CAAC,CAAtC,EAAyC;AACrC;AACH;;AACD,cAAMuC,aAAa,GAAGD,aAAa,CAACtC,CAAD,CAAnC,CAJ0C,CAK1C;AACA;;AACA,cAAM8E,aAAa,GAAI5C,OAAD,IAAa;AAC/B,gBAAM6C,gBAAgB,GAAG,EAAzB;AACA,cAAIH,UAAJ;AACA,cAAII,KAAJ;AACA,cAAIC,gBAAJ,CAJ+B,CAK/B;;AACA,eAAK,MAAMC,MAAX,IAAqBhD,OAArB,EAA8B;AAC1B,gBAAI,OAAOgD,MAAP,KAAkB,QAAlB,IACA,CAAC,UAAD,EAAa,KAAb,EAAoB,cAApB,EAAoC,IAApC,EAA0CxD,OAA1C,CAAkDwD,MAAlD,MACI,CAAC,CAFT,EAEY;AACR,oBAAMC,WAAW,GAAG,KAAKd,oBAAL,CAA0BrE,CAA1B,CAApB;;AACA,kBAAImF,WAAW,CAACA,WAAW,CAAC5F,MAAZ,GAAqB,CAAtB,CAAX,KAAwC,CAAxC,IACA,KAAKkE,aAAL,CAAmBzD,CAAnB,MAA0BlD,MAAM,CAACwE,kBADrC,EACyD;AACrD;AACA,oBAAI,CAAC,UAAD,EAAa,KAAb,EAAoBI,OAApB,CAA4BwD,MAA5B,MAAwC,CAAC,CAA7C,EAAgD;AAC5CF,kBAAAA,KAAK,GAAGjI,OAAO,CAACqI,cAAhB;AACH,iBAFD,MAGK,IAAI,CAAC,cAAD,EAAiB,IAAjB,EAAuB1D,OAAvB,CAA+BwD,MAA/B,MAA2C,CAAC,CAAhD,EAAmD;AACpDF,kBAAAA,KAAK,GAAGjI,OAAO,CAACuE,kBAAhB;AACH;AACJ,eATD,MAUK,IAAI,KAAKmC,aAAL,CAAmBzD,CAAnB,MACLlD,MAAM,CAACuI,6BADN,EACqC;AACtC;AACA;AACA,oBAAI,CAAC,UAAD,EAAa,KAAb,EAAoB3D,OAApB,CAA4BwD,MAA5B,MAAwC,CAAC,CAA7C,EAAgD;AAC5CF,kBAAAA,KAAK,GAAGjI,OAAO,CAACuI,yBAAhB;AACH,iBAFD,MAGK,IAAI,CAAC,cAAD,EAAiB,IAAjB,EAAuB5D,OAAvB,CAA+BwD,MAA/B,MAA2C,CAAC,CAAhD,EAAmD;AACpDF,kBAAAA,KAAK,GAAGjI,OAAO,CAACsI,6BAAhB;AACH;AACJ,eAVI,MAWA;AACD;AACA,oBAAI,CAAC,UAAD,EAAa,KAAb,EAAoB3D,OAApB,CAA4BwD,MAA5B,MAAwC,CAAC,CAA7C,EAAgD;AAC5CF,kBAAAA,KAAK,GAAGjI,OAAO,CAACwI,mBAAhB;AACH,iBAFD,MAGK,IAAI,CAAC,cAAD,EAAiB,IAAjB,EAAuB7D,OAAvB,CAA+BwD,MAA/B,MAA2C,CAAC,CAAhD,EAAmD;AACpDF,kBAAAA,KAAK,GAAGjI,OAAO,CAACwE,uBAAhB;AACH;AACJ;;AACD,kBAAIiE,MAAJ;;AACA,kBAAI,CAAC,UAAD,EAAa,KAAb,EAAoB9D,OAApB,CAA4BwD,MAA5B,MAAwC,CAAC,CAA7C,EAAgD;AAC5CM,gBAAAA,MAAM,GAAG,KAAT;AACH,eAFD,MAGK,IAAI,CAAC,cAAD,EAAiB,IAAjB,EAAuB9D,OAAvB,CAA+BwD,MAA/B,MAA2C,CAAC,CAAhD,EAAmD;AACpDM,gBAAAA,MAAM,GAAG,IAAT;AACH,eAtCO,CAuCR;;;AACAP,cAAAA,gBAAgB,GAAGD,KAAnB;AACAJ,cAAAA,UAAU,GAAGG,gBAAgB,GAAGS,MAAhC;AACH,aA5CD,MA6CK;AACD,oBAAMC,QAAQ,GAAG1I,OAAO,CAAC4G,GAAR,CAAYuB,MAAZ,CAAjB,CADC,CAED;;AACAD,cAAAA,gBAAgB,GAAGQ,QAAnB;AACAb,cAAAA,UAAU,GACNG,gBAAgB,GAAGhI,OAAO,CAAC2I,mBAAR,CAA4BR,MAA5B,CADvB;AAEH,aApDyB,CAqD1B;;;AACA,gBAAIS,YAAJ;AACAlJ,YAAAA,SAAS,CAACmI,UAAD,EAAa,MAAM;AACxBe,cAAAA,YAAY,GAAGV,gBAAf;AACH,aAFQ,CAAT;AAGAP,YAAAA,YAAY,CAAC1E,CAAD,EAAI4E,UAAJ,EAAgBe,YAAhB,CAAZ;AACH;AACJ,SAlED;;AAmEAb,QAAAA,aAAa,CAACvC,aAAD,CAAb,CA1E0C,CA2E1C;AACH;AACJ,KA9EQ,CAAT,CAzGU,CAwLV;AACA;;AACA,SAAKqD,yBAAL,GAAiC,KAAKC,gBAAtC;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACIC,EAAAA,gCAAgC,GAAG;AAC/B,QAAI,KAAKF,yBAAL,IAAkC,IAAtC,EAA4C;AACxC;AACH;;AACD,QAAI,KAAKC,gBAAL,CAAsBtG,MAAtB,KACA,KAAKqG,yBAAL,CAA+BrG,MADnC,EAC2C;AACvC0D,MAAAA,OAAO,CAACS,IAAR,CAAa,kEACT,yDADS,GAET,+BAFJ;AAGH;AACJ;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACIqC,EAAAA,QAAQ,CAACnH,CAAD,EAAI4C,CAAJ,EAAOmB,IAAI,GAAG,EAAd,EAAkB;AACtB,UAAMqD,SAAS,GAAGrD,IAAI,CAACqD,SAAL,IAAkB,IAAlB,GAAyB,EAAzB,GAA8BrD,IAAI,CAACqD,SAArD;AACA/H,IAAAA,cAAc,CAAC+H,SAAD,CAAd,CAFsB,CAGtB;AACA;;AACA,UAAM3G,cAAc,GAAG,IAAvB;AACA,UAAM4G,gBAAgB,GAAG,KAAKC,qBAAL,CAA2BtH,CAA3B,EAA8B4C,CAA9B,EAAiCnC,cAAjC,EAAiD2G,SAAjD,CAAzB;;AACA,QAAI;AACA;AACA;AACA,YAAMG,GAAG,GAAGF,gBAAgB,CAAC,CAAD,CAAhB,CAAoBG,MAApB,CAA2BH,gBAAgB,CAAC,CAAD,CAA3C,CAAZ;AACA,WAAKI,gBAAL;AACA,YAAMC,CAAC,GAAG,KAAKC,YAAf;AACA,YAAMC,QAAQ,GAAG,KAAKC,QAAL,CAAcH,CAAd,EAAiBH,GAAjB,EAAsBH,SAAtB,EAAiCrD,IAAI,CAAC+D,OAAtC,EAA+C/D,IAAI,CAACgE,KAApD,CAAjB;AACA,aAAOvJ,gBAAgB,CAACoJ,QAAD,CAAvB;AACH,KARD,SASQ;AACJtI,MAAAA,iBAAiB,CAAC+H,gBAAgB,CAAC,CAAD,CAAjB,EAAsBrH,CAAtB,CAAjB;AACAV,MAAAA,iBAAiB,CAAC+H,gBAAgB,CAAC,CAAD,CAAjB,EAAsBzE,CAAtB,CAAjB;AACH;AACJ,GA7TsC,CA8TvC;AACA;;AACA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACUzD,EAAAA,eAAe,CAAC6I,OAAD,EAAUjE,IAAV,EAAgB;AAAA;;AAAA;AACjC,MAAA,KAAI,CAAC0D,gBAAL;;AACA,aAAOtI,eAAe,CAAC,KAAD,EAAO6I,OAAP,EAAgBjE,IAAhB,CAAtB;AAFiC;AAGpC;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACIkE,EAAAA,eAAe,CAACV,GAAD,EAAMH,SAAN,EAAiBW,KAAjB,EAAwBG,SAAS,GAAG,OAApC,EAA6C;AACxD,QAAIC,UAAJ;;AACA,QAAIJ,KAAK,IAAI,IAAb,EAAmB;AACfI,MAAAA,UAAU,GAAG,IAAb;;AACA,UAAIf,SAAS,IAAI,IAAjB,EAAuB;AACnB,cAAM,IAAIpJ,UAAJ,CAAgB,MAAKkK,SAAU,+CAAhB,GAChB,mBAAkBd,SAAU,EAD3B,CAAN;AAEH;AACJ,KAND,MAOK,IAAIG,GAAG,IAAI,IAAX,EAAiB;AAClB,UAAIrH,KAAK,CAACC,OAAN,CAAcoH,GAAd,CAAJ,EAAwB;AACpBY,QAAAA,UAAU,GAAGZ,GAAG,CAAC,CAAD,CAAH,CAAOpG,KAAP,CAAa,CAAb,CAAb;AACH,OAFD,MAGK;AACDgH,QAAAA,UAAU,GAAGZ,GAAG,CAACpG,KAAJ,CAAU,CAAV,CAAb;AACH;AACJ,KAPI,MAQA;AACD,YAAM,IAAInD,UAAJ,CAAgB,wDAAD,GAChB,GAAEkK,SAAU,sBADX,CAAN;AAEH;;AACD,WAAOC,UAAP;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;;;AACIlJ,EAAAA,OAAO,CAACyC,MAAD,EAASsD,OAAT,EAAkB;AACrB,QAAI9E,KAAK,CAACC,OAAN,CAAc6E,OAAd,KAA0BA,OAAO,CAACrE,MAAR,KAAmB,CAAjD,EAAoD;AAChD,YAAM,IAAI3C,UAAJ,CAAe,oDAAf,CAAN;AACH;;AACD,UAAMoK,cAAc,GAAGlI,KAAK,CAACC,OAAN,CAAc6E,OAAd,CAAvB;AACA,UAAMzB,WAAW,GAAI6E,cAAc,GAAGpD,OAAH,GAAa,CAACA,OAAD,CAAhD;AACA,UAAMqD,qBAAqB,GAAG,KAAKC,uBAAL,CAA6B/E,WAA7B,CAA9B,CANqB,CAOrB;;AACA,UAAMgF,QAAQ,GAAG,IAAIrJ,QAAJ,EAAjB;;AACA,QAAIwC,MAAM,YAAYjE,MAAtB,EAA8B;AAC1BiE,MAAAA,MAAM,GAAG,CAACA,MAAD,CAAT;AACH;;AACD,QAAIxB,KAAK,CAACC,OAAN,CAAcuB,MAAd,CAAJ,EAA2B;AACvB,UAAIA,MAAM,CAACf,MAAP,KAAkB,KAAKe,MAAL,CAAYf,MAAlC,EAA0C;AACtC,cAAM,IAAI3C,UAAJ,CAAgB,kCAAiC0D,MAAM,CAACf,MAAO,IAAhD,GAChB,oDADgB,GAEhB,IAAG,KAAKe,MAAL,CAAYf,MAAO,IAFrB,CAAN;AAGH;;AACD,WAAK,IAAIS,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG,KAAKM,MAAL,CAAYf,MAAhC,EAAwC,EAAES,CAA1C,EAA6C;AACzCmH,QAAAA,QAAQ,CAACC,GAAT,CAAa,KAAK9G,MAAL,CAAYN,CAAZ,CAAb,EAA6BM,MAAM,CAACN,CAAD,CAAnC;AACH;AACJ,KATD,MAUK;AACD,WAAK,MAAMU,KAAX,IAAoB,KAAKJ,MAAzB,EAAiC;AAC7B,cAAM+G,WAAW,GAAG/G,MAAM,CAACI,KAAK,CAACd,IAAP,CAA1B;;AACA,YAAIyH,WAAW,IAAI,IAAnB,EAAyB;AACrB,gBAAM,IAAIzK,UAAJ,CAAgB,8CAA6C8D,KAAK,CAACd,IAAK,EAAxE,CAAN;AACH;;AACDuH,QAAAA,QAAQ,CAACC,GAAT,CAAa1G,KAAb,EAAoB2G,WAApB;AACH;AACJ,KA9BoB,CA+BrB;;;AACA,UAAMC,cAAc,GAAGzJ,OAAO,CAACoJ,qBAAD,EAAwBE,QAAxB,CAA9B;AACA,WAAOH,cAAc,GAAGM,cAAH,GAAoBA,cAAc,CAAC,CAAD,CAAvD;AACH;AACD;AACJ;AACA;;;AACIJ,EAAAA,uBAAuB,CAACK,mBAAD,EAAsB;AACzC,UAAMN,qBAAqB,GAAG9J,YAAY,CAAC,IAAD,EAAOoK,mBAAmB,CAAChI,MAA3B,CAA1C;AACA,QAAIiI,gBAAgB,GAAGD,mBAAmB,CAAChI,MAA3C;;AACA,SAAK,MAAMkI,KAAX,IAAoB,KAAKC,MAAzB,EAAiC;AAC7B,YAAMC,YAAY,GAAG7I,KAAK,CAACC,OAAN,CAAc0I,KAAK,CAACG,MAApB,IAA8BH,KAAK,CAACG,MAApC,GAA6C,CAACH,KAAK,CAACG,MAAP,CAAlE;AACA,YAAMC,gBAAgB,GAAGF,YAAY,CAAChI,GAAb,CAAiBiI,MAAM,IAAIA,MAAM,CAAChI,IAAlC,CAAzB;;AACA,WAAK,IAAII,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGuH,mBAAmB,CAAChI,MAAxC,EAAgD,EAAES,CAAlD,EAAqD;AACjD,cAAM8H,KAAK,GAAGD,gBAAgB,CAACnG,OAAjB,CAAyB6F,mBAAmB,CAACvH,CAAD,CAA5C,CAAd;;AACA,YAAI8H,KAAK,KAAK,CAAC,CAAf,EAAkB;AACdb,UAAAA,qBAAqB,CAACjH,CAAD,CAArB,GAA2B2H,YAAY,CAACG,KAAD,CAAvC;AACAN,UAAAA,gBAAgB;AACnB;;AACD,YAAIA,gBAAgB,KAAK,CAAzB,EAA4B;AACxB;AACH;AACJ;;AACD,UAAIA,gBAAgB,KAAK,CAAzB,EAA4B;AACxB;AACH;AACJ;;AACD,QAAIA,gBAAgB,GAAG,CAAvB,EAA0B;AACtB,YAAMO,cAAc,GAAG,EAAvB;AACAd,MAAAA,qBAAqB,CAACjD,OAAtB,CAA8B,CAACgE,MAAD,EAAShI,CAAT,KAAe;AACzC,YAAIgI,MAAM,IAAI,IAAd,EAAoB;AAChBD,UAAAA,cAAc,CAACjI,IAAf,CAAoByH,mBAAmB,CAACvH,CAAD,CAAvC;AACH;AACJ,OAJD;AAKA,YAAM,IAAIpD,UAAJ,CAAgB,kDAAD,GAChB,GAAEkE,IAAI,CAACC,SAAL,CAAegH,cAAf,CAA+B,EADhC,CAAN;AAEH;;AACD,WAAOd,qBAAP;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACIgB,EAAAA,WAAW,CAAC9B,GAAD,EAAMH,SAAS,GAAG,EAAlB,EAAsBU,OAAO,GAAG,KAAhC,EAAuC;AAC9C,WAAO1K,GAAG,CAACkM,IAAJ,CAAS,MAAM;AAClB,YAAMnB,UAAU,GAAG,KAAKF,eAAL,CAAqBV,GAArB,CAAnB;;AACA,UAAIO,OAAJ,EAAa;AACT,cAAM,IAAIhK,mBAAJ,CAAwB,+CAAxB,CAAN;AACH,OAJiB,CAKlB;AACA;AACA;AACA;;;AACA,YAAMyL,OAAO,GAAG9J,WAAW,CAAC0I,UAAD,EAAaf,SAAb,CAA3B;AACA,YAAMoC,WAAW,GAAG,KAAKxE,OAAL,CAAajE,GAAb,CAAiBiI,MAAM,IAAI,EAA3B,CAApB,CAVkB,CAWlB;;AACA,WAAK,IAAIS,UAAU,GAAG,CAAtB,EAAyBA,UAAU,GAAGF,OAAO,CAAC5I,MAA9C,EAAsD,EAAE8I,UAAxD,EAAoE;AAChE,cAAMC,SAAS,GAAGtM,GAAG,CAACkM,IAAJ,CAAS,MAAM;AAC7B,gBAAMK,UAAU,GAAGJ,OAAO,CAACE,UAAD,CAAP,CAAoB,CAApB,CAAnB;AACA,gBAAMG,QAAQ,GAAGL,OAAO,CAACE,UAAD,CAAP,CAAoB,CAApB,CAAjB,CAF6B,CAG7B;AACA;;AACA,gBAAMI,QAAQ,GAAGnK,WAAW,CAAC6H,GAAD,EAAMoC,UAAN,EAAkBC,QAAlB,CAA5B,CAL6B,CAM7B;;AACA,gBAAME,KAAK,GAAG,EAAd;;AACA,cAAI5J,KAAK,CAACC,OAAN,CAAc0J,QAAd,CAAJ,EAA6B;AACzB,iBAAK,IAAIzI,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGyI,QAAQ,CAAClJ,MAA7B,EAAqC,EAAES,CAAvC,EAA0C;AACtC0I,cAAAA,KAAK,CAAC5I,IAAN,CAAW;AAAEL,gBAAAA,GAAG,EAAE,KAAKa,MAAL,CAAYN,CAAZ,CAAP;AAAuB2I,gBAAAA,KAAK,EAAEF,QAAQ,CAACzI,CAAD;AAAtC,eAAX;AACH;AACJ,WAJD,MAKK;AACD0I,YAAAA,KAAK,CAAC5I,IAAN,CAAW;AAAEL,cAAAA,GAAG,EAAE,KAAKa,MAAL,CAAY,CAAZ,CAAP;AAAuBqI,cAAAA,KAAK,EAAEF;AAA9B,aAAX;AACH;;AACD,gBAAMtB,QAAQ,GAAG,IAAIrJ,QAAJ,CAAa4K,KAAb,CAAjB;AACA,iBAAO7K,OAAO,CAAC,KAAK+F,OAAN,EAAeuD,QAAf,CAAd;AACH,SAlBiB,CAAlB;AAmBAmB,QAAAA,SAAS,CAACtE,OAAV,CAAkB,CAAC4E,QAAD,EAAW5I,CAAX,KAAiBoI,WAAW,CAACpI,CAAD,CAAX,CAAeF,IAAf,CAAoB8I,QAApB,CAAnC;AACH;;AACD,aAAOxL,gBAAgB,CAACgL,WAAW,CAACzI,GAAZ,CAAgBwI,OAAO,IAAInM,GAAG,CAACoK,MAAJ,CAAW+B,OAAX,EAAoB,CAApB,CAA3B,CAAD,CAAvB;AACH,KAnCM,CAAP;AAoCH;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACIU,EAAAA,OAAO,CAACjK,CAAD,EAAI+D,IAAI,GAAG,EAAX,EAAe;AAClB,UAAMmG,eAAe,GAAG3K,0BAA0B,CAACS,CAAD,CAAlD;AACAoD,IAAAA,cAAc,CAAC8G,eAAD,EAAkB,KAAKC,UAAvB,EAAmC,KAAKC,eAAxC,EAAyD,KAAzD,CAAd;;AACA,QAAI;AACA;AACA;AACA;AACA;AACA,YAAMhD,SAAS,GAAGrD,IAAI,CAACqD,SAAL,IAAkB,IAAlB,GAAyB,EAAzB,GAA8BrD,IAAI,CAACqD,SAArD;AACA/H,MAAAA,cAAc,CAAC+H,SAAD,CAAd;AACA,aAAO,KAAKiC,WAAL,CAAiBa,eAAjB,EAAkC9C,SAAlC,CAAP;AACH,KARD,SASQ;AACJ9H,MAAAA,iBAAiB,CAAC4K,eAAD,EAAkBlK,CAAlB,CAAjB;AACH;AACJ;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACIqK,EAAAA,cAAc,CAACrK,CAAD,EAAI;AACdoD,IAAAA,cAAc,CAACpD,CAAD,EAAI,KAAKmK,UAAT,EAAqB,KAAKC,eAA1B,EAA2C,IAA3C,CAAd,CADc,CAEd;AACA;;AACA,UAAMhD,SAAS,GAAG,CAAClH,KAAK,CAACC,OAAN,CAAcH,CAAd,IAAmBA,CAAC,CAAC,CAAD,CAApB,GAA0BA,CAA3B,EAA8BmB,KAA9B,CAAoC,CAApC,CAAlB;AACA,WAAO,KAAKkI,WAAL,CAAiBrJ,CAAjB,EAAoBoH,SAApB,CAAP;AACH;;AACDE,EAAAA,qBAAqB,CAACtH,CAAD,EAAI4C,CAAJ,EAAOnC,cAAc,GAAG,IAAxB,EAA8B2G,SAA9B,EAAyC;AAC1D;AACA,QAAI,KAAK1C,UAAL,IAAmB,IAAvB,EAA6B;AACzB,YAAM,IAAI3G,YAAJ,CAAiB,2DACnB,wCADE,CAAN;AAEH;;AACD,UAAMwE,YAAY,GAAG,EAArB;;AACA,SAAK,IAAInB,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG,KAAKmE,gBAAL,CAAsB5E,MAA1C,EAAkD,EAAES,CAApD,EAAuD;AACnD,YAAMmF,WAAW,GAAG,KAAKhB,gBAAL,CAAsBnE,CAAtB,CAApB;AACA,YAAMkJ,MAAM,GAAG,KAAK9E,WAAL,CAAiBpE,CAAjB,CAAf;;AACA,UAAIkJ,MAAM,KAAKpM,MAAM,CAACuI,6BAAtB,EAAqD;AACjDlE,QAAAA,YAAY,CAACrB,IAAb,CAAkBqF,WAAW,CAACvD,KAAZ,CAAkB,CAAlB,EAAqBuD,WAAW,CAAC5F,MAAZ,GAAqB,CAA1C,EAA6C6G,MAA7C,CAAoD,CAAC,CAAD,CAApD,CAAlB;AACH,OAFD,MAGK;AACD;AACAjF,QAAAA,YAAY,CAACrB,IAAb,CAAkBqF,WAAlB;AACH;AACJ;;AACDvG,IAAAA,CAAC,GAAGK,oBAAoB,CAACL,CAAD,EAAI,KAAKuK,cAAT,EAAyB,KAAKH,eAA9B,EAA+C,KAA/C,EAAsD,OAAtD,CAAxB;AACAxH,IAAAA,CAAC,GAAGvC,oBAAoB,CAACuC,CAAD,EAAI,KAAK0C,eAAT,EAA0B/C,YAA1B,EAAwC,KAAxC,EAA+C,QAA/C,CAAxB,CAnB0D,CAoB1D;;AACAd,IAAAA,iBAAiB,CAACzB,CAAD,EAAI4C,CAAJ,EAAO,IAAP,CAAjB,CArB0D,CAsB1D;;AACAP,IAAAA,+BAA+B,CAACO,CAAD,EAAI,KAAK4C,WAAT,EAAsB,KAAKD,gBAA3B,CAA/B;;AACA,QAAI,KAAKiF,QAAL,IAAiBpD,SAAS,IAAI,IAA9B,IAAsCA,SAAS,GAAG,CAAtD,EAAyD;AACrD,UAAIpH,CAAC,CAAC,CAAD,CAAD,CAAKmB,KAAL,CAAW,CAAX,IAAgBiG,SAAhB,KAA8B,CAAlC,EAAqC;AACjC,cAAM,IAAIpJ,UAAJ,CAAgB,4DAAD,GAChB,wDADgB,GAEhB,GAAEoJ,SAAU,YAAWpH,CAAC,CAAC,CAAD,CAAD,CAAKmB,KAAL,CAAW,CAAX,CAAc,aAFpC,CAAN;AAGH;AACJ;;AACD,WAAO,CAACnB,CAAD,EAAI4C,CAAJ,CAAP;AACH;;AACK6H,EAAAA,mBAAmB,CAACzK,CAAD,EAAI4C,CAAJ,EAAO8H,YAAP,EAAqBC,WAArB,EAAkClK,cAAc,GAAG,IAAnD,EAAyD2G,SAAzD,EAAoE;AAAA;;AAAA;AACzF,YAAM,CAACwD,UAAD,EAAaC,UAAb,IAA2B,MAAI,CAACvD,qBAAL,CAA2BtH,CAA3B,EAA8B4C,CAA9B,EAAiCnC,cAAjC,EAAiD2G,SAAjD,CAAjC,CADyF,CAEzF;;;AACA,UAAIsD,YAAY,IAAI,IAApB,EAA0B;AACtB,cAAM,IAAII,KAAJ,CAAU,qCAAV,CAAN;AACH;;AACD,UAAIC,qBAAqB,GAAG,IAA5B;;AACA,UAAIJ,WAAW,IAAI,IAAnB,EAAyB;AACrB,cAAMK,YAAY,GAAGnL,uBAAuB,CAAC8K,WAAD,EAAc,MAAI,CAACpH,WAAnB,CAA5C;AACAwH,QAAAA,qBAAqB,GAAG,EAAxB;;AACA,aAAK,IAAI3J,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG4J,YAAY,CAACrK,MAAjC,EAAyC,EAAES,CAA3C,EAA8C;AAC1C2J,UAAAA,qBAAqB,CAAC7J,IAAtB,OAAiCpB,kBAAkB,CAAC+K,UAAU,CAACzJ,CAAD,CAAX,EAAgB,IAAhB,EAAsB4J,YAAY,CAAC5J,CAAD,CAAlC,CAAnD;AACH;AACJ,OAbwF,CAczF;;;AACA,aAAO,CAACwJ,UAAD,EAAaC,UAAb,EAAyBE,qBAAzB,CAAP;AAfyF;AAgB5F;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACIlD,EAAAA,QAAQ,CAACH,CAAD,EAAIH,GAAJ,EAASH,SAAT,EAAoBU,OAAO,GAAG,CAA9B,EAAiCC,KAAjC,EAAwC;AAC5C,WAAO3K,GAAG,CAACkM,IAAJ,CAAS,MAAM;AAClB,YAAMnB,UAAU,GAAG,KAAKF,eAAL,CAAqBV,GAArB,EAA0BH,SAA1B,EAAqCW,KAArC,EAA4C,OAA5C,CAAnB;AACA,YAAMkD,IAAI,GAAG,EAAb;;AACA,UAAInD,OAAO,GAAG,CAAd,EAAiB;AACb,cAAM,IAAIhK,mBAAJ,CAAwB,sCAAxB,CAAN;AACH,OALiB,CAMlB;;;AACA,UAAIiK,KAAK,IAAI,IAAb,EAAmB;AACf,cAAM,IAAIjK,mBAAJ,CAAwB,iDAAxB,CAAN;AACH,OAFD,MAGK;AACD,cAAMyL,OAAO,GAAG9J,WAAW,CAAC0I,UAAD,EAAaf,SAAb,CAA3B;AACA,cAAM8D,UAAU,GAAGxN,QAAQ,CAACmB,KAAK,CAAC,CAAD,EAAIsJ,UAAJ,CAAN,CAA3B;;AACA,aAAK,IAAIsB,UAAU,GAAG,CAAtB,EAAyBA,UAAU,GAAGF,OAAO,CAAC5I,MAA9C,EAAsD,EAAE8I,UAAxD,EAAoE;AAChE,gBAAME,UAAU,GAAGJ,OAAO,CAACE,UAAD,CAAP,CAAoB,CAApB,CAAnB;AACA,gBAAMG,QAAQ,GAAGL,OAAO,CAACE,UAAD,CAAP,CAAoB,CAApB,CAAjB;AACA,gBAAM0B,QAAQ,GAAGvN,CAAC,CAACwN,mBAAF,CAAsBF,UAAtB,EAAkCvB,UAAlC,EAA8CC,QAAQ,GAAGD,UAAzD,CAAjB,CAHgE,CAIhE;AACA;;AACA,gBAAME,QAAQ,GAAGlK,oBAAoB,CAAC4H,GAAD,EAAM4D,QAAN,CAArC;AACA,gBAAMzB,SAAS,GAAGhC,CAAC,CAACmC,QAAD,CAAnB;;AACA,cAAIJ,UAAU,KAAK,CAAnB,EAAsB;AAClB,iBAAK,IAAIrI,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGsI,SAAS,CAAC/I,MAA9B,EAAsC,EAAES,CAAxC,EAA2C;AACvC6J,cAAAA,IAAI,CAAC/J,IAAL,CAAU3D,MAAM,CAAC,CAAD,CAAhB;AACH;AACJ;;AACD,eAAK,IAAI6D,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGsI,SAAS,CAAC/I,MAA9B,EAAsC,EAAES,CAAxC,EAA2C;AACvC,kBAAM4I,QAAQ,GAAGN,SAAS,CAACtI,CAAD,CAA1B;AACA6J,YAAAA,IAAI,CAAC7J,CAAD,CAAJ,GACIhE,GAAG,CAACoL,GAAJ,CAAQyC,IAAI,CAAC7J,CAAD,CAAZ,EAAiBhE,GAAG,CAACiO,GAAJ,CAAQzB,QAAQ,GAAGD,UAAnB,EAA+BK,QAA/B,CAAjB,CADJ;AAEH;AACJ;;AACD,aAAK,IAAI5I,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG6J,IAAI,CAACtK,MAAzB,EAAiC,EAAES,CAAnC,EAAsC;AAClC6J,UAAAA,IAAI,CAAC7J,CAAD,CAAJ,GAAUhE,GAAG,CAACkO,GAAJ,CAAQL,IAAI,CAAC7J,CAAD,CAAZ,EAAiB+G,UAAjB,CAAV;AACH;AACJ;;AACD,aAAO8C,IAAP;AACH,KArCM,CAAP;AAsCH;;AACDM,EAAAA,sBAAsB,GAAG;AACrB,UAAMC,SAAS,GAAG,KAAK7F,YAAvB,CADqB,CAErB;AACA;;AACA,UAAM8F,gBAAgB,GAAG,EAAzB;;AACA,SAAK,IAAIrK,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGoK,SAAS,CAAC7K,MAA9B,EAAsC,EAAES,CAAxC,EAA2C;AACvC,YAAMsK,KAAK,GAAGF,SAAS,CAACpK,CAAD,CAAvB;AACA,UAAIuK,QAAQ,GAAGD,KAAf;;AACA,UAAIpN,KAAK,CAACkN,SAAD,EAAYE,KAAZ,CAAL,GAA0B,CAA9B,EAAiC;AAC7B,cAAME,QAAQ,GAAGtN,KAAK,CAACkN,SAAS,CAACxI,KAAV,CAAgB,CAAhB,EAAmB5B,CAAnB,CAAD,EAAwBsK,KAAxB,CAAtB;AACAC,QAAAA,QAAQ,IAAK,IAAGC,QAAS,EAAzB;AACH;;AACDH,MAAAA,gBAAgB,CAACvK,IAAjB,CAAsByK,QAAtB;AACH;;AACD,WAAOF,gBAAP;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACII,EAAAA,iBAAiB,GAAG;AAChB,WAAQvL,IAAD,IAAU;AACb,YAAMwL,UAAU,GAAG,EAAnB;AACA,YAAMpK,MAAM,GAAGpB,IAAI,CAAC0C,KAAL,CAAW,CAAX,EAAc,KAAKtB,MAAL,CAAYf,MAA1B,CAAf;AACA,YAAMgB,OAAO,GAAGrB,IAAI,CAAC0C,KAAL,CAAW,KAAKtB,MAAL,CAAYf,MAAvB,EAA+B,KAAKe,MAAL,CAAYf,MAAZ,GAAqB,KAAKqE,OAAL,CAAarE,MAAjE,CAAhB;AACA,YAAMoL,aAAa,GAAGzL,IAAI,CAAC0C,KAAL,CAAW,KAAKtB,MAAL,CAAYf,MAAZ,GAAqB,KAAKqE,OAAL,CAAarE,MAA7C,EAAqD,KAAKe,MAAL,CAAYf,MAAZ,GAAqB,KAAKqE,OAAL,CAAarE,MAAb,GAAsB,CAAhG,CAAtB;AACA,YAAMqL,aAAa,GAAG,EAAtB,CALa,CAMb;AACA;AACA;;AACA,YAAMC,iBAAiB,GAAG,MAAM;AAC5B,cAAMnC,KAAK,GAAG,EAAd;;AACA,aAAK,IAAI1I,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG,KAAKM,MAAL,CAAYf,MAAhC,EAAwC,EAAES,CAA1C,EAA6C;AACzC0I,UAAAA,KAAK,CAAC5I,IAAN,CAAW;AAAEL,YAAAA,GAAG,EAAE,KAAKa,MAAL,CAAYN,CAAZ,CAAP;AAAuB2I,YAAAA,KAAK,EAAErI,MAAM,CAACN,CAAD;AAApC,WAAX;AACH;;AACD,cAAMmH,QAAQ,GAAG,IAAIrJ,QAAJ,CAAa4K,KAAb,CAAjB;AACA,cAAM9E,OAAO,GAAG/F,OAAO,CAAC,KAAK+F,OAAN,EAAeuD,QAAf,EAAyB;AAAE,sBAAY;AAAd,SAAzB,CAAvB,CAN4B,CAO5B;AACA;;AACA,YAAI2D,SAAJ;;AACA,aAAK,IAAI9K,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG,KAAKyD,aAAL,CAAmBlE,MAAvC,EAA+C,EAAES,CAAjD,EAAoD;AAChD,gBAAM+D,YAAY,GAAG,KAAKN,aAAL,CAAmBzD,CAAnB,CAArB;AACA,cAAIyB,IAAI,GAAGsC,YAAY,CAACxD,OAAO,CAACP,CAAD,CAAR,EAAa4D,OAAO,CAAC5D,CAAD,CAApB,CAAvB;;AACA,cAAI2K,aAAa,CAAC3K,CAAD,CAAb,IAAoB,IAAxB,EAA8B;AAC1ByB,YAAAA,IAAI,GAAGjD,mBAAmB,CAACiD,IAAD,EAAOkJ,aAAa,CAAC3K,CAAD,CAApB,CAA1B;AACH,WAL+C,CAMhD;;;AACA,gBAAM+K,QAAQ,GAAG/O,GAAG,CAACgP,IAAJ,CAASvJ,IAAT,CAAjB,CAPgD,CAQhD;;AACAiJ,UAAAA,UAAU,CAAC5K,IAAX,CAAgBiL,QAAhB;;AACA,cAAI/K,CAAC,KAAK,CAAV,EAAa;AACT8K,YAAAA,SAAS,GAAGrJ,IAAZ;AACH,WAFD,MAGK;AACDqJ,YAAAA,SAAS,GAAG9O,GAAG,CAACoL,GAAJ,CAAQ0D,SAAR,EAAmBrJ,IAAnB,CAAZ;AACH;AACJ,SA1B2B,CA2B5B;AACA;AACA;;;AACA,aAAK,IAAIzB,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG,KAAKwE,cAAL,CAAoBjF,MAAxC,EAAgD,EAAES,CAAlD,EAAqD;AACjD,cAAIiL,cAAJ;;AACA,cAAI,KAAKrH,OAAL,CAAarE,MAAb,GAAsB,CAAtB,IAA2BS,CAAC,GAAG,KAAK4D,OAAL,CAAarE,MAAhD,EAAwD;AACpD0L,YAAAA,cAAc,GAAGP,UAAU,CAAC1K,CAAD,CAA3B;AACH,WAFD,MAGK;AACD,kBAAMkF,MAAM,GAAG,KAAKV,cAAL,CAAoBxE,CAApB,EAAuB,CAAvB,CAAf;AACA,kBAAM2E,WAAW,GAAG,KAAKH,cAAL,CAAoBxE,CAApB,EAAuB,CAAvB,CAApB;AACAiL,YAAAA,cAAc,GACVjP,GAAG,CAACgP,IAAJ,CAAS9F,MAAM,CAAC3E,OAAO,CAACoE,WAAD,CAAR,EAAuBf,OAAO,CAACe,WAAD,CAA9B,CAAf,CADJ;AAEH;;AACD3I,UAAAA,GAAG,CAACkP,IAAJ,CAASD,cAAT,EAXiD,CAYjD;;AACAL,UAAAA,aAAa,CAAC9K,IAAd,CAAmBmL,cAAnB;AACH;;AACDH,QAAAA,SAAS,GAAG9O,GAAG,CAACgP,IAAJ,CAASF,SAAT,CAAZ,CA7C4B,CA8C5B;;AACA,aAAKK,eAAL,GAAuBnH,OAAvB,CAA+BoH,eAAe,IAAI;AAC9CN,UAAAA,SAAS,GAAG9O,GAAG,CAACoL,GAAJ,CAAQ0D,SAAR,EAAmBM,eAAnB,CAAZ;AACH,SAFD;AAGA,eAAON,SAAP;AACH,OAnDD;;AAoDA,YAAMO,SAAS,GAAG,KAAKzF,yBAAL,CAA+BjG,GAA/B,CAAmC2L,KAAK,IAAIA,KAAK,CAACC,IAAN,EAA5C,CAAlB;AACA,YAAMC,UAAU,GAAG,IAAnB;AACA,YAAMC,cAAc,GAAG,KAAKnI,UAAL,CAAgBoI,QAAhB,CAAyBb,iBAAzB,EAA4CW,UAA5C,EAAwDH,SAAxD,CAAvB;AACA,aAAO,CAACI,cAAD,EAAiBrF,MAAjB,CAAwBwE,aAAxB,CAAP;AACH,KAjED;AAkEH;AACD;AACJ;AACA;AACA;AACA;;;AACIvE,EAAAA,gBAAgB,GAAG;AACf,SAAKE,YAAL,GAAqBrH,IAAD,IAAU;AAC1B,aAAOlD,GAAG,CAACkM,IAAJ,CAAS,MAAM;AAClB,cAAMyD,UAAU,GAAG,EAAnB;AACA,YAAIb,SAAJ;AACA,cAAMxK,MAAM,GAAGpB,IAAI,CAAC0C,KAAL,CAAW,CAAX,EAAc,KAAKtB,MAAL,CAAYf,MAA1B,CAAf;AACA,cAAMgB,OAAO,GAAGrB,IAAI,CAAC0C,KAAL,CAAW,KAAKtB,MAAL,CAAYf,MAAvB,EAA+B,KAAKe,MAAL,CAAYf,MAAZ,GAAqB,KAAKqE,OAAL,CAAarE,MAAjE,CAAhB;AACA,cAAMmJ,KAAK,GAAG,EAAd;;AACA,aAAK,IAAI1I,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG,KAAKM,MAAL,CAAYf,MAAhC,EAAwC,EAAES,CAA1C,EAA6C;AACzC0I,UAAAA,KAAK,CAAC5I,IAAN,CAAW;AAAEL,YAAAA,GAAG,EAAE,KAAKa,MAAL,CAAYN,CAAZ,CAAP;AAAuB2I,YAAAA,KAAK,EAAErI,MAAM,CAACN,CAAD;AAApC,WAAX;AACH;;AACD,cAAMmH,QAAQ,GAAG,IAAIrJ,QAAJ,CAAa4K,KAAb,CAAjB;AACA,cAAM9E,OAAO,GAAG/F,OAAO,CAAC,KAAK+F,OAAN,EAAeuD,QAAf,CAAvB,CAVkB,CAWlB;;AACA,aAAK,IAAInH,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG,KAAKyD,aAAL,CAAmBlE,MAAvC,EAA+C,EAAES,CAAjD,EAAoD;AAChD,gBAAM+D,YAAY,GAAG,KAAKN,aAAL,CAAmBzD,CAAnB,CAArB,CADgD,CAEhD;AACA;;AACA,gBAAMyB,IAAI,GAAGzF,GAAG,CAACgP,IAAJ,CAASjH,YAAY,CAACxD,OAAO,CAACP,CAAD,CAAR,EAAa4D,OAAO,CAAC5D,CAAD,CAApB,CAArB,CAAb;;AACA,cAAIA,CAAC,KAAK,CAAV,EAAa;AACT8K,YAAAA,SAAS,GAAGrJ,IAAZ;AACH,WAFD,MAGK;AACDqJ,YAAAA,SAAS,GAAG9O,GAAG,CAACoL,GAAJ,CAAQ0D,SAAR,EAAmBrJ,IAAnB,CAAZ;AACH;;AACDkK,UAAAA,UAAU,CAAC7L,IAAX,CAAgBgL,SAAhB;AACH,SAxBiB,CAyBlB;;;AACA,aAAK,IAAI9K,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG,KAAKwE,cAAL,CAAoBjF,MAAxC,EAAgD,EAAES,CAAlD,EAAqD;AACjD,gBAAMkF,MAAM,GAAG,KAAKV,cAAL,CAAoBxE,CAApB,EAAuB,CAAvB,CAAf;AACA,gBAAM2E,WAAW,GAAG,KAAKH,cAAL,CAAoBxE,CAApB,EAAuB,CAAvB,CAApB,CAFiD,CAGjD;;AACA,gBAAM4L,UAAU,GAAG5P,GAAG,CAACgP,IAAJ,CAAS9F,MAAM,CAAC3E,OAAO,CAACoE,WAAD,CAAR,EAAuBf,OAAO,CAACe,WAAD,CAA9B,CAAf,CAAnB;AACAgH,UAAAA,UAAU,CAAC7L,IAAX,CAAgB8L,UAAhB;AACH;;AACD,eAAOD,UAAP;AACH,OAlCM,CAAP;AAmCH,KApCD;AAqCH;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACUE,EAAAA,GAAG,CAACjN,CAAD,EAAI4C,CAAJ,EAAOmB,IAAI,GAAG,EAAd,EAAkB;AAAA;;AAAA;AACvB,aAAOvE,UAAU,CAAC,MAAD,EAAOQ,CAAP,EAAU4C,CAAV,EAAamB,IAAb,CAAjB;AADuB;AAE1B,GA70BsC,CA80BvC;AACA;;AACA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACU3E,EAAAA,UAAU,CAAC4I,OAAD,EAAUjE,IAAV,EAAgB;AAAA;;AAAA;AAC5B,aAAO3E,UAAU,CAAC,MAAD,EAAO4I,OAAP,EAAgBjE,IAAhB,CAAjB;AAD4B;AAE/B;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACUmJ,EAAAA,YAAY,CAAClN,CAAD,EAAI4C,CAAJ,EAAO;AAAA;;AAAA;AACrB;AACA;AACA,YAAMuK,cAAc,SAAS,MAAI,CAAC1C,mBAAL,CAAyBzK,CAAzB,EAA4B4C,CAA5B,CAA7B;AACA,YAAMlB,MAAM,GAAGyL,cAAc,CAAC,CAAD,CAA7B;AACA,YAAMxL,OAAO,GAAGwL,cAAc,CAAC,CAAD,CAA9B;;AACA,YAAMC,aAAa,GAAG,MAAI,CAACvB,iBAAL,EAAtB;;AACA,YAAM3N,MAAM,GAAGkP,aAAa,CAAC1L,MAAM,CAAC8F,MAAP,CAAc7F,OAAd,CAAD,CAA5B;AACA,YAAMmK,UAAU,GAAG,EAAnB;;AACA,WAAK,MAAMjJ,IAAX,IAAmB3E,MAAnB,EAA2B;AACvB,cAAMmP,CAAC,SAASxK,IAAI,CAACvC,IAAL,EAAhB;AACAwL,QAAAA,UAAU,CAAC5K,IAAX,CAAgBmM,CAAC,CAAC,CAAD,CAAjB;AACH;;AACDjQ,MAAAA,GAAG,CAACkQ,OAAJ,CAAYpP,MAAZ;AACA,aAAOM,gBAAgB,CAACsN,UAAD,CAAvB;AAdqB;AAexB;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACIyB,EAAAA,eAAe,CAACC,MAAD,EAAS;AACpB,UAAMC,YAAY,GAAG,EAArB;AACA,UAAMC,aAAa,GAAGF,MAAM,IAAI,IAAV,IAAkBA,MAAM,CAACE,aAA/C;AACA,UAAM9L,OAAO,GAAG8L,aAAa,GAAG,KAAKzG,gBAAR,GAA2B,KAAKrF,OAA7D;AACA,UAAM+L,YAAY,GAAG,KAAKC,UAAL,CAAgBF,aAAhB,CAArB;;AACA,SAAK,IAAItM,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGQ,OAAO,CAACjB,MAA5B,EAAoC,EAAES,CAAtC,EAAyC;AACrC,UAAIsM,aAAa,IAAI,CAAC9L,OAAO,CAACR,CAAD,CAAP,CAAWyM,SAAjC,EAA4C;AACxC;AACA;AACH;;AACDJ,MAAAA,YAAY,CAACvM,IAAb,CAAkB;AAAEF,QAAAA,IAAI,EAAEY,OAAO,CAACR,CAAD,CAAP,CAAW0M,YAAnB;AAAiC1E,QAAAA,MAAM,EAAEuE,YAAY,CAACvM,CAAD;AAArD,OAAlB;AACH;;AACD,WAAOqM,YAAP;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACoB,MAAZM,YAAY,CAACC,IAAD,EAAO;AACnB,SAAKC,aAAL,GAAqBD,IAArB;AACH;;AACe,MAAZD,YAAY,GAAG;AACf,WAAO,KAAKE,aAAZ;AACH;;AACY,MAATxJ,SAAS,GAAG;AACZ,WAAO,KAAKC,UAAZ;AACH;;AACY,MAATD,SAAS,CAACA,SAAD,EAAY;AACrB,QAAI,KAAKC,UAAL,KAAoBD,SAAxB,EAAmC;AAC/B,WAAKC,UAAL,GAAkBD,SAAlB;AACA,WAAKG,gBAAL,GAAwB,KAAxB;AACH;AACJ;;AACD0I,EAAAA,OAAO,GAAG;AACN,UAAMY,MAAM,GAAG,MAAMZ,OAAN,EAAf;;AACA,QAAIY,MAAM,CAACC,oBAAP,KAAgC,CAAhC,IAAqC,KAAK1J,SAAL,IAAkB,IAAvD,IACA,KAAKG,gBADT,EAC2B;AACvB,YAAMwJ,gCAAgC,GAAGhR,GAAG,CAACiR,MAAJ,GAAaC,UAAtD;AACA,WAAK5J,UAAL,CAAgB4I,OAAhB;AACAY,MAAAA,MAAM,CAACK,oBAAP,IACIH,gCAAgC,GAAGhR,GAAG,CAACiR,MAAJ,GAAaC,UADpD;AAEH;;AACD,WAAOJ,MAAP;AACH;;AACDM,EAAAA,kBAAkB,GAAG;AACjB,QAAIC,SAAJ;;AACA,QAAI,OAAO,KAAK5L,IAAZ,KAAqB,QAAzB,EAAmC;AAC/B4L,MAAAA,SAAS,GAAG/P,WAAW,CAAC,KAAKmE,IAAN,CAAvB;AACH,KAFD,MAGK,IAAI3C,KAAK,CAACC,OAAN,CAAc,KAAK0C,IAAnB,CAAJ,EAA8B;AAC/B,WAAK,MAAMA,IAAX,IAAmB,KAAKA,IAAxB,EAA8B;AAC1B,YAAI,OAAOA,IAAP,KAAgB,QAApB,EAA8B;AAC1B,gBAAM,IAAIiI,KAAJ,CAAU,oDAAV,CAAN;AACH;AACJ;;AACD2D,MAAAA,SAAS,GAAG,KAAK5L,IAAL,CAAU9B,GAAV,CAAcC,IAAI,IAAItC,WAAW,CAACsC,IAAD,CAAjC,CAAZ;AACH,KAPI,MAQA;AACD,YAAMuC,WAAW,GAAGmL,MAAM,CAACC,IAAP,CAAY,KAAK9L,IAAjB,CAApB;AACA4L,MAAAA,SAAS,GAAG,EAAZ;AACA,YAAMvQ,MAAM,GAAG,KAAK2E,IAApB;;AACA,WAAK,MAAM+L,UAAX,IAAyBrL,WAAzB,EAAsC;AAClC,YAAI,OAAOrF,MAAM,CAAC0Q,UAAD,CAAb,KAA8B,QAAlC,EAA4C;AACxCH,UAAAA,SAAS,CAACG,UAAD,CAAT,GACIlQ,WAAW,CAACR,MAAM,CAAC0Q,UAAD,CAAP,CADf;AAEH,SAHD,MAIK;AACD,gBAAM,IAAI9D,KAAJ,CAAU,oDAAV,CAAN;AACH;AACJ;AACJ;;AACD,WAAO2D,SAAP;AACH;;AACDI,EAAAA,oBAAoB,GAAG;AACnB,QAAI,OAAO,KAAKvL,OAAZ,KAAwB,QAAxB,IACA,OAAO,KAAKA,OAAZ,KAAwB,UAD5B,EACwC;AACpC,aAAO,CAAC5E,WAAW,CAACP,OAAO,CAAC2I,mBAAR,CAA4B,KAAKxD,OAAjC,CAAD,CAAZ,CAAP;AACH,KAHD,MAIK,IAAIpD,KAAK,CAACC,OAAN,CAAc,KAAKmD,OAAnB,CAAJ,EAAiC;AAClC,aAAO,KAAKA,OAAL,CAAavC,GAAb,CAAiBuF,MAAM,IAAI5H,WAAW,CAACP,OAAO,CAAC2I,mBAAR,CAA4BR,MAA5B,CAAD,CAAtC,CAAP;AACH,KAFI,MAGA;AACD,YAAMwI,kBAAkB,GAAG,EAA3B;;AACA,WAAK,MAAMjO,GAAX,IAAkB,KAAKyC,OAAvB,EAAgC;AAC5BwL,QAAAA,kBAAkB,CAACjO,GAAD,CAAlB,GACInC,WAAW,CAACP,OAAO,CAAC2I,mBAAR,CAA4B,KAAKxD,OAAL,CAAazC,GAAb,CAA5B,CAAD,CADf;AAEH;;AACD,aAAOiO,kBAAP;AACH;AACJ;;AACDC,EAAAA,iBAAiB,GAAG;AAChB,WAAO;AACHlM,MAAAA,IAAI,EAAE,KAAK2L,kBAAL,EADH;AAEHlL,MAAAA,OAAO,EAAE,KAAKuL,oBAAL,EAFN;AAGHG,MAAAA,gBAAgB,EAAE;AACdC,QAAAA,UAAU,EAAE,KAAKxK,SAAL,CAAeyK,YAAf,EADE;AAEd1B,QAAAA,MAAM,EAAE,KAAK/I,SAAL,CAAe0K,SAAf;AAFM;AAHf,KAAP,CADgB,CAShB;AACA;AACA;AACH;;AACDC,EAAAA,kBAAkB,CAACC,cAAD,EAAiB;AAC/B,QAAIA,cAAc,CAACC,gBAAf,IAAmC,IAAvC,EAA6C;AACzC,YAAM,IAAIxE,KAAJ,CAAU,8CAAV,CAAN;AACH;;AACD,QAAIuE,cAAc,CAACE,YAAf,IAA+B,IAAnC,EAAyC;AACrC,YAAM,IAAIzE,KAAJ,CAAU,4CAAV,CAAN;AACH;;AACD,QAAIuE,cAAc,CAACG,kBAAf,IAAqC,IAAzC,EAA+C;AAC3C,YAAM,IAAI1E,KAAJ,CAAU,kDAAV,CAAN;AACH;;AACD,UAAM2E,QAAQ,GAAG3Q,mBAAmB,CAACuQ,cAAc,CAACL,gBAAhB,CAApC;AACA,UAAMvK,SAAS,GAAGxG,WAAW,CAACwR,QAAD,CAA7B;AACA,QAAI5M,IAAJ;;AACA,QAAI,OAAOwM,cAAc,CAACxM,IAAtB,KAA+B,QAAnC,EAA6C;AACzCA,MAAAA,IAAI,GAAGpE,WAAW,CAAC4Q,cAAc,CAACxM,IAAhB,CAAlB;AACH,KAFD,MAGK,IAAI3C,KAAK,CAACC,OAAN,CAAckP,cAAc,CAACxM,IAA7B,CAAJ,EAAwC;AACzCA,MAAAA,IAAI,GAAGwM,cAAc,CAACxM,IAAf,CAAoB9B,GAApB,CAAwB2O,SAAS,IAAIjR,WAAW,CAACiR,SAAD,CAAhD,CAAP;AACH,KAFI,MAGA,IAAIL,cAAc,CAACxM,IAAf,IAAuB,IAA3B,EAAiC;AAClCA,MAAAA,IAAI,GAAG,EAAP;;AACA,WAAK,MAAMhC,GAAX,IAAkBwO,cAAc,CAACxM,IAAjC,EAAuC;AACnCA,QAAAA,IAAI,CAAChC,GAAD,CAAJ,GAAYpC,WAAW,CAAC4Q,cAAc,CAACxM,IAAf,CAAoBhC,GAApB,CAAD,CAAvB;AACH;AACJ;;AACD,QAAIyC,OAAJ;;AACA,QAAIpD,KAAK,CAACC,OAAN,CAAckP,cAAc,CAAC/L,OAA7B,CAAJ,EAA2C;AACvCA,MAAAA,OAAO,GAAG+L,cAAc,CAAC/L,OAAf,CAAuBvC,GAAvB,CAA2BuF,MAAM,IAAI7H,WAAW,CAAC6H,MAAD,CAAhD,CAAV;AACH,KAFD,MAGK,IAAI+I,cAAc,CAAC/L,OAAf,IAA0B,IAA9B,EAAoC;AACrCA,MAAAA,OAAO,GAAG,EAAV;;AACA,WAAK,MAAMzC,GAAX,IAAkBwO,cAAc,CAAC/L,OAAjC,EAA0C;AACtCA,QAAAA,OAAO,CAACzC,GAAD,CAAP,GAAepC,WAAW,CAAC4Q,cAAc,CAAC/L,OAAf,CAAuBzC,GAAvB,CAAD,CAA1B;AACH;AACJ;;AACD,SAAK2D,OAAL,CAAa;AAAE3B,MAAAA,IAAF;AAAQS,MAAAA,OAAR;AAAiBmB,MAAAA;AAAjB,KAAb;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACUkL,EAAAA,IAAI,CAACC,YAAD,EAAepC,MAAf,EAAuB;AAAA;;AAAA;AAC7B,UAAI,OAAOoC,YAAP,KAAwB,QAA5B,EAAsC;AAClC,cAAMC,QAAQ,GAAGxS,EAAE,CAACyS,eAAH,CAAmBF,YAAnB,CAAjB;;AACA,YAAIC,QAAQ,CAAClP,MAAT,KAAoB,CAAxB,EAA2B;AACvB,gBAAM,IAAI3C,UAAJ,CAAgB,0CAAyC4R,YAAa,GAAtE,CAAN;AACH,SAFD,MAGK,IAAIC,QAAQ,CAAClP,MAAT,GAAkB,CAAtB,EAAyB;AAC1B,gBAAM,IAAI3C,UAAJ,CAAgB,wBAAuB6R,QAAQ,CAAClP,MAAO,sBAAxC,GAChB,QAAOiP,YAAa,GADnB,CAAN;AAEH;;AACDA,QAAAA,YAAY,GAAGC,QAAQ,CAAC,CAAD,CAAvB;AACH;;AACD,UAAID,YAAY,CAACD,IAAb,IAAqB,IAAzB,EAA+B;AAC3B,cAAM,IAAI3R,UAAJ,CAAe,6DACjB,sDADE,CAAN;AAEH;;AACD,YAAM+R,kBAAkB,SAAS1S,EAAE,CAAC2S,aAAH,CAAiB,MAAI,CAACzC,eAAL,CAAqBC,MAArB,CAAjB,CAAjC;AACA,YAAMyC,YAAY,GAAG,KAArB;AACA,YAAMC,SAAS,GAAG,IAAlB;;AACA,YAAMC,WAAW,GAAG,MAAI,CAACC,MAAL,CAAYF,SAAZ,EAAuBD,YAAvB,CAApB;;AACA,YAAMI,cAAc,GAAG;AACnBC,QAAAA,aAAa,EAAEH,WADI;AAEnBI,QAAAA,MAAM,EAAE3M,wBAFW;AAGnB4M,QAAAA,WAAW,EAAG,8BAA6BzR,OAAQ,EAHhC;AAInB0R,QAAAA,WAAW,EAAE;AAJM,OAAvB;AAMA,YAAMC,gBAAgB,GAAGlD,MAAM,IAAI,IAAV,GAAiB,KAAjB,GAAyBA,MAAM,CAACkD,gBAAzD;;AACA,UAAIA,gBAAgB,IAAI,MAAI,CAACjM,SAAL,IAAkB,IAA1C,EAAgD;AAC5C4L,QAAAA,cAAc,CAAChB,cAAf,GAAgC,MAAI,CAACN,iBAAL,EAAhC;AACA,cAAM4B,UAAU,GAAG,WAAnB;AACA,cAAM;AAAErQ,UAAAA,IAAI,EAAEsQ,mBAAR;AAA6BC,UAAAA,KAAK,EAAEC;AAApC,kBAAmEzT,EAAE,CAAC2S,aAAH,OAAuB,MAAI,CAACvL,SAAL,CAAemJ,UAAf,EAAvB,EAAoD+C,UAApD,CAAzE;AACAZ,QAAAA,kBAAkB,CAACc,KAAnB,CAAyB3P,IAAzB,CAA8B,GAAG4P,oBAAjC;AACAf,QAAAA,kBAAkB,CAACzP,IAAnB,GAA0BjD,EAAE,CAAC0T,uBAAH,CAA2B,CAAChB,kBAAkB,CAACzP,IAApB,EAA0BsQ,mBAA1B,CAA3B,CAA1B;AACH;;AACD,UAAI,MAAI,CAACI,mBAAL,IAA4B,IAAhC,EAAsC;AAClC;AACA,cAAMC,SAAS,GAAG,IAAlB;AACA5S,QAAAA,wBAAwB,CAAC,MAAI,CAAC2S,mBAAN,EAA2B,MAAI,CAAChQ,IAAhC,EAAsCiQ,SAAtC,CAAxB;AACAZ,QAAAA,cAAc,CAACW,mBAAf,GAAqC,MAAI,CAACA,mBAA1C;AACH;;AACDX,MAAAA,cAAc,CAACa,UAAf,GAA4BnB,kBAAkB,CAACzP,IAA/C;AACA+P,MAAAA,cAAc,CAACc,WAAf,GAA6BpB,kBAAkB,CAACc,KAAhD;AACA,aAAOjB,YAAY,CAACD,IAAb,CAAkBU,cAAlB,CAAP;AA1C6B;AA2ChC;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;;;AACIe,EAAAA,sBAAsB,CAACJ,mBAAD,EAAsB;AACxC3S,IAAAA,wBAAwB,CAAC2S,mBAAD,EAAsB,KAAKhQ,IAA3B,CAAxB;AACA,SAAKgQ,mBAAL,GAA2BA,mBAA3B;AACH;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACIK,EAAAA,sBAAsB,GAAG;AACrB,WAAO,KAAKL,mBAAZ;AACH;;AAptCsC,C,CAstC3C;AACA;;AACA;;AACAnN,WAAW,CAACyN,SAAZ,GAAwB,OAAxB;AACA9T,aAAa,CAAC+T,aAAd,CAA4B1N,WAA5B;AACA;AACA;AACA;AACA;AACA;AACA;;AACA;;AACA,OAAO,MAAM2N,UAAN,SAAyB3N,WAAzB,CAAqC;AAE5C2N,UAAU,CAACF,SAAX,GAAuB,YAAvB;AACA9T,aAAa,CAAC+T,aAAd,CAA4BC,UAA5B","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/* Original Source: engine/training.py */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { io, Optimizer, scalar, serialization, Tensor, tensor1d, util } from '@tensorflow/tfjs-core';\nimport * as K from '../backend/tfjs_backend';\nimport { nameScope } from '../common';\nimport { NotImplementedError, RuntimeError, ValueError } from '../errors';\nimport { deserialize } from '../layers/serialization';\nimport * as losses from '../losses';\nimport * as Metrics from '../metrics';\nimport * as optimizers from '../optimizers';\nimport { checkUserDefinedMetadata } from '../user_defined_metadata';\nimport { count, pyListRepeat, singletonOrArray, toCamelCase, toSnakeCase, unique } from '../utils/generic_utils';\nimport { printSummary } from '../utils/layer_utils';\nimport { range } from '../utils/math_utils';\nimport { convertPythonicToTs } from '../utils/serialization_utils';\nimport { version } from '../version';\nimport { Container } from './container';\nimport { execute, FeedDict } from './executor';\nimport { evaluateDataset, fitDataset } from './training_dataset';\nimport { checkBatchSize, disposeNewTensors, ensureTensorsRank2OrHigher, fitTensors, makeBatches, sliceArrays, sliceArraysByIndices } from './training_tensors';\nimport { computeWeightedLoss, standardizeClassWeights, standardizeWeights } from './training_utils';\n/**\n * Helper function for polymorphic input data: 1. singleton Tensor.\n */\nexport function isDataTensor(x) {\n    return x instanceof Tensor;\n}\n/**\n * Helper function for polymorphic input data: 2. Array of Tensor.\n */\nexport function isDataArray(x) {\n    return Array.isArray(x);\n}\n/**\n * Helper function for polymorphic input data: 3. \"dict\" of Tensor.\n */\nexport function isDataDict(x) {\n    return !isDataTensor(x) && !isDataArray(x);\n}\n/**\n * Normalizes inputs and targets provided by users.\n * @param data User-provided input data (polymorphic).\n * @param names An Array of expected Tensor names.\n * @param shapes Optional Array of expected Tensor shapes.\n * @param checkBatchAxis Whether to check that the batch axis of the arrays\n *   match  the expected value found in `shapes`.\n * @param exceptionPrefix String prefix used for exception formatting.\n * @returns List of standardized input Tensors (one Tensor per model input).\n * @throws ValueError: in case of improperly formatted user data.\n */\nexport function standardizeInputData(data, names, shapes, checkBatchAxis = true, exceptionPrefix = '') {\n    if (names == null || names.length === 0) {\n        // Check for the case where the model expected no data, but some data got\n        // sent.\n        if (data != null) {\n            let gotUnexpectedData = false;\n            if (isDataArray(data) && data.length > 0) {\n                gotUnexpectedData = true;\n            }\n            else if (isDataDict(data)) {\n                for (const key in data) {\n                    if (data.hasOwnProperty(key)) {\n                        gotUnexpectedData = true;\n                        break;\n                    }\n                }\n            }\n            else {\n                // `data` is a singleton Tensor in this case.\n                gotUnexpectedData = true;\n            }\n            if (gotUnexpectedData) {\n                throw new ValueError(`Error when checking model ${exceptionPrefix} expected no data, ` +\n                    `but got ${data}`);\n            }\n        }\n        return [];\n    }\n    if (data == null) {\n        return names.map(name => null);\n    }\n    let arrays;\n    if (isDataDict(data)) {\n        data = data;\n        arrays = [];\n        for (const name of names) {\n            if (data[name] == null) {\n                throw new ValueError(`No data provided for \"${name}\". Need data for each key in: ` +\n                    `${names}`);\n            }\n            arrays.push(data[name]);\n        }\n    }\n    else if (isDataArray(data)) {\n        data = data;\n        if (data.length !== names.length) {\n            throw new ValueError(`Error when checking model ${exceptionPrefix}: the Array of ` +\n                `Tensors that you are passing to your model is not the size the ` +\n                `model expected. Expected to see ${names.length} Tensor(s), but ` +\n                `instead got the following list of Tensor(s): ${data}`);\n        }\n        arrays = data;\n    }\n    else {\n        data = data;\n        if (names.length > 1) {\n            throw new ValueError(`The model ${exceptionPrefix} expects ${names.length} Tensor(s), ` +\n                `but only received one Tensor. Found: Tensor with shape ${data.shape}`);\n        }\n        arrays = [data];\n    }\n    arrays = ensureTensorsRank2OrHigher(arrays);\n    // Check shape compatibility.\n    if (shapes != null) {\n        for (let i = 0; i < names.length; ++i) {\n            if (shapes[i] == null) {\n                continue;\n            }\n            const array = arrays[i];\n            if (array.shape.length !== shapes[i].length) {\n                throw new ValueError(`Error when checking ${exceptionPrefix}: expected ${names[i]} ` +\n                    `to have ${shapes[i].length} dimension(s). but got array with ` +\n                    `shape ${array.shape}`);\n            }\n            for (let j = 0; j < shapes[i].length; ++j) {\n                if (j === 0 && !checkBatchAxis) {\n                    // Skip the first (batch) axis.\n                    continue;\n                }\n                const dim = array.shape[j];\n                const refDim = shapes[i][j];\n                if (refDim != null && refDim >= 0 && dim !== refDim) {\n                    throw new ValueError(`Error when checking ${exceptionPrefix}: expected ${names[i]} ` +\n                        `to have shape [${shapes[i]}], but got array with shape ` +\n                        `[${array.shape}].`);\n                }\n            }\n        }\n    }\n    return arrays;\n}\n/**\n * User input validation for Tensors.\n * @param inputs `Array` of `tf.Tensor`s for inputs.\n * @param targets `Array` of `tf.Tensor`s for targets.\n * @param weights Optional `Array` of `tf.Tensor`s for sample weights.\n * @throws ValueError: in case of incorrectly formatted data.\n */\nexport function checkArrayLengths(inputs, targets, weights) {\n    const setX = unique(inputs.map(input => input.shape[0]));\n    setX.sort();\n    const setY = unique(targets.map(target => target.shape[0]));\n    setY.sort();\n    // TODO(cais): Check `weights` as well.\n    if (setX.length > 1) {\n        throw new ValueError(`All input Tensors (x) should have the same number of samples. ` +\n            `Got array shapes: ` +\n            `${JSON.stringify(inputs.map(input => input.shape))}`);\n    }\n    if (setY.length > 1) {\n        throw new ValueError(`All target Tensors (y) should have the same number of samples. ` +\n            `Got array shapes: ` +\n            `${JSON.stringify(targets.map(target => target.shape))}`);\n    }\n    if (setX.length > 0 && setY.length > 0 && !util.arraysEqual(setX, setY)) {\n        throw new ValueError(`Input Tensors should have the same number of samples as target ` +\n            `Tensors. Found ${setX[0]} input sample(s) and ${setY[0]} target ` +\n            `sample(s).`);\n    }\n}\n/**\n * Validation on the compatibility of targes and loss functions.\n *\n * This helps prevent users from using loss functions incorrectly.\n *\n * @param targets `Array` of `tf.Tensor`s of targets.\n * @param lossFns `Array` of loss functions.\n * @param outputShapes `Array` of shapes of model outputs.\n */\nfunction checkLossAndTargetCompatibility(targets, lossFns, outputShapes) {\n    // TODO(cais): Dedicated test coverage?\n    const keyLosses = [\n        losses.meanSquaredError, losses.binaryCrossentropy,\n        losses.categoricalCrossentropy\n    ];\n    for (let i = 0; i < targets.length; ++i) {\n        const y = targets[i];\n        const loss = lossFns[i];\n        const shape = outputShapes[i];\n        if (loss == null) {\n            continue;\n        }\n        if (loss === losses.categoricalCrossentropy) {\n            if (y.shape[y.shape.length - 1] === 1) {\n                throw new ValueError(`You are passing a target array of shape ${y.shape} while using ` +\n                    `a loss 'categorical_crossentropy'. 'categorical_crossentropy'` +\n                    `expects targets to be binary matrices (1s and 0s) of shape ` +\n                    `[samples, classes].`);\n                // TODO(cais): Example code in error message.\n            }\n        }\n        if (keyLosses.indexOf(loss) !== -1) {\n            const slicedYShape = y.shape.slice(1);\n            const slicedShape = shape.slice(1);\n            for (let j = 0; j < slicedYShape.length; ++j) {\n                const targetDim = slicedYShape[j];\n                const outDim = slicedShape[j];\n                if (outDim != null && targetDim !== outDim) {\n                    throw new ValueError(`A target Tensor with shape ${y.shape} was passed for an ` +\n                        `output of shape ${shape}, while using a loss function that ` +\n                        `expects targets to have the same shape as the output.`);\n                }\n            }\n        }\n    }\n}\n/**\n * Check inputs provided by the user.\n *\n * Porting Note: This corresponds to _standardize_input_data() in Python\n *   Keras. Because of the strong typing in TF.js, we do not need to convert\n *   the data. Specifically:\n *   1) in PyKeras, `data` can be `DataFrame` instances from pandas, for\n *      example. We don't need to worry about that here because there is no\n *      widely popular javascript/typesdcript equivalent of pandas (so far).\n *      If one becomes available in the future, we can add support.\n *   2) in PyKeras, inputs can be Python dict. But here we are stipulating\n * that the data is either a single `tf.Tensor` or an Array of `tf.Tensor`s. We\n * may add support for `Object` data inputs in the future when the need\n * arises.\n *\n * Instead, we perform basic checks for number of parameters and shapes.\n *\n * @param data: The input data.\n * @param names: Name for the inputs, from the model.\n * @param shapes: Expected shapes for the input data, from the model.\n * @param checkBatchAxis: Whether the size along the batch axis (i.e., the\n *   first dimension) will be checked for matching.\n * @param exceptionPrefix: Execption prefix message, used in generating error\n *   messages.\n * @throws ValueError: on incorrect number of inputs or mismatches in shapes.\n */\nfunction checkInputData(data, names, shapes, checkBatchAxis = true, exceptionPrefix = '') {\n    let arrays;\n    if (Array.isArray(data)) {\n        if (data.length !== names.length) {\n            throw new ValueError(`Error when checking model ${exceptionPrefix}: the Array of ` +\n                `Tensors that you are passing to your model is not the size the ` +\n                `the model expected. Expected to see ${names.length} Tensor(s),` +\n                ` but instead got ${data.length} Tensors(s).`);\n        }\n        arrays = data;\n    }\n    else {\n        if (names.length > 1) {\n            throw new ValueError(`The model expects ${names.length} ${exceptionPrefix} Tensors, ` +\n                `but only received one Tensor. Found: array with shape ` +\n                `${JSON.stringify(data.shape)}.`);\n        }\n        arrays = [data];\n    }\n    if (shapes != null) {\n        for (let i = 0; i < names.length; ++i) {\n            if (shapes[i] == null) {\n                continue;\n            }\n            const array = arrays[i];\n            if (array.shape.length !== shapes[i].length) {\n                throw new ValueError(`Error when checking ${exceptionPrefix}: expected ${names[i]} ` +\n                    `to have ${shapes[i].length} dimension(s), but got array with ` +\n                    `shape ${JSON.stringify(array.shape)}`);\n            }\n            for (let j = 0; j < shapes[i].length; ++j) {\n                if (j === 0 && !checkBatchAxis) {\n                    continue;\n                }\n                const dim = array.shape[j];\n                const refDim = shapes[i][j];\n                if (refDim != null) {\n                    if (refDim !== dim) {\n                        throw new ValueError(`Error when checking ${exceptionPrefix}: expected ` +\n                            `${names[i]} to have shape ${JSON.stringify(shapes[i])} but ` +\n                            `got array with shape ${JSON.stringify(array.shape)}.`);\n                    }\n                }\n            }\n        }\n    }\n}\n/**\n * Maps metric functions to model outputs.\n * @param metrics An shortcut strings name, metric function, `Array` or dict\n *   (`Object`) of metric functions.\n * @param outputNames An `Array` of the names of model outputs.\n * @returns An `Array` (one entry per model output) of `Array` of metric\n *   functions. For instance, if the model has 2 outputs, and for the first\n *   output we want to compute `binaryAccuracy` and `binaryCrossentropy`,\n *   and just `binaryAccuracy` for the second output, the `Array` would look\n *   like:\n *     `[[binaryAccuracy, binaryCrossentropy],  [binaryAccuracy]]`\n * @throws TypeError: incompatible metrics format.\n */\nexport function collectMetrics(metrics, outputNames) {\n    if (metrics == null || Array.isArray(metrics) && metrics.length === 0) {\n        return outputNames.map(name => []);\n    }\n    let wrappedMetrics;\n    if (typeof metrics === 'string' || typeof metrics === 'function') {\n        wrappedMetrics = [metrics];\n    }\n    else if (Array.isArray(metrics) || typeof metrics === 'object') {\n        wrappedMetrics = metrics;\n    }\n    else {\n        throw new TypeError('Type of metrics argument not understood. Expected an string,' +\n            `function, Array, or Object, found: ${metrics}`);\n    }\n    if (Array.isArray(wrappedMetrics)) {\n        // We then apply all metrics to all outputs.\n        return outputNames.map(name => wrappedMetrics);\n    }\n    else {\n        // In this case, metrics is a dict.\n        const nestedMetrics = [];\n        for (const name of outputNames) {\n            let outputMetrics = wrappedMetrics.hasOwnProperty(name) ? wrappedMetrics[name] : [];\n            if (!Array.isArray(outputMetrics)) {\n                outputMetrics = [outputMetrics];\n            }\n            nestedMetrics.push(outputMetrics);\n        }\n        return nestedMetrics;\n    }\n}\nconst LAYERS_MODEL_FORMAT_NAME = 'layers-model';\n/**\n * A `tf.LayersModel` is a directed, acyclic graph of `tf.Layer`s plus methods\n * for training, evaluation, prediction and saving.\n *\n * `tf.LayersModel` is the basic unit of training, inference and evaluation in\n * TensorFlow.js. To create a `tf.LayersModel`, use `tf.LayersModel`.\n *\n * See also:\n *   `tf.Sequential`, `tf.loadLayersModel`.\n *\n * @doc {heading: 'Models', subheading: 'Classes'}\n */\nexport class LayersModel extends Container {\n    constructor(args) {\n        super(args);\n        this.isTraining = false;\n    }\n    /**\n     * Print a text summary of the model's layers.\n     *\n     * The summary includes\n     * - Name and type of all layers that comprise the model.\n     * - Output shape(s) of the layers\n     * - Number of weight parameters of each layer\n     * - If the model has non-sequential-like topology, the inputs each layer\n     *   receives\n     * - The total number of trainable and non-trainable parameters of the model.\n     *\n     * ```js\n     * const input1 = tf.input({shape: [10]});\n     * const input2 = tf.input({shape: [20]});\n     * const dense1 = tf.layers.dense({units: 4}).apply(input1);\n     * const dense2 = tf.layers.dense({units: 8}).apply(input2);\n     * const concat = tf.layers.concatenate().apply([dense1, dense2]);\n     * const output =\n     *     tf.layers.dense({units: 3, activation: 'softmax'}).apply(concat);\n     *\n     * const model = tf.model({inputs: [input1, input2], outputs: output});\n     * model.summary();\n     * ```\n     *\n     * @param lineLength Custom line length, in number of characters.\n     * @param positions Custom widths of each of the columns, as either\n     *   fractions of `lineLength` (e.g., `[0.5, 0.75, 1]`) or absolute number\n     *   of characters (e.g., `[30, 50, 65]`). Each number corresponds to\n     *   right-most (i.e., ending) position of a column.\n     * @param printFn Custom print function. Can be used to replace the default\n     *   `console.log`. For example, you can use `x => {}` to mute the printed\n     *   messages in the console.\n     *\n     * @doc {heading: 'Models', subheading: 'Classes'}\n     */\n    summary(lineLength, positions, printFn = console.log) {\n        if (!this.built) {\n            throw new ValueError(`This model has never been called, thus its weights have not been ` +\n                `created yet. So no summary can be displayed. Build the model ` +\n                `first (e.g., by calling it on some test data).`);\n        }\n        printSummary(this, lineLength, positions, printFn);\n    }\n    /**\n     * Configures and prepares the model for training and evaluation.  Compiling\n     * outfits the model with an optimizer, loss, and/or metrics.  Calling `fit`\n     * or `evaluate` on an un-compiled model will throw an error.\n     *\n     * @param args a `ModelCompileArgs` specifying the loss, optimizer, and\n     * metrics to be used for fitting and evaluating this model.\n     *\n     * @doc {heading: 'Models', subheading: 'Classes'}\n     */\n    compile(args) {\n        if (args.loss == null) {\n            args.loss = [];\n        }\n        this.loss = args.loss;\n        if (typeof args.optimizer === 'string') {\n            this.optimizer_ = optimizers.getOptimizer(args.optimizer);\n            this.isOptimizerOwned = true;\n        }\n        else {\n            if (!(args.optimizer instanceof Optimizer)) {\n                throw new ValueError(`User-defined optimizer must be an instance of tf.Optimizer.`);\n            }\n            this.optimizer_ = args.optimizer;\n            this.isOptimizerOwned = false;\n        }\n        // TODO(cais): Add lossWeights.\n        // TODO(cais): Add sampleWeightMode.\n        // Prepare loss functions.\n        let lossFunctions = [];\n        if (!Array.isArray(args.loss) && typeof args.loss !== 'string' &&\n            typeof args.loss !== 'function') {\n            args.loss = args.loss;\n            for (const name in args.loss) {\n                if (this.outputNames.indexOf(name) === -1) {\n                    throw new ValueError(`Unknown entry in loss dictionary: \"${name}\". ` +\n                        `Only expected the following keys: ${this.outputNames}`);\n                }\n            }\n            for (const name of this.outputNames) {\n                if (args.loss[name] == null) {\n                    console.warn(`Output \"${name}\" is missing from loss dictionary. We assume ` +\n                        `this was done on purpose, and we will not be expecting data ` +\n                        `to be passed to ${name} during training`);\n                }\n                lossFunctions.push(losses.get(args.loss[name]));\n            }\n        }\n        else if (Array.isArray(args.loss)) {\n            if (args.loss.length !== this.outputs.length) {\n                throw new ValueError(`When passing an Array as loss, it should have one entry per ` +\n                    `model output. The model has ${this.outputs.length} output(s), ` +\n                    `but you passed loss=${args.loss}.`);\n            }\n            const theLosses = args.loss;\n            lossFunctions = theLosses.map(l => losses.get(l));\n        }\n        else {\n            const lossFunction = losses.get(args.loss);\n            this.outputs.forEach(_ => {\n                lossFunctions.push(lossFunction);\n            });\n        }\n        this.lossFunctions = lossFunctions;\n        this.feedOutputNames = [];\n        this.feedOutputShapes = [];\n        this.feedLossFns = [];\n        for (let i = 0; i < this.outputs.length; ++i) {\n            // TODO(cais): Logic for skipping target(s).\n            const shape = this.internalOutputShapes[i];\n            const name = this.outputNames[i];\n            this.feedOutputNames.push(name);\n            this.feedOutputShapes.push(shape);\n            this.feedLossFns.push(this.lossFunctions[i]);\n        }\n        // TODO(cais): Add logic for output masks.\n        // TODO(cais): Add logic for sample weights.\n        const skipTargetIndices = [];\n        // Prepare metrics.\n        this.metrics = args.metrics;\n        // TODO(cais): Add weightedMetrics.\n        this.metricsNames = ['loss'];\n        this.metricsTensors = [];\n        // Compute total loss.\n        // Porting Note: In PyKeras, metrics_tensors are symbolic tensor objects.\n        //   Here, metricsTensors are TypeScript functions. This difference is due\n        //   to the difference in symbolic/imperative property of the backends.\n        nameScope('loss', () => {\n            for (let i = 0; i < this.outputs.length; ++i) {\n                if (skipTargetIndices.indexOf(i) !== -1) {\n                    continue;\n                }\n                // TODO(cais): Add weightedLoss, sampleWeight and mask.\n                //   The following line should be weightedLoss\n                const weightedLoss = this.lossFunctions[i];\n                if (this.outputs.length > 1) {\n                    this.metricsTensors.push([weightedLoss, i]);\n                    this.metricsNames.push(this.outputNames[i] + '_loss');\n                }\n            }\n            // Porting Note: Due to the imperative nature of the backend, we calculate\n            //   the regularizer penalties in the totalLossFunction, instead of here.\n        });\n        const nestedMetrics = collectMetrics(args.metrics, this.outputNames);\n        // TODO(cais): Add nestedWeightedMetrics.\n        /**\n         * Helper function used in loop below.\n         */\n        const appendMetric = (outputIndex, metricName, metricTensor) => {\n            if (this.outputNames.length > 1) {\n                metricName = this.outputNames[outputIndex] + '_' + metricName;\n            }\n            this.metricsNames.push(metricName);\n            this.metricsTensors.push([metricTensor, outputIndex]);\n        };\n        nameScope('metric', () => {\n            for (let i = 0; i < this.outputs.length; ++i) {\n                if (skipTargetIndices.indexOf(i) !== -1) {\n                    continue;\n                }\n                const outputMetrics = nestedMetrics[i];\n                // TODO(cais): Add weights and outputWeightedMetrics.\n                // TODO(cais): Add optional arg `weights` to the following function.\n                const handleMetrics = (metrics) => {\n                    const metricNamePrefix = '';\n                    let metricName;\n                    let accFn;\n                    let weightedMetricFn;\n                    //  TODO(cais): Use 'weights_' for weighted metrics.\n                    for (const metric of metrics) {\n                        if (typeof metric === 'string' &&\n                            ['accuracy', 'acc', 'crossentropy', 'ce'].indexOf(metric) !==\n                                -1) {\n                            const outputShape = this.internalOutputShapes[i];\n                            if (outputShape[outputShape.length - 1] === 1 ||\n                                this.lossFunctions[i] === losses.binaryCrossentropy) {\n                                // case: binary accuracy/crossentropy.\n                                if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                                    accFn = Metrics.binaryAccuracy;\n                                }\n                                else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                                    accFn = Metrics.binaryCrossentropy;\n                                }\n                            }\n                            else if (this.lossFunctions[i] ===\n                                losses.sparseCategoricalCrossentropy) {\n                                // case: categorical accuracy / crossentropy with sparse\n                                // targets.\n                                if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                                    accFn = Metrics.sparseCategoricalAccuracy;\n                                }\n                                else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                                    accFn = Metrics.sparseCategoricalCrossentropy;\n                                }\n                            }\n                            else {\n                                // case: categorical accuracy / crossentropy.\n                                if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                                    accFn = Metrics.categoricalAccuracy;\n                                }\n                                else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                                    accFn = Metrics.categoricalCrossentropy;\n                                }\n                            }\n                            let suffix;\n                            if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                                suffix = 'acc';\n                            }\n                            else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                                suffix = 'ce';\n                            }\n                            // TODO(cais): Add weighting actually.\n                            weightedMetricFn = accFn;\n                            metricName = metricNamePrefix + suffix;\n                        }\n                        else {\n                            const metricFn = Metrics.get(metric);\n                            // TODO(cais): Add weighting actually.\n                            weightedMetricFn = metricFn;\n                            metricName =\n                                metricNamePrefix + Metrics.getLossOrMetricName(metric);\n                        }\n                        // TODO(cais): Add weighting and masking to metricResult.\n                        let metricResult;\n                        nameScope(metricName, () => {\n                            metricResult = weightedMetricFn;\n                        });\n                        appendMetric(i, metricName, metricResult);\n                    }\n                };\n                handleMetrics(outputMetrics);\n                // TODO(cais): Call handleMetrics with weights.\n            }\n        });\n        // Porting Notes: Given the imperative backend of tfjs-core,\n        //   there is no need for constructing the symbolic graph and placeholders.\n        this.collectedTrainableWeights = this.trainableWeights;\n    }\n    /**\n     * Check trainable weights count consistency.\n     *\n     * This will raise a warning if `this.trainableWeights` and\n     * `this.collectedTrainableWeights` are inconsistent (i.e., have different\n     * numbers of parameters).\n     * Inconsistency will typically arise when one modifies `model.trainable`\n     * without calling `model.compile()` again.\n     */\n    checkTrainableWeightsConsistency() {\n        if (this.collectedTrainableWeights == null) {\n            return;\n        }\n        if (this.trainableWeights.length !==\n            this.collectedTrainableWeights.length) {\n            console.warn('Discrepancy between trainableweights and collected trainable ' +\n                'weights. Did you set `model.trainable` without calling ' +\n                '`model.compile()` afterwards?');\n        }\n    }\n    /**\n     * Returns the loss value & metrics values for the model in test mode.\n     *\n     * Loss and metrics are specified during `compile()`, which needs to happen\n     * before calls to `evaluate()`.\n     *\n     * Computation is done in batches.\n     *\n     * ```js\n     * const model = tf.sequential({\n     *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]\n     * });\n     * model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});\n     * const result = model.evaluate(\n     *     tf.ones([8, 10]), tf.ones([8, 1]), {batchSize: 4});\n     * result.print();\n     * ```\n     *\n     * @param x `tf.Tensor` of test data, or an `Array` of `tf.Tensor`s if the\n     * model has multiple inputs.\n     * @param y `tf.Tensor` of target data, or an `Array` of `tf.Tensor`s if the\n     * model has multiple outputs.\n     * @param args A `ModelEvaluateArgs`, containing optional fields.\n     *\n     * @return `Scalar` test loss (if the model has a single output and no\n     *   metrics) or `Array` of `Scalar`s (if the model has multiple outputs\n     *   and/or metrics). The attribute `model.metricsNames`\n     *   will give you the display labels for the scalar outputs.\n     *\n     * @doc {heading: 'Models', subheading: 'Classes'}\n     */\n    evaluate(x, y, args = {}) {\n        const batchSize = args.batchSize == null ? 32 : args.batchSize;\n        checkBatchSize(batchSize);\n        // TODO(cais): Standardize `config.sampleWeights` as well.\n        // Validate user data.\n        const checkBatchAxis = true;\n        const standardizedOuts = this.standardizeUserDataXY(x, y, checkBatchAxis, batchSize);\n        try {\n            // TODO(cais): If uses `useLearningPhase`, set the corresponding element\n            // of the input to 0.\n            const ins = standardizedOuts[0].concat(standardizedOuts[1]);\n            this.makeTestFunction();\n            const f = this.testFunction;\n            const testOuts = this.testLoop(f, ins, batchSize, args.verbose, args.steps);\n            return singletonOrArray(testOuts);\n        }\n        finally {\n            disposeNewTensors(standardizedOuts[0], x);\n            disposeNewTensors(standardizedOuts[1], y);\n        }\n    }\n    // TODO(cais): Add code snippet below once real dataset objects are\n    //   available.\n    /**\n     * Evaluate model using a dataset object.\n     *\n     * Note: Unlike `evaluate()`, this method is asynchronous (`async`);\n     *\n     * @param dataset A dataset object. Its `iterator()` method is expected\n     *   to generate a dataset iterator object, the `next()` method of which\n     *   is expected to produce data batches for evaluation. The return value\n     *   of the `next()` call ought to contain a boolean `done` field and a\n     *   `value` field. The `value` field is expected to be an array of two\n     *   `tf.Tensor`s or an array of two nested `tf.Tensor` structures. The former\n     *   case is for models with exactly one input and one output (e.g..\n     *   a sequential model). The latter case is for models with multiple\n     *   inputs and/or multiple outputs. Of the two items in the array, the\n     *   first is the input feature(s) and the second is the output target(s).\n     * @param args A configuration object for the dataset-based evaluation.\n     * @returns Loss and metric values as an Array of `Scalar` objects.\n     *\n     * @doc {heading: 'Models', subheading: 'Classes'}\n     */\n    async evaluateDataset(dataset, args) {\n        this.makeTestFunction();\n        return evaluateDataset(this, dataset, args);\n    }\n    /**\n     * Get number of samples provided for training, evaluation or prediction.\n     *\n     * @param ins Input `tf.Tensor`.\n     * @param batchSize Integer batch size, optional.\n     * @param steps Total number of steps (batches of samples) before\n     * declaring loop finished. Optional.\n     * @param stepsName The public API's parameter name for `steps`.\n     * @returns Number of samples provided.\n     */\n    checkNumSamples(ins, batchSize, steps, stepsName = 'steps') {\n        let numSamples;\n        if (steps != null) {\n            numSamples = null;\n            if (batchSize != null) {\n                throw new ValueError(`If ${stepsName} is set, batchSize must be null or undefined.` +\n                    `Got batchSize = ${batchSize}`);\n            }\n        }\n        else if (ins != null) {\n            if (Array.isArray(ins)) {\n                numSamples = ins[0].shape[0];\n            }\n            else {\n                numSamples = ins.shape[0];\n            }\n        }\n        else {\n            throw new ValueError(`Either the input data should have a defined shape, or ` +\n                `${stepsName} shoud be specified.`);\n        }\n        return numSamples;\n    }\n    /**\n     * Execute internal tensors of the model with input data feed.\n     * @param inputs Input data feed. Must match the inputs of the model.\n     * @param outputs Names of the output tensors to be fetched. Must match\n     *   names of the SymbolicTensors that belong to the graph.\n     * @returns Fetched values for `outputs`.\n     */\n    execute(inputs, outputs) {\n        if (Array.isArray(outputs) && outputs.length === 0) {\n            throw new ValueError('`outputs` is an empty Array, which is not allowed.');\n        }\n        const outputsIsArray = Array.isArray(outputs);\n        const outputNames = (outputsIsArray ? outputs : [outputs]);\n        const outputSymbolicTensors = this.retrieveSymbolicTensors(outputNames);\n        // Format the input into a FeedDict.\n        const feedDict = new FeedDict();\n        if (inputs instanceof Tensor) {\n            inputs = [inputs];\n        }\n        if (Array.isArray(inputs)) {\n            if (inputs.length !== this.inputs.length) {\n                throw new ValueError(`The number of inputs provided (${inputs.length}) ` +\n                    `does not match the number of inputs of this model ` +\n                    `(${this.inputs.length}).`);\n            }\n            for (let i = 0; i < this.inputs.length; ++i) {\n                feedDict.add(this.inputs[i], inputs[i]);\n            }\n        }\n        else {\n            for (const input of this.inputs) {\n                const tensorValue = inputs[input.name];\n                if (tensorValue == null) {\n                    throw new ValueError(`No value is provided for the model's input ${input.name}`);\n                }\n                feedDict.add(input, tensorValue);\n            }\n        }\n        // Run execution.\n        const executeOutputs = execute(outputSymbolicTensors, feedDict);\n        return outputsIsArray ? executeOutputs : executeOutputs[0];\n    }\n    /**\n     * Retrieve the model's internal symbolic tensors from symbolic-tensor names.\n     */\n    retrieveSymbolicTensors(symbolicTensorNames) {\n        const outputSymbolicTensors = pyListRepeat(null, symbolicTensorNames.length);\n        let outputsRemaining = symbolicTensorNames.length;\n        for (const layer of this.layers) {\n            const layerOutputs = Array.isArray(layer.output) ? layer.output : [layer.output];\n            const layerOutputNames = layerOutputs.map(output => output.name);\n            for (let i = 0; i < symbolicTensorNames.length; ++i) {\n                const index = layerOutputNames.indexOf(symbolicTensorNames[i]);\n                if (index !== -1) {\n                    outputSymbolicTensors[i] = layerOutputs[index];\n                    outputsRemaining--;\n                }\n                if (outputsRemaining === 0) {\n                    break;\n                }\n            }\n            if (outputsRemaining === 0) {\n                break;\n            }\n        }\n        if (outputsRemaining > 0) {\n            const remainingNames = [];\n            outputSymbolicTensors.forEach((tensor, i) => {\n                if (tensor == null) {\n                    remainingNames.push(symbolicTensorNames[i]);\n                }\n            });\n            throw new ValueError(`Cannot find SymbolicTensors for output name(s): ` +\n                `${JSON.stringify(remainingNames)}`);\n        }\n        return outputSymbolicTensors;\n    }\n    /**\n     * Helper method to loop over some data in batches.\n     *\n     * Porting Note: Not using the functional approach in the Python equivalent\n     *   due to the imperative backend.\n     * Porting Note: Does not support step mode currently.\n     *\n     * @param ins: input data\n     * @param batchSize: integer batch size.\n     * @param verbose: verbosity model\n     * @returns: Predictions as `tf.Tensor` (if a single output) or an `Array` of\n     *   `tf.Tensor` (if multipe outputs).\n     */\n    predictLoop(ins, batchSize = 32, verbose = false) {\n        return tfc.tidy(() => {\n            const numSamples = this.checkNumSamples(ins);\n            if (verbose) {\n                throw new NotImplementedError('Verbose predictLoop() is not implemented yet.');\n            }\n            // Sample-based predictions.\n            // Porting Note: Tensor currently does not support sliced assignments as\n            //   in numpy, e.g., x[1:3] = y. Therefore we use concatenation while\n            //   iterating over the batches.\n            const batches = makeBatches(numSamples, batchSize);\n            const outsBatches = this.outputs.map(output => []);\n            // TODO(cais): Can the scope() be pushed down inside the for loop?\n            for (let batchIndex = 0; batchIndex < batches.length; ++batchIndex) {\n                const batchOuts = tfc.tidy(() => {\n                    const batchStart = batches[batchIndex][0];\n                    const batchEnd = batches[batchIndex][1];\n                    // TODO(cais): Take care of the case of the last element is a flag for\n                    //   training/test.\n                    const insBatch = sliceArrays(ins, batchStart, batchEnd);\n                    // Construct the feeds for execute();\n                    const feeds = [];\n                    if (Array.isArray(insBatch)) {\n                        for (let i = 0; i < insBatch.length; ++i) {\n                            feeds.push({ key: this.inputs[i], value: insBatch[i] });\n                        }\n                    }\n                    else {\n                        feeds.push({ key: this.inputs[0], value: insBatch });\n                    }\n                    const feedDict = new FeedDict(feeds);\n                    return execute(this.outputs, feedDict);\n                });\n                batchOuts.forEach((batchOut, i) => outsBatches[i].push(batchOut));\n            }\n            return singletonOrArray(outsBatches.map(batches => tfc.concat(batches, 0)));\n        });\n    }\n    /**\n     * Generates output predictions for the input samples.\n     *\n     * Computation is done in batches.\n     *\n     * Note: the \"step\" mode of predict() is currently not supported.\n     *   This is because the TensorFlow.js core backend is imperative only.\n     *\n     * ```js\n     * const model = tf.sequential({\n     *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]\n     * });\n     * model.predict(tf.ones([8, 10]), {batchSize: 4}).print();\n     * ```\n     *\n     * @param x The input data, as a Tensor, or an `Array` of `tf.Tensor`s if\n     *   the model has multiple inputs.\n     * @param args A `ModelPredictArgs` object containing optional fields.\n     *\n     * @return Prediction results as a `tf.Tensor`(s).\n     *\n     * @exception ValueError In case of mismatch between the provided input data\n     *   and the model's expectations, or in case a stateful model receives a\n     *   number of samples that is not a multiple of the batch size.\n     *\n     * @doc {heading: 'Models', subheading: 'Classes'}\n     */\n    predict(x, args = {}) {\n        const xsRank2OrHigher = ensureTensorsRank2OrHigher(x);\n        checkInputData(xsRank2OrHigher, this.inputNames, this.feedInputShapes, false);\n        try {\n            // TODO(cais): Take care of stateful models.\n            //   if (this.stateful) ...\n            // TODO(cais): Take care of the learning_phase boolean flag.\n            //   if (this.useLearningPhase) ...\n            const batchSize = args.batchSize == null ? 32 : args.batchSize;\n            checkBatchSize(batchSize);\n            return this.predictLoop(xsRank2OrHigher, batchSize);\n        }\n        finally {\n            disposeNewTensors(xsRank2OrHigher, x);\n        }\n    }\n    /**\n     * Returns predictions for a single batch of samples.\n     *\n     * ```js\n     * const model = tf.sequential({\n     *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]\n     * });\n     * model.predictOnBatch(tf.ones([8, 10])).print();\n     * ```\n     * @param x: Input samples, as a Tensor (for models with exactly one\n     *   input) or an array of Tensors (for models with more than one input).\n     * @return Tensor(s) of predictions\n     *\n     * @doc {heading: 'Models', subheading: 'Classes'}\n     */\n    predictOnBatch(x) {\n        checkInputData(x, this.inputNames, this.feedInputShapes, true);\n        // TODO(cais): Take care of the learning_phase boolean flag.\n        //   if (this.useLearningPhase) ...\n        const batchSize = (Array.isArray(x) ? x[0] : x).shape[0];\n        return this.predictLoop(x, batchSize);\n    }\n    standardizeUserDataXY(x, y, checkBatchAxis = true, batchSize) {\n        // TODO(cais): Add sampleWeight, classWeight\n        if (this.optimizer_ == null) {\n            throw new RuntimeError('You must compile a model before training/testing. Use ' +\n                'LayersModel.compile(modelCompileArgs).');\n        }\n        const outputShapes = [];\n        for (let i = 0; i < this.feedOutputShapes.length; ++i) {\n            const outputShape = this.feedOutputShapes[i];\n            const lossFn = this.feedLossFns[i];\n            if (lossFn === losses.sparseCategoricalCrossentropy) {\n                outputShapes.push(outputShape.slice(0, outputShape.length - 1).concat([1]));\n            }\n            else {\n                // Porting Note: Because of strong typing `lossFn` must be a function.\n                outputShapes.push(outputShape);\n            }\n        }\n        x = standardizeInputData(x, this.feedInputNames, this.feedInputShapes, false, 'input');\n        y = standardizeInputData(y, this.feedOutputNames, outputShapes, false, 'target');\n        // TODO(cais): Standardize sampleWeights & classWeights.\n        checkArrayLengths(x, y, null);\n        // TODO(cais): Check sampleWeights as well.\n        checkLossAndTargetCompatibility(y, this.feedLossFns, this.feedOutputShapes);\n        if (this.stateful && batchSize != null && batchSize > 0) {\n            if (x[0].shape[0] % batchSize !== 0) {\n                throw new ValueError(`In a stateful network, you should only pass inputs with a ` +\n                    `number of samples that is divisible by the batch size ` +\n                    `${batchSize}. Found: ${x[0].shape[0]} sample(s).`);\n            }\n        }\n        return [x, y];\n    }\n    async standardizeUserData(x, y, sampleWeight, classWeight, checkBatchAxis = true, batchSize) {\n        const [standardXs, standardYs] = this.standardizeUserDataXY(x, y, checkBatchAxis, batchSize);\n        // TODO(cais): Handle sampleWeights.\n        if (sampleWeight != null) {\n            throw new Error('sample weight is not supported yet.');\n        }\n        let standardSampleWeights = null;\n        if (classWeight != null) {\n            const classWeights = standardizeClassWeights(classWeight, this.outputNames);\n            standardSampleWeights = [];\n            for (let i = 0; i < classWeights.length; ++i) {\n                standardSampleWeights.push(await standardizeWeights(standardYs[i], null, classWeights[i]));\n            }\n        }\n        // TODO(cais): Deal with the case of model.stateful == true.\n        return [standardXs, standardYs, standardSampleWeights];\n    }\n    /**\n     * Loop over some test data in batches.\n     * @param f A Function returning a list of tensors.\n     * @param ins Array of tensors to be fed to `f`.\n     * @param batchSize Integer batch size or `null` / `undefined`.\n     * @param verbose verbosity mode.\n     * @param steps Total number of steps (batches of samples) before\n     * declaring test finished. Ignored with the default value of `null` /\n     * `undefined`.\n     * @returns Array of Scalars.\n     */\n    testLoop(f, ins, batchSize, verbose = 0, steps) {\n        return tfc.tidy(() => {\n            const numSamples = this.checkNumSamples(ins, batchSize, steps, 'steps');\n            const outs = [];\n            if (verbose > 0) {\n                throw new NotImplementedError('Verbose mode is not implemented yet.');\n            }\n            // TODO(cais): Use `indicesForConversionToDense' to prevent slow down.\n            if (steps != null) {\n                throw new NotImplementedError('steps mode in testLoop() is not implemented yet');\n            }\n            else {\n                const batches = makeBatches(numSamples, batchSize);\n                const indexArray = tensor1d(range(0, numSamples));\n                for (let batchIndex = 0; batchIndex < batches.length; ++batchIndex) {\n                    const batchStart = batches[batchIndex][0];\n                    const batchEnd = batches[batchIndex][1];\n                    const batchIds = K.sliceAlongFirstAxis(indexArray, batchStart, batchEnd - batchStart);\n                    // TODO(cais): In ins, train flag can be a number, instead of an\n                    //   Tensor? Do we need to handle this in tfjs-layers?\n                    const insBatch = sliceArraysByIndices(ins, batchIds);\n                    const batchOuts = f(insBatch);\n                    if (batchIndex === 0) {\n                        for (let i = 0; i < batchOuts.length; ++i) {\n                            outs.push(scalar(0));\n                        }\n                    }\n                    for (let i = 0; i < batchOuts.length; ++i) {\n                        const batchOut = batchOuts[i];\n                        outs[i] =\n                            tfc.add(outs[i], tfc.mul(batchEnd - batchStart, batchOut));\n                    }\n                }\n                for (let i = 0; i < outs.length; ++i) {\n                    outs[i] = tfc.div(outs[i], numSamples);\n                }\n            }\n            return outs;\n        });\n    }\n    getDedupedMetricsNames() {\n        const outLabels = this.metricsNames;\n        // Rename duplicated metrics names (can happen with an output layer\n        // shared among multiple dataflows).\n        const dedupedOutLabels = [];\n        for (let i = 0; i < outLabels.length; ++i) {\n            const label = outLabels[i];\n            let newLabel = label;\n            if (count(outLabels, label) > 1) {\n                const dupIndex = count(outLabels.slice(0, i), label);\n                newLabel += `_${dupIndex}`;\n            }\n            dedupedOutLabels.push(newLabel);\n        }\n        return dedupedOutLabels;\n    }\n    /**\n     * Creates a function that performs the following actions:\n     *\n     * 1. computes the losses\n     * 2. sums them to get the total loss\n     * 3. call the optimizer computes the gradients of the LayersModel's\n     *    trainable weights w.r.t. the total loss and update the variables\n     * 4. calculates the metrics\n     * 5. returns the values of the losses and metrics.\n     */\n    makeTrainFunction() {\n        return (data) => {\n            const lossValues = [];\n            const inputs = data.slice(0, this.inputs.length);\n            const targets = data.slice(this.inputs.length, this.inputs.length + this.outputs.length);\n            const sampleWeights = data.slice(this.inputs.length + this.outputs.length, this.inputs.length + this.outputs.length * 2);\n            const metricsValues = [];\n            // Create a function that computes the total loss based on the\n            // inputs. This function is used for obtaining gradients through\n            // backprop.\n            const totalLossFunction = () => {\n                const feeds = [];\n                for (let i = 0; i < this.inputs.length; ++i) {\n                    feeds.push({ key: this.inputs[i], value: inputs[i] });\n                }\n                const feedDict = new FeedDict(feeds);\n                const outputs = execute(this.outputs, feedDict, { 'training': true });\n                // TODO(cais): Take care of the case of multiple outputs from a\n                //   single layer?\n                let totalLoss;\n                for (let i = 0; i < this.lossFunctions.length; ++i) {\n                    const lossFunction = this.lossFunctions[i];\n                    let loss = lossFunction(targets[i], outputs[i]);\n                    if (sampleWeights[i] != null) {\n                        loss = computeWeightedLoss(loss, sampleWeights[i]);\n                    }\n                    // TODO(cais): push Scalar instead.\n                    const meanLoss = tfc.mean(loss);\n                    // TODO(cais): Use a scope() instead, to avoid ownership.\n                    lossValues.push(meanLoss);\n                    if (i === 0) {\n                        totalLoss = loss;\n                    }\n                    else {\n                        totalLoss = tfc.add(totalLoss, loss);\n                    }\n                }\n                // Compute the metrics.\n                // TODO(cais): These should probably be calculated outside\n                //   totalLossFunction to benefit speed?\n                for (let i = 0; i < this.metricsTensors.length; ++i) {\n                    let weightedMetric;\n                    if (this.outputs.length > 1 && i < this.outputs.length) {\n                        weightedMetric = lossValues[i];\n                    }\n                    else {\n                        const metric = this.metricsTensors[i][0];\n                        const outputIndex = this.metricsTensors[i][1];\n                        weightedMetric =\n                            tfc.mean(metric(targets[outputIndex], outputs[outputIndex]));\n                    }\n                    tfc.keep(weightedMetric);\n                    // TODO(cais): Use a scope() instead, to avoid ownership.\n                    metricsValues.push(weightedMetric);\n                }\n                totalLoss = tfc.mean(totalLoss);\n                // Add regularizer penalties.\n                this.calculateLosses().forEach(regularizerLoss => {\n                    totalLoss = tfc.add(totalLoss, regularizerLoss);\n                });\n                return totalLoss;\n            };\n            const variables = this.collectedTrainableWeights.map(param => param.read());\n            const returnCost = true;\n            const totalLossValue = this.optimizer_.minimize(totalLossFunction, returnCost, variables);\n            return [totalLossValue].concat(metricsValues);\n        };\n    }\n    /**\n     * Create a function which, when invoked with an array of `tf.Tensor`s as a\n     * batch of inputs, returns the prespecified loss and metrics of the model\n     * under the batch of input data.\n     */\n    makeTestFunction() {\n        this.testFunction = (data) => {\n            return tfc.tidy(() => {\n                const valOutputs = [];\n                let totalLoss;\n                const inputs = data.slice(0, this.inputs.length);\n                const targets = data.slice(this.inputs.length, this.inputs.length + this.outputs.length);\n                const feeds = [];\n                for (let i = 0; i < this.inputs.length; ++i) {\n                    feeds.push({ key: this.inputs[i], value: inputs[i] });\n                }\n                const feedDict = new FeedDict(feeds);\n                const outputs = execute(this.outputs, feedDict);\n                // Compute total loss.\n                for (let i = 0; i < this.lossFunctions.length; ++i) {\n                    const lossFunction = this.lossFunctions[i];\n                    // TODO(cais): Add sample weighting and replace the simple\n                    // averaging.\n                    const loss = tfc.mean(lossFunction(targets[i], outputs[i]));\n                    if (i === 0) {\n                        totalLoss = loss;\n                    }\n                    else {\n                        totalLoss = tfc.add(totalLoss, loss);\n                    }\n                    valOutputs.push(totalLoss);\n                }\n                // Compute the metrics.\n                for (let i = 0; i < this.metricsTensors.length; ++i) {\n                    const metric = this.metricsTensors[i][0];\n                    const outputIndex = this.metricsTensors[i][1];\n                    // TODO(cais): Replace K.mean() with a proper weighting function.\n                    const meanMetric = tfc.mean(metric(targets[outputIndex], outputs[outputIndex]));\n                    valOutputs.push(meanMetric);\n                }\n                return valOutputs;\n            });\n        };\n    }\n    /**\n     * Trains the model for a fixed number of epochs (iterations on a\n     * dataset).\n     *\n     * ```js\n     * const model = tf.sequential({\n     *     layers: [tf.layers.dense({units: 1, inputShape: [10]})]\n     * });\n     * model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});\n     * for (let i = 1; i < 5 ; ++i) {\n     *   const h = await model.fit(tf.ones([8, 10]), tf.ones([8, 1]), {\n     *       batchSize: 4,\n     *       epochs: 3\n     *   });\n     *   console.log(\"Loss after Epoch \" + i + \" : \" + h.history.loss[0]);\n     * }\n     * ```\n     *\n     * @param x `tf.Tensor` of training data, or an array of `tf.Tensor`s if the\n     * model has multiple inputs. If all inputs in the model are named, you\n     * can also pass a dictionary mapping input names to `tf.Tensor`s.\n     * @param y `tf.Tensor` of target (label) data, or an array of `tf.Tensor`s if\n     * the model has multiple outputs. If all outputs in the model are named,\n     * you can also pass a dictionary mapping output names to `tf.Tensor`s.\n     * @param args A `ModelFitArgs`, containing optional fields.\n     *\n     * @return A `History` instance. Its `history` attribute contains all\n     *   information collected during training.\n     *\n     * @exception ValueError In case of mismatch between the provided input\n     * data and what the model expects.\n     *\n     * @doc {heading: 'Models', subheading: 'Classes'}\n     */\n    async fit(x, y, args = {}) {\n        return fitTensors(this, x, y, args);\n    }\n    // TODO(cais): Add code snippet below when it's possible to instantiate\n    //   actual dataset objects.\n    /**\n     * Trains the model using a dataset object.\n     *\n     * @param dataset A dataset object. Its `iterator()` method is expected\n     *   to generate a dataset iterator object, the `next()` method of which\n     *   is expected to produce data batches for training. The return value\n     *   of the `next()` call ought to contain a boolean `done` field and a\n     *   `value` field. The `value` field is expected to be an array of two\n     *   `tf.Tensor`s or an array of two nested `tf.Tensor` structures. The former\n     *   case is for models with exactly one input and one output (e.g..\n     *   a sequential model). The latter case is for models with multiple\n     *   inputs and/or multiple outputs.\n     *   Of the two items in the array, the first is the input feature(s) and\n     *   the second is the output target(s).\n     * @param args A `ModelFitDatasetArgs`, containing optional fields.\n     *\n     * @return A `History` instance. Its `history` attribute contains all\n     *   information collected during training.\n     *\n     * @doc {heading: 'Models', subheading: 'Classes'}\n     */\n    async fitDataset(dataset, args) {\n        return fitDataset(this, dataset, args);\n    }\n    /**\n     * Runs a single gradient update on a single batch of data.\n     *\n     * This method differs from `fit()` and `fitDataset()` in the following\n     * regards:\n     *   - It operates on exactly one batch of data.\n     *   - It returns only the loss and matric values, instead of\n     *     returning the batch-by-batch loss and metric values.\n     *   - It doesn't support fine-grained options such as verbosity and\n     *     callbacks.\n     *\n     * @param x Input data. It could be one of the following:\n     *   - A `tf.Tensor`, or an Array of `tf.Tensor`s (in case the model has\n     *     multiple inputs).\n     *   - An Object mapping input names to corresponding `tf.Tensor` (if the\n     *     model has named inputs).\n     * @param y Target darta. It could be either a `tf.Tensor` a multiple\n     *   `tf.Tensor`s. It should be consistent with `x`.\n     * @returns Training loss or losses (in case the model has\n     *   multiple outputs), along with metrics (if any), as numbers.\n     *\n     * @doc {heading: 'Models', subheading: 'Classes'}\n     */\n    async trainOnBatch(x, y) {\n        // TODO(cais): Support sampleWeight and classWeight.\n        // TODO(cais): Support Dataset objects.\n        const standardizeOut = await this.standardizeUserData(x, y);\n        const inputs = standardizeOut[0];\n        const targets = standardizeOut[1];\n        const trainFunction = this.makeTrainFunction();\n        const losses = trainFunction(inputs.concat(targets));\n        const lossValues = [];\n        for (const loss of losses) {\n            const v = await loss.data();\n            lossValues.push(v[0]);\n        }\n        tfc.dispose(losses);\n        return singletonOrArray(lossValues);\n    }\n    /**\n     * Extract weight values of the model.\n     *\n     * @param config: An instance of `io.SaveConfig`, which specifies\n     * model-saving options such as whether only trainable weights are to be\n     * saved.\n     * @returns A `NamedTensorMap` mapping original weight names (i.e.,\n     *   non-uniqueified weight names) to their values.\n     */\n    getNamedWeights(config) {\n        const namedWeights = [];\n        const trainableOnly = config != null && config.trainableOnly;\n        const weights = trainableOnly ? this.trainableWeights : this.weights;\n        const weightValues = this.getWeights(trainableOnly);\n        for (let i = 0; i < weights.length; ++i) {\n            if (trainableOnly && !weights[i].trainable) {\n                // Optionally skip non-trainable weights.\n                continue;\n            }\n            namedWeights.push({ name: weights[i].originalName, tensor: weightValues[i] });\n        }\n        return namedWeights;\n    }\n    /**\n     * Setter used for force stopping of LayersModel.fit() (i.e., training).\n     *\n     * Example:\n     *\n     * ```js\n     * const input = tf.input({shape: [10]});\n     * const output = tf.layers.dense({units: 1}).apply(input);\n     * const model = tf.model({inputs: [input], outputs: [output]});\n     * model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});\n     * const xs = tf.ones([8, 10]);\n     * const ys = tf.zeros([8, 1]);\n     *\n     * const history = await model.fit(xs, ys, {\n     *   epochs: 10,\n     *   callbacks: {\n     *     onEpochEnd: async (epoch, logs) => {\n     *       if (epoch === 2) {\n     *         model.stopTraining = true;\n     *       }\n     *     }\n     *   }\n     * });\n     *\n     * // There should be only 3 values in the loss array, instead of 10\n     * values,\n     * // due to the stopping after 3 epochs.\n     * console.log(history.history.loss);\n     * ```\n     */\n    set stopTraining(stop) {\n        this.stopTraining_ = stop;\n    }\n    get stopTraining() {\n        return this.stopTraining_;\n    }\n    get optimizer() {\n        return this.optimizer_;\n    }\n    set optimizer(optimizer) {\n        if (this.optimizer_ !== optimizer) {\n            this.optimizer_ = optimizer;\n            this.isOptimizerOwned = false;\n        }\n    }\n    dispose() {\n        const result = super.dispose();\n        if (result.refCountAfterDispose === 0 && this.optimizer != null &&\n            this.isOptimizerOwned) {\n            const numTensorsBeforeOptmizerDisposal = tfc.memory().numTensors;\n            this.optimizer_.dispose();\n            result.numDisposedVariables +=\n                numTensorsBeforeOptmizerDisposal - tfc.memory().numTensors;\n        }\n        return result;\n    }\n    getLossIdentifiers() {\n        let lossNames;\n        if (typeof this.loss === 'string') {\n            lossNames = toSnakeCase(this.loss);\n        }\n        else if (Array.isArray(this.loss)) {\n            for (const loss of this.loss) {\n                if (typeof loss !== 'string') {\n                    throw new Error('Serialization of non-string loss is not supported.');\n                }\n            }\n            lossNames = this.loss.map(name => toSnakeCase(name));\n        }\n        else {\n            const outputNames = Object.keys(this.loss);\n            lossNames = {};\n            const losses = this.loss;\n            for (const outputName of outputNames) {\n                if (typeof losses[outputName] === 'string') {\n                    lossNames[outputName] =\n                        toSnakeCase(losses[outputName]);\n                }\n                else {\n                    throw new Error('Serialization of non-string loss is not supported.');\n                }\n            }\n        }\n        return lossNames;\n    }\n    getMetricIdentifiers() {\n        if (typeof this.metrics === 'string' ||\n            typeof this.metrics === 'function') {\n            return [toSnakeCase(Metrics.getLossOrMetricName(this.metrics))];\n        }\n        else if (Array.isArray(this.metrics)) {\n            return this.metrics.map(metric => toSnakeCase(Metrics.getLossOrMetricName(metric)));\n        }\n        else {\n            const metricsIdentifiers = {};\n            for (const key in this.metrics) {\n                metricsIdentifiers[key] =\n                    toSnakeCase(Metrics.getLossOrMetricName(this.metrics[key]));\n            }\n            return metricsIdentifiers;\n        }\n    }\n    getTrainingConfig() {\n        return {\n            loss: this.getLossIdentifiers(),\n            metrics: this.getMetricIdentifiers(),\n            optimizer_config: {\n                class_name: this.optimizer.getClassName(),\n                config: this.optimizer.getConfig()\n            }\n        };\n        // TODO(cais): Add weight_metrics when they are supported.\n        // TODO(cais): Add sample_weight_mode when it's supported.\n        // TODO(cais): Add loss_weights when it's supported.\n    }\n    loadTrainingConfig(trainingConfig) {\n        if (trainingConfig.weighted_metrics != null) {\n            throw new Error('Loading weight_metrics is not supported yet.');\n        }\n        if (trainingConfig.loss_weights != null) {\n            throw new Error('Loading loss_weights is not supported yet.');\n        }\n        if (trainingConfig.sample_weight_mode != null) {\n            throw new Error('Loading sample_weight_mode is not supported yet.');\n        }\n        const tsConfig = convertPythonicToTs(trainingConfig.optimizer_config);\n        const optimizer = deserialize(tsConfig);\n        let loss;\n        if (typeof trainingConfig.loss === 'string') {\n            loss = toCamelCase(trainingConfig.loss);\n        }\n        else if (Array.isArray(trainingConfig.loss)) {\n            loss = trainingConfig.loss.map(lossEntry => toCamelCase(lossEntry));\n        }\n        else if (trainingConfig.loss != null) {\n            loss = {};\n            for (const key in trainingConfig.loss) {\n                loss[key] = toCamelCase(trainingConfig.loss[key]);\n            }\n        }\n        let metrics;\n        if (Array.isArray(trainingConfig.metrics)) {\n            metrics = trainingConfig.metrics.map(metric => toCamelCase(metric));\n        }\n        else if (trainingConfig.metrics != null) {\n            metrics = {};\n            for (const key in trainingConfig.metrics) {\n                metrics[key] = toCamelCase(trainingConfig.metrics[key]);\n            }\n        }\n        this.compile({ loss, metrics, optimizer });\n    }\n    /**\n     * Save the configuration and/or weights of the LayersModel.\n     *\n     * An `IOHandler` is an object that has a `save` method of the proper\n     * signature defined. The `save` method manages the storing or\n     * transmission of serialized data (\"artifacts\") that represent the\n     * model's topology and weights onto or via a specific medium, such as\n     * file downloads, local storage, IndexedDB in the web browser and HTTP\n     * requests to a server. TensorFlow.js provides `IOHandler`\n     * implementations for a number of frequently used saving mediums, such as\n     * `tf.io.browserDownloads` and `tf.io.browserLocalStorage`. See `tf.io`\n     * for more details.\n     *\n     * This method also allows you to refer to certain types of `IOHandler`s\n     * as URL-like string shortcuts, such as 'localstorage://' and\n     * 'indexeddb://'.\n     *\n     * Example 1: Save `model`'s topology and weights to browser [local\n     * storage](https://developer.mozilla.org/en-US/docs/Web/API/Window/localStorage);\n     * then load it back.\n     *\n     * ```js\n     * const model = tf.sequential(\n     *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});\n     * console.log('Prediction from original model:');\n     * model.predict(tf.ones([1, 3])).print();\n     *\n     * const saveResults = await model.save('localstorage://my-model-1');\n     *\n     * const loadedModel = await tf.loadLayersModel('localstorage://my-model-1');\n     * console.log('Prediction from loaded model:');\n     * loadedModel.predict(tf.ones([1, 3])).print();\n     * ```\n     *\n     * Example 2. Saving `model`'s topology and weights to browser\n     * [IndexedDB](https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API);\n     * then load it back.\n     *\n     * ```js\n     * const model = tf.sequential(\n     *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});\n     * console.log('Prediction from original model:');\n     * model.predict(tf.ones([1, 3])).print();\n     *\n     * const saveResults = await model.save('indexeddb://my-model-1');\n     *\n     * const loadedModel = await tf.loadLayersModel('indexeddb://my-model-1');\n     * console.log('Prediction from loaded model:');\n     * loadedModel.predict(tf.ones([1, 3])).print();\n     * ```\n     *\n     * Example 3. Saving `model`'s topology and weights as two files\n     * (`my-model-1.json` and `my-model-1.weights.bin`) downloaded from\n     * browser.\n     *\n     * ```js\n     * const model = tf.sequential(\n     *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});\n     * const saveResults = await model.save('downloads://my-model-1');\n     * ```\n     *\n     * Example 4. Send  `model`'s topology and weights to an HTTP server.\n     * See the documentation of `tf.io.http` for more details\n     * including specifying request parameters and implementation of the\n     * server.\n     *\n     * ```js\n     * const model = tf.sequential(\n     *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});\n     * const saveResults = await model.save('http://my-server/model/upload');\n     * ```\n     *\n     * @param handlerOrURL An instance of `IOHandler` or a URL-like,\n     * scheme-based string shortcut for `IOHandler`.\n     * @param config Options for saving the model.\n     * @returns A `Promise` of `SaveResult`, which summarizes the result of\n     * the saving, such as byte sizes of the saved artifacts for the model's\n     *   topology and weight values.\n     *\n     * @doc {heading: 'Models', subheading: 'Classes', ignoreCI: true}\n     */\n    async save(handlerOrURL, config) {\n        if (typeof handlerOrURL === 'string') {\n            const handlers = io.getSaveHandlers(handlerOrURL);\n            if (handlers.length === 0) {\n                throw new ValueError(`Cannot find any save handlers for URL '${handlerOrURL}'`);\n            }\n            else if (handlers.length > 1) {\n                throw new ValueError(`Found more than one (${handlers.length}) save handlers for ` +\n                    `URL '${handlerOrURL}'`);\n            }\n            handlerOrURL = handlers[0];\n        }\n        if (handlerOrURL.save == null) {\n            throw new ValueError('LayersModel.save() cannot proceed because the IOHandler ' +\n                'provided does not have the `save` attribute defined.');\n        }\n        const weightDataAndSpecs = await io.encodeWeights(this.getNamedWeights(config));\n        const returnString = false;\n        const unusedArg = null;\n        const modelConfig = this.toJSON(unusedArg, returnString);\n        const modelArtifacts = {\n            modelTopology: modelConfig,\n            format: LAYERS_MODEL_FORMAT_NAME,\n            generatedBy: `TensorFlow.js tfjs-layers v${version}`,\n            convertedBy: null,\n        };\n        const includeOptimizer = config == null ? false : config.includeOptimizer;\n        if (includeOptimizer && this.optimizer != null) {\n            modelArtifacts.trainingConfig = this.getTrainingConfig();\n            const weightType = 'optimizer';\n            const { data: optimizerWeightData, specs: optimizerWeightSpecs } = await io.encodeWeights(await this.optimizer.getWeights(), weightType);\n            weightDataAndSpecs.specs.push(...optimizerWeightSpecs);\n            weightDataAndSpecs.data = io.concatenateArrayBuffers([weightDataAndSpecs.data, optimizerWeightData]);\n        }\n        if (this.userDefinedMetadata != null) {\n            // Check serialized size of user-defined metadata.\n            const checkSize = true;\n            checkUserDefinedMetadata(this.userDefinedMetadata, this.name, checkSize);\n            modelArtifacts.userDefinedMetadata = this.userDefinedMetadata;\n        }\n        modelArtifacts.weightData = weightDataAndSpecs.data;\n        modelArtifacts.weightSpecs = weightDataAndSpecs.specs;\n        return handlerOrURL.save(modelArtifacts);\n    }\n    /**\n     * Set user-defined metadata.\n     *\n     * The set metadata will be serialized together with the topology\n     * and weights of the model during `save()` calls.\n     *\n     * @param setUserDefinedMetadata\n     */\n    setUserDefinedMetadata(userDefinedMetadata) {\n        checkUserDefinedMetadata(userDefinedMetadata, this.name);\n        this.userDefinedMetadata = userDefinedMetadata;\n    }\n    /**\n     * Get user-defined metadata.\n     *\n     * The metadata is supplied via one of the two routes:\n     *   1. By calling `setUserDefinedMetadata()`.\n     *   2. Loaded during model loading (if the model is constructed\n     *      via `tf.loadLayersModel()`.)\n     *\n     * If no user-defined metadata is available from either of the\n     * two routes, this function will return `undefined`.\n     */\n    getUserDefinedMetadata() {\n        return this.userDefinedMetadata;\n    }\n}\n// The class name is 'Model' rather than 'LayersModel' for backwards\n// compatibility since this class name shows up in the serialization format.\n/** @nocollapse */\nLayersModel.className = 'Model';\nserialization.registerClass(LayersModel);\n/**\n * A `tf.Functional` is an alias to `tf.LayersModel`.\n *\n * See also:\n *   `tf.LayersModel`, `tf.Sequential`, `tf.loadLayersModel`.\n */\n/** @doc {heading: 'Models', subheading: 'Classes'} */\nexport class Functional extends LayersModel {\n}\nFunctional.className = 'Functional';\nserialization.registerClass(Functional);\n"]},"metadata":{},"sourceType":"module"}