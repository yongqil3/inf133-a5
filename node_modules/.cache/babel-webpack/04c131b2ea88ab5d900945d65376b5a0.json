{"ast":null,"code":"import _asyncToGenerator from \"/Users/ryanliang/Downloads/main_movir_picker/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\nimport { env } from '@tensorflow/tfjs-core';\nimport { LazyIterator, OneToManyIterator } from './lazy_iterator';\nimport { StringIterator } from './string_iterator';\nexport class ByteChunkIterator extends LazyIterator {\n  /**\n   * Decode a stream of UTF8-encoded byte arrays to a stream of strings.\n   *\n   * The byte arrays producetd from the ByteChunkIterator on which this is\n   * called will be interpreted as concatenated.  No assumptions are made about\n   * the boundaries of the incoming chunks, so a multi-byte UTF8 encoding of a\n   * character may span the boundary between chunks.  This naturally happens,\n   * for instance, when reading fixed-size byte arrays from a file.\n   */\n  decodeUTF8() {\n    return new Utf8Iterator(this);\n  }\n\n} // ============================================================================\n// The following private classes serve to implement the chainable methods\n// on ByteChunkIterator.  Unfortunately they can't be placed in separate files,\n// due to resulting trouble with circular imports.\n// ============================================================================\n// We wanted multiple inheritance, e.g.\n//   class Utf8Iterator extends QueueIterator<string>, StringIterator\n// but the TypeScript mixin approach is a bit hacky, so we take this adapter\n// approach instead.\n\nclass Utf8Iterator extends StringIterator {\n  constructor(upstream) {\n    super();\n    this.upstream = upstream;\n    this.impl = new Utf8IteratorImpl(upstream);\n  }\n\n  summary() {\n    return this.impl.summary();\n  }\n\n  next() {\n    var _this = this;\n\n    return _asyncToGenerator(function* () {\n      return _this.impl.next();\n    })();\n  }\n\n}\n/**\n * Decode a stream of UTF8-encoded byte arrays to a stream of strings.\n *\n * This is tricky because the incoming byte array boundaries may disrupt a\n * multi-byte UTF8 character. Thus any incomplete character data at the end of\n * a chunk must be carried over and prepended to the next chunk before\n * decoding. Luckily with native decoder, TextDecoder in browser and\n * string_decoder in node, byte array boundaries are handled automatically.\n *\n * In the context of an input pipeline for machine learning, UTF8 decoding is\n * needed to parse text files containing training examples or prediction\n * requests (e.g., formatted as CSV or JSON). We cannot use the built-in\n * decoding provided by FileReader.readAsText() because here we are in a\n * streaming context, which FileReader does not support.\n *\n * @param upstream A `LazyIterator` of `Uint8Arrays` containing UTF8-encoded\n *   text, which should be interpreted as concatenated.  No assumptions are\n *   made about the boundaries of the incoming chunks, so a multi-byte UTF8\n *   encoding of a character may span the boundary between chunks.  This\n *   naturally happens, for instance, when reading fixed-size byte arrays from a\n *   file.\n */\n\n\nclass Utf8IteratorImpl extends OneToManyIterator {\n  constructor(upstream) {\n    super();\n    this.upstream = upstream;\n\n    if (env().get('IS_BROWSER')) {\n      this.decoder = new TextDecoder('utf-8');\n    } else {\n      // tslint:disable-next-line:no-require-imports\n      const {\n        StringDecoder\n      } = require('string_decoder');\n\n      this.decoder = new StringDecoder('utf8');\n    }\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Utf8`;\n  }\n\n  pump() {\n    var _this2 = this;\n\n    return _asyncToGenerator(function* () {\n      const chunkResult = yield _this2.upstream.next();\n      let chunk;\n\n      if (chunkResult.done) {\n        return false;\n      } else {\n        chunk = chunkResult.value;\n      }\n\n      let text;\n\n      if (env().get('IS_BROWSER')) {\n        text = _this2.decoder.decode(chunk, {\n          stream: true\n        });\n      } else {\n        text = _this2.decoder.write(Buffer.from(chunk.buffer));\n      }\n\n      _this2.outputQueue.push(text);\n\n      return true;\n    })();\n  }\n\n}","map":{"version":3,"sources":["/Users/ryanliang/Downloads/main_movir_picker/node_modules/@tensorflow/tfjs-data/dist/iterators/byte_chunk_iterator.js"],"names":["env","LazyIterator","OneToManyIterator","StringIterator","ByteChunkIterator","decodeUTF8","Utf8Iterator","constructor","upstream","impl","Utf8IteratorImpl","summary","next","get","decoder","TextDecoder","StringDecoder","require","pump","chunkResult","chunk","done","value","text","decode","stream","write","Buffer","from","buffer","outputQueue","push"],"mappings":";;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASA,GAAT,QAAoB,uBAApB;AACA,SAASC,YAAT,EAAuBC,iBAAvB,QAAgD,iBAAhD;AACA,SAASC,cAAT,QAA+B,mBAA/B;AACA,OAAO,MAAMC,iBAAN,SAAgCH,YAAhC,CAA6C;AAChD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACII,EAAAA,UAAU,GAAG;AACT,WAAO,IAAIC,YAAJ,CAAiB,IAAjB,CAAP;AACH;;AAZ+C,C,CAcpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,MAAMA,YAAN,SAA2BH,cAA3B,CAA0C;AACtCI,EAAAA,WAAW,CAACC,QAAD,EAAW;AAClB;AACA,SAAKA,QAAL,GAAgBA,QAAhB;AACA,SAAKC,IAAL,GAAY,IAAIC,gBAAJ,CAAqBF,QAArB,CAAZ;AACH;;AACDG,EAAAA,OAAO,GAAG;AACN,WAAO,KAAKF,IAAL,CAAUE,OAAV,EAAP;AACH;;AACKC,EAAAA,IAAI,GAAG;AAAA;;AAAA;AACT,aAAO,KAAI,CAACH,IAAL,CAAUG,IAAV,EAAP;AADS;AAEZ;;AAXqC;AAa1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,MAAMF,gBAAN,SAA+BR,iBAA/B,CAAiD;AAC7CK,EAAAA,WAAW,CAACC,QAAD,EAAW;AAClB;AACA,SAAKA,QAAL,GAAgBA,QAAhB;;AACA,QAAIR,GAAG,GAAGa,GAAN,CAAU,YAAV,CAAJ,EAA6B;AACzB,WAAKC,OAAL,GAAe,IAAIC,WAAJ,CAAgB,OAAhB,CAAf;AACH,KAFD,MAGK;AACD;AACA,YAAM;AAAEC,QAAAA;AAAF,UAAoBC,OAAO,CAAC,gBAAD,CAAjC;;AACA,WAAKH,OAAL,GAAe,IAAIE,aAAJ,CAAkB,MAAlB,CAAf;AACH;AACJ;;AACDL,EAAAA,OAAO,GAAG;AACN,WAAQ,GAAE,KAAKH,QAAL,CAAcG,OAAd,EAAwB,UAAlC;AACH;;AACKO,EAAAA,IAAI,GAAG;AAAA;;AAAA;AACT,YAAMC,WAAW,SAAS,MAAI,CAACX,QAAL,CAAcI,IAAd,EAA1B;AACA,UAAIQ,KAAJ;;AACA,UAAID,WAAW,CAACE,IAAhB,EAAsB;AAClB,eAAO,KAAP;AACH,OAFD,MAGK;AACDD,QAAAA,KAAK,GAAGD,WAAW,CAACG,KAApB;AACH;;AACD,UAAIC,IAAJ;;AACA,UAAIvB,GAAG,GAAGa,GAAN,CAAU,YAAV,CAAJ,EAA6B;AACzBU,QAAAA,IAAI,GAAG,MAAI,CAACT,OAAL,CAAaU,MAAb,CAAoBJ,KAApB,EAA2B;AAAEK,UAAAA,MAAM,EAAE;AAAV,SAA3B,CAAP;AACH,OAFD,MAGK;AACDF,QAAAA,IAAI,GAAG,MAAI,CAACT,OAAL,CAAaY,KAAb,CAAmBC,MAAM,CAACC,IAAP,CAAYR,KAAK,CAACS,MAAlB,CAAnB,CAAP;AACH;;AACD,MAAA,MAAI,CAACC,WAAL,CAAiBC,IAAjB,CAAsBR,IAAtB;;AACA,aAAO,IAAP;AAjBS;AAkBZ;;AAlC4C","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\nimport { env } from '@tensorflow/tfjs-core';\nimport { LazyIterator, OneToManyIterator } from './lazy_iterator';\nimport { StringIterator } from './string_iterator';\nexport class ByteChunkIterator extends LazyIterator {\n    /**\n     * Decode a stream of UTF8-encoded byte arrays to a stream of strings.\n     *\n     * The byte arrays producetd from the ByteChunkIterator on which this is\n     * called will be interpreted as concatenated.  No assumptions are made about\n     * the boundaries of the incoming chunks, so a multi-byte UTF8 encoding of a\n     * character may span the boundary between chunks.  This naturally happens,\n     * for instance, when reading fixed-size byte arrays from a file.\n     */\n    decodeUTF8() {\n        return new Utf8Iterator(this);\n    }\n}\n// ============================================================================\n// The following private classes serve to implement the chainable methods\n// on ByteChunkIterator.  Unfortunately they can't be placed in separate files,\n// due to resulting trouble with circular imports.\n// ============================================================================\n// We wanted multiple inheritance, e.g.\n//   class Utf8Iterator extends QueueIterator<string>, StringIterator\n// but the TypeScript mixin approach is a bit hacky, so we take this adapter\n// approach instead.\nclass Utf8Iterator extends StringIterator {\n    constructor(upstream) {\n        super();\n        this.upstream = upstream;\n        this.impl = new Utf8IteratorImpl(upstream);\n    }\n    summary() {\n        return this.impl.summary();\n    }\n    async next() {\n        return this.impl.next();\n    }\n}\n/**\n * Decode a stream of UTF8-encoded byte arrays to a stream of strings.\n *\n * This is tricky because the incoming byte array boundaries may disrupt a\n * multi-byte UTF8 character. Thus any incomplete character data at the end of\n * a chunk must be carried over and prepended to the next chunk before\n * decoding. Luckily with native decoder, TextDecoder in browser and\n * string_decoder in node, byte array boundaries are handled automatically.\n *\n * In the context of an input pipeline for machine learning, UTF8 decoding is\n * needed to parse text files containing training examples or prediction\n * requests (e.g., formatted as CSV or JSON). We cannot use the built-in\n * decoding provided by FileReader.readAsText() because here we are in a\n * streaming context, which FileReader does not support.\n *\n * @param upstream A `LazyIterator` of `Uint8Arrays` containing UTF8-encoded\n *   text, which should be interpreted as concatenated.  No assumptions are\n *   made about the boundaries of the incoming chunks, so a multi-byte UTF8\n *   encoding of a character may span the boundary between chunks.  This\n *   naturally happens, for instance, when reading fixed-size byte arrays from a\n *   file.\n */\nclass Utf8IteratorImpl extends OneToManyIterator {\n    constructor(upstream) {\n        super();\n        this.upstream = upstream;\n        if (env().get('IS_BROWSER')) {\n            this.decoder = new TextDecoder('utf-8');\n        }\n        else {\n            // tslint:disable-next-line:no-require-imports\n            const { StringDecoder } = require('string_decoder');\n            this.decoder = new StringDecoder('utf8');\n        }\n    }\n    summary() {\n        return `${this.upstream.summary()} -> Utf8`;\n    }\n    async pump() {\n        const chunkResult = await this.upstream.next();\n        let chunk;\n        if (chunkResult.done) {\n            return false;\n        }\n        else {\n            chunk = chunkResult.value;\n        }\n        let text;\n        if (env().get('IS_BROWSER')) {\n            text = this.decoder.decode(chunk, { stream: true });\n        }\n        else {\n            text = this.decoder.write(Buffer.from(chunk.buffer));\n        }\n        this.outputQueue.push(text);\n        return true;\n    }\n}\n"]},"metadata":{},"sourceType":"module"}