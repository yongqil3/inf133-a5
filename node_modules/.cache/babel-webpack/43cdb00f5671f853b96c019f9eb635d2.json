{"ast":null,"code":"import _asyncToGenerator from \"/Users/ryanliang/Downloads/main_movir_picker/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n// inspired by https://github.com/maxogden/filereader-stream\nimport { env, util } from '@tensorflow/tfjs-core';\nimport { ByteChunkIterator } from './byte_chunk_iterator';\n/**\n * Provide a stream of chunks from a File, Blob, or Uint8Array.\n * @param file The source File, Blob or Uint8Array.\n * @param options Optional settings controlling file reading.\n * @returns a lazy Iterator of Uint8Arrays containing sequential chunks of the\n *   input File, Blob or Uint8Array.\n */\n\nexport class FileChunkIterator extends ByteChunkIterator {\n  constructor(file, options = {}) {\n    super();\n    this.file = file;\n    this.options = options;\n    util.assert(file instanceof Uint8Array || (env().get('IS_BROWSER') ? file instanceof File || file instanceof Blob : false), () => 'FileChunkIterator only supports File, Blob and Uint8Array ' + 'right now.');\n    this.offset = options.offset || 0; // default 1MB chunk has tolerable perf on large files\n\n    this.chunkSize = options.chunkSize || 1024 * 1024;\n  }\n\n  summary() {\n    return `FileChunks ${this.file}`;\n  }\n\n  next() {\n    var _this = this;\n\n    return _asyncToGenerator(function* () {\n      if (_this.offset >= (_this.file instanceof Uint8Array ? _this.file.byteLength : _this.file.size)) {\n        return {\n          value: null,\n          done: true\n        };\n      }\n\n      const chunk = new Promise((resolve, reject) => {\n        const end = _this.offset + _this.chunkSize;\n\n        if (_this.file instanceof Uint8Array) {\n          // Note if end > this.uint8Array.byteLength, we just get a small last\n          // chunk.\n          resolve(new Uint8Array(_this.file.slice(_this.offset, end)));\n        } else {\n          // This branch assumes that this.file type is File or Blob, which\n          // means it is in the browser environment.\n          // TODO(soergel): is this a performance issue?\n          const fileReader = new FileReader();\n\n          fileReader.onload = event => {\n            let data = fileReader.result; // Not sure we can trust the return type of\n            // FileReader.readAsArrayBuffer See e.g.\n            // https://github.com/node-file-api/FileReader/issues/2\n\n            if (data instanceof ArrayBuffer) {\n              data = new Uint8Array(data);\n            }\n\n            if (!(data instanceof Uint8Array)) {\n              return reject(new TypeError('FileReader returned unknown type.'));\n            }\n\n            resolve(data);\n          };\n\n          fileReader.onabort = event => {\n            return reject(new Error('Aborted'));\n          };\n\n          fileReader.onerror = event => {\n            return reject(new Error(event.type));\n          }; // TODO(soergel): better handle onabort, onerror\n          // Note if end > this.file.size, we just get a small last chunk.\n\n\n          const slice = _this.file.slice(_this.offset, end); // We can't use readAsText here (even if we know the file is text)\n          // because the slice boundary may fall within a multi-byte character.\n\n\n          fileReader.readAsArrayBuffer(slice);\n        }\n\n        _this.offset = end;\n      });\n      return {\n        value: yield chunk,\n        done: false\n      };\n    })();\n  }\n\n}","map":{"version":3,"sources":["/Users/ryanliang/Downloads/main_movir_picker/node_modules/@tensorflow/tfjs-data/dist/iterators/file_chunk_iterator.js"],"names":["env","util","ByteChunkIterator","FileChunkIterator","constructor","file","options","assert","Uint8Array","get","File","Blob","offset","chunkSize","summary","next","byteLength","size","value","done","chunk","Promise","resolve","reject","end","slice","fileReader","FileReader","onload","event","data","result","ArrayBuffer","TypeError","onabort","Error","onerror","type","readAsArrayBuffer"],"mappings":";;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASA,GAAT,EAAcC,IAAd,QAA0B,uBAA1B;AACA,SAASC,iBAAT,QAAkC,uBAAlC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,MAAMC,iBAAN,SAAgCD,iBAAhC,CAAkD;AACrDE,EAAAA,WAAW,CAACC,IAAD,EAAOC,OAAO,GAAG,EAAjB,EAAqB;AAC5B;AACA,SAAKD,IAAL,GAAYA,IAAZ;AACA,SAAKC,OAAL,GAAeA,OAAf;AACAL,IAAAA,IAAI,CAACM,MAAL,CAAaF,IAAI,YAAYG,UAAjB,KACPR,GAAG,GAAGS,GAAN,CAAU,YAAV,IACIJ,IAAI,YAAYK,IAAhB,IAAwBL,IAAI,YAAYM,IAD5C,GAEG,KAHI,CAAZ,EAGgB,MAAM,+DAClB,YAJJ;AAKA,SAAKC,MAAL,GAAcN,OAAO,CAACM,MAAR,IAAkB,CAAhC,CAT4B,CAU5B;;AACA,SAAKC,SAAL,GAAiBP,OAAO,CAACO,SAAR,IAAqB,OAAO,IAA7C;AACH;;AACDC,EAAAA,OAAO,GAAG;AACN,WAAQ,cAAa,KAAKT,IAAK,EAA/B;AACH;;AACKU,EAAAA,IAAI,GAAG;AAAA;;AAAA;AACT,UAAI,KAAI,CAACH,MAAL,KAAiB,KAAI,CAACP,IAAL,YAAqBG,UAAtB,GAChB,KAAI,CAACH,IAAL,CAAUW,UADM,GAEhB,KAAI,CAACX,IAAL,CAAUY,IAFV,CAAJ,EAEqB;AACjB,eAAO;AAAEC,UAAAA,KAAK,EAAE,IAAT;AAAeC,UAAAA,IAAI,EAAE;AAArB,SAAP;AACH;;AACD,YAAMC,KAAK,GAAG,IAAIC,OAAJ,CAAY,CAACC,OAAD,EAAUC,MAAV,KAAqB;AAC3C,cAAMC,GAAG,GAAG,KAAI,CAACZ,MAAL,GAAc,KAAI,CAACC,SAA/B;;AACA,YAAI,KAAI,CAACR,IAAL,YAAqBG,UAAzB,EAAqC;AACjC;AACA;AACAc,UAAAA,OAAO,CAAC,IAAId,UAAJ,CAAe,KAAI,CAACH,IAAL,CAAUoB,KAAV,CAAgB,KAAI,CAACb,MAArB,EAA6BY,GAA7B,CAAf,CAAD,CAAP;AACH,SAJD,MAKK;AACD;AACA;AACA;AACA,gBAAME,UAAU,GAAG,IAAIC,UAAJ,EAAnB;;AACAD,UAAAA,UAAU,CAACE,MAAX,GAAqBC,KAAD,IAAW;AAC3B,gBAAIC,IAAI,GAAGJ,UAAU,CAACK,MAAtB,CAD2B,CAE3B;AACA;AACA;;AACA,gBAAID,IAAI,YAAYE,WAApB,EAAiC;AAC7BF,cAAAA,IAAI,GAAG,IAAItB,UAAJ,CAAesB,IAAf,CAAP;AACH;;AACD,gBAAI,EAAEA,IAAI,YAAYtB,UAAlB,CAAJ,EAAmC;AAC/B,qBAAOe,MAAM,CAAC,IAAIU,SAAJ,CAAc,mCAAd,CAAD,CAAb;AACH;;AACDX,YAAAA,OAAO,CAACQ,IAAD,CAAP;AACH,WAZD;;AAaAJ,UAAAA,UAAU,CAACQ,OAAX,GAAsBL,KAAD,IAAW;AAC5B,mBAAON,MAAM,CAAC,IAAIY,KAAJ,CAAU,SAAV,CAAD,CAAb;AACH,WAFD;;AAGAT,UAAAA,UAAU,CAACU,OAAX,GAAsBP,KAAD,IAAW;AAC5B,mBAAON,MAAM,CAAC,IAAIY,KAAJ,CAAUN,KAAK,CAACQ,IAAhB,CAAD,CAAb;AACH,WAFD,CArBC,CAwBD;AACA;;;AACA,gBAAMZ,KAAK,GAAG,KAAI,CAACpB,IAAL,CAAUoB,KAAV,CAAgB,KAAI,CAACb,MAArB,EAA6BY,GAA7B,CAAd,CA1BC,CA2BD;AACA;;;AACAE,UAAAA,UAAU,CAACY,iBAAX,CAA6Bb,KAA7B;AACH;;AACD,QAAA,KAAI,CAACb,MAAL,GAAcY,GAAd;AACH,OAvCa,CAAd;AAwCA,aAAO;AAAEN,QAAAA,KAAK,QAASE,KAAhB;AAAwBD,QAAAA,IAAI,EAAE;AAA9B,OAAP;AA9CS;AA+CZ;;AAhEoD","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n// inspired by https://github.com/maxogden/filereader-stream\nimport { env, util } from '@tensorflow/tfjs-core';\nimport { ByteChunkIterator } from './byte_chunk_iterator';\n/**\n * Provide a stream of chunks from a File, Blob, or Uint8Array.\n * @param file The source File, Blob or Uint8Array.\n * @param options Optional settings controlling file reading.\n * @returns a lazy Iterator of Uint8Arrays containing sequential chunks of the\n *   input File, Blob or Uint8Array.\n */\nexport class FileChunkIterator extends ByteChunkIterator {\n    constructor(file, options = {}) {\n        super();\n        this.file = file;\n        this.options = options;\n        util.assert((file instanceof Uint8Array) ||\n            (env().get('IS_BROWSER') ?\n                (file instanceof File || file instanceof Blob) :\n                false), () => 'FileChunkIterator only supports File, Blob and Uint8Array ' +\n            'right now.');\n        this.offset = options.offset || 0;\n        // default 1MB chunk has tolerable perf on large files\n        this.chunkSize = options.chunkSize || 1024 * 1024;\n    }\n    summary() {\n        return `FileChunks ${this.file}`;\n    }\n    async next() {\n        if (this.offset >= ((this.file instanceof Uint8Array) ?\n            this.file.byteLength :\n            this.file.size)) {\n            return { value: null, done: true };\n        }\n        const chunk = new Promise((resolve, reject) => {\n            const end = this.offset + this.chunkSize;\n            if (this.file instanceof Uint8Array) {\n                // Note if end > this.uint8Array.byteLength, we just get a small last\n                // chunk.\n                resolve(new Uint8Array(this.file.slice(this.offset, end)));\n            }\n            else {\n                // This branch assumes that this.file type is File or Blob, which\n                // means it is in the browser environment.\n                // TODO(soergel): is this a performance issue?\n                const fileReader = new FileReader();\n                fileReader.onload = (event) => {\n                    let data = fileReader.result;\n                    // Not sure we can trust the return type of\n                    // FileReader.readAsArrayBuffer See e.g.\n                    // https://github.com/node-file-api/FileReader/issues/2\n                    if (data instanceof ArrayBuffer) {\n                        data = new Uint8Array(data);\n                    }\n                    if (!(data instanceof Uint8Array)) {\n                        return reject(new TypeError('FileReader returned unknown type.'));\n                    }\n                    resolve(data);\n                };\n                fileReader.onabort = (event) => {\n                    return reject(new Error('Aborted'));\n                };\n                fileReader.onerror = (event) => {\n                    return reject(new Error(event.type));\n                };\n                // TODO(soergel): better handle onabort, onerror\n                // Note if end > this.file.size, we just get a small last chunk.\n                const slice = this.file.slice(this.offset, end);\n                // We can't use readAsText here (even if we know the file is text)\n                // because the slice boundary may fall within a multi-byte character.\n                fileReader.readAsArrayBuffer(slice);\n            }\n            this.offset = end;\n        });\n        return { value: (await chunk), done: false };\n    }\n}\n"]},"metadata":{},"sourceType":"module"}